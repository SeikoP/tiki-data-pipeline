"""
Load pipeline Ä‘á»ƒ load dá»¯ liá»‡u Ä‘Ã£ transform vÃ o database
"""

import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any

logger = logging.getLogger(__name__)

# Import PostgresStorage vá»›i TYPE_CHECKING Ä‘á»ƒ trÃ¡nh mypy errors
if TYPE_CHECKING:
    pass  # PostgresStorageType khÃ´ng cáº§n thiáº¿t
else:
    pass  # type: ignore[misc, assignment]

PostgresStorageClass: type[Any] | None = None


class DateTimeEncoder(json.JSONEncoder):
    """JSON encoder Ä‘á»ƒ serialize datetime objects"""

    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)


def serialize_for_json(obj: Any) -> Any:
    """Recursively convert datetime objects to ISO format strings"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {key: serialize_for_json(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [serialize_for_json(item) for item in obj]
    else:
        return obj


# ThÃªm /opt/airflow/src vÃ o sys.path náº¿u chÆ°a cÃ³ (cho Docker environment)
src_paths = [
    Path("/opt/airflow/src"),  # Docker default path
    Path(__file__).parent.parent.parent,  # Tá»« loader.py lÃªn src
]

for src_path in src_paths:
    if src_path.exists() and str(src_path) not in sys.path:
        sys.path.insert(0, str(src_path))
        break

PostgresStorageClass = None
try:
    # Æ¯u tiÃªn 1: Absolute import (sau khi Ä‘Ã£ thÃªm src vÃ o path)
    from pipelines.crawl.storage import (
        PostgresStorage as _PostgresStorage,  # type: ignore[attr-defined]
    )

    PostgresStorageClass = _PostgresStorage  # type: ignore[assignment]
except ImportError:
    try:
        # Æ¯u tiÃªn 2: Absolute import tá»« file trá»±c tiáº¿p
        from pipelines.crawl.storage.postgres_storage import (
            PostgresStorage as _PostgresStorage2,  # type: ignore[attr-defined]
        )

        PostgresStorageClass = _PostgresStorage2  # type: ignore[assignment]
    except ImportError:
        try:
            # Æ¯u tiÃªn 3: Relative import (náº¿u cháº¡y nhÆ° package)
            from ...crawl.storage import (
                PostgresStorage as _PostgresStorage3,  # type: ignore[attr-defined]
            )

            PostgresStorageClass = _PostgresStorage3  # type: ignore[assignment]
        except ImportError:
            try:
                import importlib.util
                import os

                # TÃ¬m Ä‘Æ°á»ng dáº«n Ä‘áº¿n postgres_storage.py
                # Láº¥y Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i cá»§a file hiá»‡n táº¡i
                current_file = Path(__file__).resolve()

                # TÃ¬m Ä‘Æ°á»ng dáº«n src (cÃ³ thá»ƒ lÃ  parent hoáº·c grandparent)
                # loader.py á»Ÿ: src/pipelines/load/loader.py
                # postgres_storage.py á»Ÿ: src/pipelines/crawl/storage/postgres_storage.py
                possible_paths = [
                    # Tá»« /opt/airflow/src (Docker default - Æ°u tiÃªn)
                    Path("/opt/airflow/src/pipelines/crawl/storage/postgres_storage.py"),
                    # Tá»« current file: loader.py -> pipelines -> crawl/storage/postgres_storage.py
                    current_file.parent.parent / "crawl" / "storage" / "postgres_storage.py",
                    # Tá»« current file lÃªn 1 cáº¥p ná»¯a (trong trÆ°á»ng há»£p Ä‘áº·c biá»‡t)
                    current_file.parent.parent.parent
                    / "pipelines"
                    / "crawl"
                    / "storage"
                    / "postgres_storage.py",
                    # Tá»« current working directory
                    Path(os.getcwd())
                    / "src"
                    / "pipelines"
                    / "crawl"
                    / "storage"
                    / "postgres_storage.py",
                    # Tá»« workspace root
                    Path("/workspace/src/pipelines/crawl/storage/postgres_storage.py"),
                ]

                postgres_storage_path = None
                for path in possible_paths:
                    test_path = Path(path) if isinstance(path, str) else path
                    if test_path.exists() and test_path.is_file():
                        postgres_storage_path = test_path
                        break

                if postgres_storage_path:
                    # Sá»­ dá»¥ng importlib Ä‘á»ƒ load trá»±c tiáº¿p tá»« file
                    spec = importlib.util.spec_from_file_location(
                        "postgres_storage", postgres_storage_path
                    )
                    if spec and spec.loader:
                        postgres_storage_module = importlib.util.module_from_spec(spec)
                        spec.loader.exec_module(postgres_storage_module)
                        PostgresStorageClass = postgres_storage_module.PostgresStorage  # type: ignore[assignment]
                else:
                    # Náº¿u khÃ´ng tÃ¬m tháº¥y file, thá»­ thÃªm src vÃ o path vÃ  import absolute
                    # loader.py á»Ÿ: src/pipelines/load/loader.py
                    # src á»Ÿ: current_file.parent.parent.parent
                    src_path = current_file.parent.parent.parent
                    if src_path.exists() and str(src_path) not in sys.path:
                        sys.path.insert(0, str(src_path))

                        try:
                            from pipelines.crawl.storage import (
                                PostgresStorage as _PostgresStorage4,  # type: ignore[attr-defined]
                            )

                            PostgresStorageClass = _PostgresStorage4  # type: ignore[assignment]
                        except ImportError:
                            try:
                                from pipelines.crawl.storage.postgres_storage import (
                                    PostgresStorage as _PostgresStorage5,  # type: ignore[attr-defined]
                                )

                                PostgresStorageClass = _PostgresStorage5  # type: ignore[assignment]
                            except ImportError:
                                # KhÃ´ng thá»ƒ import, sáº½ dÃ¹ng file-based loading
                                PostgresStorageClass = None
            except Exception:
                # Náº¿u importlib fail, set None
                PostgresStorageClass = None

# Náº¿u váº«n khÃ´ng import Ä‘Æ°á»£c, log warning
if PostgresStorageClass is None:
    logger.warning(
        "âš ï¸  KhÃ´ng thá»ƒ import PostgresStorage. Chá»‰ há»— trá»£ load tá»« file (khÃ´ng cÃ³ database)."
    )


class DataLoader:
    """Class Ä‘á»ƒ load dá»¯ liá»‡u Ä‘Ã£ transform vÃ o database hoáº·c file"""

    def __init__(
        self,
        database: str | None = None,
        host: str | None = None,
        port: int = 5432,
        user: str | None = None,
        password: str | None = None,
        batch_size: int = 100,
        enable_db: bool = True,
    ):
        """
        Khá»Ÿi táº¡o DataLoader

        Args:
            database: Database name (máº·c Ä‘á»‹nh: crawl_data)
            host: PostgreSQL host
            port: PostgreSQL port
            user: PostgreSQL user
            password: PostgreSQL password
            batch_size: KÃ­ch thÆ°á»›c batch khi insert
            enable_db: CÃ³ enable database loading khÃ´ng
        """
        self.batch_size = batch_size
        self.enable_db = enable_db and PostgresStorageClass is not None
        self.stats: dict[str, Any] = {
            "total_loaded": 0,
            "success_count": 0,
            "failed_count": 0,
            "db_loaded": 0,
            "file_loaded": 0,
            "inserted_count": 0,  # Sá»‘ products má»›i Ä‘Æ°á»£c INSERT
            "updated_count": 0,  # Sá»‘ products Ä‘Ã£ cÃ³ Ä‘Æ°á»£c UPDATE
            "errors": [],
        }

        # Khá»Ÿi táº¡o PostgresStorage náº¿u enable_db
        self.db_storage: Any = None
        if self.enable_db:
            try:
                if PostgresStorageClass is None:
                    raise ImportError("PostgresStorageClass not available")
                self.db_storage = PostgresStorageClass(
                    host=host,
                    port=port,
                    database=database or "crawl_data",
                    user=user,
                    password=password,
                )
                logger.info("âœ… ÄÃ£ káº¿t ná»‘i vá»›i PostgreSQL database")
            except Exception as e:
                logger.warning(f"âš ï¸  KhÃ´ng thá»ƒ káº¿t ná»‘i database: {e}")
                self.enable_db = False
                self.db_storage = None

    def load_products(
        self,
        products: list[dict[str, Any]],
        save_to_file: str | None = None,
        upsert: bool = True,
        validate_before_load: bool = True,
    ) -> dict[str, Any]:
        """
        Load danh sÃ¡ch products vÃ o database vÃ /hoáº·c file

        Args:
            products: Danh sÃ¡ch products Ä‘Ã£ transform
            save_to_file: ÄÆ°á»ng dáº«n file Ä‘á»ƒ lÆ°u (náº¿u cáº§n)
            upsert: Náº¿u True, update náº¿u Ä‘Ã£ tá»“n táº¡i
            validate_before_load: CÃ³ validate trÆ°á»›c khi load khÃ´ng

        Returns:
            Stats dictionary
        """
        self.stats = {
            "total_loaded": len(products),
            "success_count": 0,
            "failed_count": 0,
            "db_loaded": 0,
            "file_loaded": 0,
            "errors": [],
        }

        if not products:
            logger.warning("âš ï¸  Danh sÃ¡ch products rá»—ng")
            return self.stats

        # Validate trÆ°á»›c náº¿u cáº§n
        if validate_before_load:
            valid_products = []
            for product in products:
                # Kiá»ƒm tra required fields
                if not product.get("product_id") or not product.get("name"):
                    self.stats["failed_count"] += 1
                    self.stats["errors"].append(
                        f"Missing required fields: product_id={product.get('product_id')}"
                    )
                    continue
                valid_products.append(product)
            products = valid_products

        # Load vÃ o database
        if self.enable_db and self.db_storage:
            try:
                result: dict[str, Any] = self.db_storage.save_products(
                    products, upsert=upsert, batch_size=self.batch_size
                )

                # Xá»­ lÃ½ káº¿t quáº£ (always dict with consistent structure)
                saved_count: int = result.get("saved_count", 0)
                inserted_count: int = result.get("inserted_count", 0)
                updated_count: int = result.get("updated_count", 0)
                self.stats["db_loaded"] = saved_count
                self.stats["success_count"] = saved_count
                self.stats["inserted_count"] = inserted_count
                self.stats["updated_count"] = updated_count
                logger.info(f"âœ… ÄÃ£ load {saved_count} products vÃ o database")
                if upsert:
                    logger.info(f"   - INSERT (má»›i): {inserted_count}")
                    logger.info(f"   - UPDATE (Ä‘Ã£ cÃ³): {updated_count}")
            except Exception as e:
                error_msg = f"Lá»—i khi load vÃ o database: {str(e)}"
                self.stats["errors"].append(error_msg)
                self.stats["failed_count"] += len(products)
                logger.error(f"âŒ {error_msg}")

        # Load vÃ o file náº¿u cáº§n
        if save_to_file:
            try:
                file_path = Path(save_to_file)
                file_path.parent.mkdir(parents=True, exist_ok=True)

                # Serialize datetime objects trong products trÆ°á»›c khi save
                serialized_products = serialize_for_json(products)

                # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u
                output_data = {
                    "loaded_at": datetime.now().isoformat(),
                    "total_products": len(products),
                    "stats": {
                        "db_loaded": self.stats.get("db_loaded", 0),
                        "file_loaded": len(products),
                    },
                    "products": serialized_products,
                }

                with open(file_path, "w", encoding="utf-8", newline="\n") as f:
                    json.dump(output_data, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)

                self.stats["file_loaded"] = len(products)
                logger.info(f"âœ… ÄÃ£ lÆ°u {len(products)} products vÃ o file: {save_to_file}")
            except Exception as e:
                error_msg = f"Lá»—i khi lÆ°u vÃ o file: {str(e)}"
                self.stats["errors"].append(error_msg)
                logger.error(f"âŒ {error_msg}")
                import traceback

                logger.debug(traceback.format_exc())

        # Update success count náº¿u chÆ°a cÃ³
        if self.stats["success_count"] == 0 and self.stats["file_loaded"] > 0:
            self.stats["success_count"] = self.stats["file_loaded"]

        return self.stats

    def load_from_file(
        self,
        input_file: str,
        save_to_file: str | None = None,
        upsert: bool = True,
    ) -> dict[str, Any]:
        """
        Load products tá»« file JSON

        Args:
            input_file: ÄÆ°á»ng dáº«n file JSON input
            save_to_db: CÃ³ lÆ°u vÃ o database khÃ´ng
            save_to_file: ÄÆ°á»ng dáº«n file output (náº¿u cáº§n)
            upsert: Náº¿u True, update náº¿u Ä‘Ã£ tá»“n táº¡i

        Returns:
            Stats dictionary
        """
        file_path = Path(input_file)
        if not file_path.exists():
            error_msg = f"File khÃ´ng tá»“n táº¡i: {input_file}"
            self.stats["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
            return self.stats

        try:
            with open(file_path, encoding="utf-8") as f:
                data = json.load(f)

            # Extract products tá»« data
            # Há»— trá»£ nhiá»u format:
            # - {"products": [...]}
            # - {"data": {"products": [...]}}
            # - [...] (trá»±c tiáº¿p lÃ  list)
            products = []
            if isinstance(data, list):
                products = data
            elif isinstance(data, dict):
                if "products" in data:
                    products = data["products"]
                elif "data" in data and isinstance(data["data"], dict):
                    products = data["data"].get("products", [])

            if not products:
                logger.warning("âš ï¸  KhÃ´ng tÃ¬m tháº¥y products trong file")
                return self.stats

            logger.info(f"ğŸ“‚ ÄÃ£ load {len(products)} products tá»« file: {input_file}")

            # Load vÃ o database vÃ /hoáº·c file
            return self.load_products(
                products,
                save_to_file=save_to_file,
                upsert=upsert,
                validate_before_load=True,
            )

        except json.JSONDecodeError as e:
            error_msg = f"Lá»—i parse JSON: {str(e)}"
            self.stats["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
            return self.stats
        except Exception as e:
            error_msg = f"Lá»—i khi load tá»« file: {str(e)}"
            self.stats["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
            return self.stats

    def load_categories(
        self,
        categories: list[dict[str, Any]],
        save_to_file: str | None = None,
        upsert: bool = True,
        validate_before_load: bool = True,
    ) -> dict[str, Any]:
        """
        Load danh sÃ¡ch categories vÃ o database vÃ /hoáº·c file

        Args:
            categories: Danh sÃ¡ch categories Ä‘Ã£ transform
            save_to_file: ÄÆ°á»ng dáº«n file Ä‘á»ƒ lÆ°u (náº¿u cáº§n)
            upsert: Náº¿u True, update náº¿u Ä‘Ã£ tá»“n táº¡i
            validate_before_load: CÃ³ validate trÆ°á»›c khi load khÃ´ng

        Returns:
            Stats dictionary
        """
        self.stats = {
            "total_loaded": len(categories),
            "success_count": 0,
            "failed_count": 0,
            "db_loaded": 0,
            "file_loaded": 0,
            "errors": [],
        }

        if not categories:
            logger.warning("âš ï¸  Danh sÃ¡ch categories rá»—ng")
            return self.stats

        # Validate trÆ°á»›c náº¿u cáº§n
        if validate_before_load:
            valid_categories = []
            for cat in categories:
                # Kiá»ƒm tra required fields
                if not cat.get("url") or not cat.get("name"):
                    self.stats["failed_count"] += 1
                    self.stats["errors"].append(
                        f"Missing required fields: url={cat.get('url')}, name={cat.get('name')}"
                    )
                    continue
                valid_categories.append(cat)
            categories = valid_categories

        # Load vÃ o database
        if self.enable_db and self.db_storage:
            logger.info(
                "â„¹ï¸ Skip saving categories to DB (Table 'categories' removed). Only saving to file."
            )
            # Database load logic removed as requested

        # Load vÃ o file náº¿u cáº§n
        if save_to_file:
            try:
                file_path = Path(save_to_file)
                file_path.parent.mkdir(parents=True, exist_ok=True)

                # Serialize datetime objects trong categories trÆ°á»›c khi save
                serialized_categories = serialize_for_json(categories)

                # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u
                output_data = {
                    "loaded_at": datetime.now().isoformat(),
                    "total_categories": len(categories),
                    "stats": {
                        "db_loaded": self.stats.get("db_loaded", 0),
                        "file_loaded": len(categories),
                    },
                    "categories": serialized_categories,
                }

                with open(file_path, "w", encoding="utf-8", newline="\n") as f:
                    json.dump(output_data, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)

                self.stats["file_loaded"] = len(categories)
                logger.info(f"âœ… ÄÃ£ lÆ°u {len(categories)} categories vÃ o file: {save_to_file}")
            except Exception as e:
                error_msg = f"Lá»—i khi lÆ°u vÃ o file: {str(e)}"
                self.stats["errors"].append(error_msg)
                logger.error(f"âŒ {error_msg}")
                import traceback

                logger.debug(traceback.format_exc())

        # Update success count náº¿u chÆ°a cÃ³
        if self.stats["success_count"] == 0 and self.stats["file_loaded"] > 0:
            self.stats["success_count"] = self.stats["file_loaded"]

        return self.stats

    def get_stats(self) -> dict[str, Any]:
        """Láº¥y thá»‘ng kÃª load"""
        return self.stats.copy()

    def close(self):
        """ÄÃ³ng káº¿t ná»‘i database"""
        if self.db_storage:
            self.db_storage.close()
            logger.info("âœ… ÄÃ£ Ä‘Ã³ng káº¿t ná»‘i database")
