"""
Load pipeline Ä‘á»ƒ load dá»¯ liá»‡u Ä‘Ã£ transform vÃ o database
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)


class DateTimeEncoder(json.JSONEncoder):
    """JSON encoder Ä‘á»ƒ serialize datetime objects"""

    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)


def serialize_for_json(obj: Any) -> Any:
    """Recursively convert datetime objects to ISO format strings"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {key: serialize_for_json(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [serialize_for_json(item) for item in obj]
    else:
        return obj


# Import PostgresStorage tá»« crawl storage
try:
    from ...crawl.storage.postgres_storage import PostgresStorage
except ImportError:
    try:
        import sys
        from pathlib import Path

        # ThÃªm src vÃ o path
        src_path = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(src_path))
        from pipelines.crawl.storage.postgres_storage import PostgresStorage
    except ImportError:
        logger.warning("âš ï¸  KhÃ´ng thá»ƒ import PostgresStorage, chá»‰ há»— trá»£ load tá»« file")
        PostgresStorage = None


class DataLoader:
    """Class Ä‘á»ƒ load dá»¯ liá»‡u Ä‘Ã£ transform vÃ o database hoáº·c file"""

    def __init__(
        self,
        database: str | None = None,
        host: str | None = None,
        port: int = 5432,
        user: str | None = None,
        password: str | None = None,
        batch_size: int = 100,
        enable_db: bool = True,
    ):
        """
        Khá»Ÿi táº¡o DataLoader

        Args:
            database: Database name (máº·c Ä‘á»‹nh: crawl_data)
            host: PostgreSQL host
            port: PostgreSQL port
            user: PostgreSQL user
            password: PostgreSQL password
            batch_size: KÃ­ch thÆ°á»›c batch khi insert
            enable_db: CÃ³ enable database loading khÃ´ng
        """
        self.batch_size = batch_size
        self.enable_db = enable_db and PostgresStorage is not None
        self.stats = {
            "total_loaded": 0,
            "success_count": 0,
            "failed_count": 0,
            "db_loaded": 0,
            "file_loaded": 0,
            "errors": [],
        }

        # Khá»Ÿi táº¡o PostgresStorage náº¿u enable_db
        self.db_storage: PostgresStorage | None = None
        if self.enable_db:
            try:
                self.db_storage = PostgresStorage(
                    host=host,
                    port=port,
                    database=database or "crawl_data",
                    user=user,
                    password=password,
                )
                logger.info("âœ… ÄÃ£ káº¿t ná»‘i vá»›i PostgreSQL database")
            except Exception as e:
                logger.warning(f"âš ï¸  KhÃ´ng thá»ƒ káº¿t ná»‘i database: {e}")
                self.enable_db = False
                self.db_storage = None

    def load_products(
        self,
        products: list[dict[str, Any]],
        save_to_file: str | None = None,
        upsert: bool = True,
        validate_before_load: bool = True,
    ) -> dict[str, Any]:
        """
        Load danh sÃ¡ch products vÃ o database vÃ /hoáº·c file

        Args:
            products: Danh sÃ¡ch products Ä‘Ã£ transform
            save_to_file: ÄÆ°á»ng dáº«n file Ä‘á»ƒ lÆ°u (náº¿u cáº§n)
            upsert: Náº¿u True, update náº¿u Ä‘Ã£ tá»“n táº¡i
            validate_before_load: CÃ³ validate trÆ°á»›c khi load khÃ´ng

        Returns:
            Stats dictionary
        """
        self.stats = {
            "total_loaded": len(products),
            "success_count": 0,
            "failed_count": 0,
            "db_loaded": 0,
            "file_loaded": 0,
            "errors": [],
        }

        if not products:
            logger.warning("âš ï¸  Danh sÃ¡ch products rá»—ng")
            return self.stats

        # Validate trÆ°á»›c náº¿u cáº§n
        if validate_before_load:
            valid_products = []
            for product in products:
                # Kiá»ƒm tra required fields
                if not product.get("product_id") or not product.get("name"):
                    self.stats["failed_count"] += 1
                    self.stats["errors"].append(
                        f"Missing required fields: product_id={product.get('product_id')}"
                    )
                    continue
                valid_products.append(product)
            products = valid_products

        # Load vÃ o database
        if self.enable_db and self.db_storage:
            try:
                saved_count = self.db_storage.save_products(
                    products, upsert=upsert, batch_size=self.batch_size
                )
                self.stats["db_loaded"] = saved_count
                self.stats["success_count"] = saved_count
                logger.info(f"âœ… ÄÃ£ load {saved_count} products vÃ o database")
            except Exception as e:
                error_msg = f"Lá»—i khi load vÃ o database: {str(e)}"
                self.stats["errors"].append(error_msg)
                self.stats["failed_count"] += len(products)
                logger.error(f"âŒ {error_msg}")

        # Load vÃ o file náº¿u cáº§n
        if save_to_file:
            try:
                file_path = Path(save_to_file)
                file_path.parent.mkdir(parents=True, exist_ok=True)

                # Serialize datetime objects trong products trÆ°á»›c khi save
                serialized_products = serialize_for_json(products)

                # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u
                output_data = {
                    "loaded_at": datetime.now().isoformat(),
                    "total_products": len(products),
                    "stats": {
                        "db_loaded": self.stats.get("db_loaded", 0),
                        "file_loaded": len(products),
                    },
                    "products": serialized_products,
                }

                with open(file_path, "w", encoding="utf-8", newline="\n") as f:
                    json.dump(output_data, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)

                self.stats["file_loaded"] = len(products)
                logger.info(f"âœ… ÄÃ£ lÆ°u {len(products)} products vÃ o file: {save_to_file}")
            except Exception as e:
                error_msg = f"Lá»—i khi lÆ°u vÃ o file: {str(e)}"
                self.stats["errors"].append(error_msg)
                logger.error(f"âŒ {error_msg}")
                import traceback

                logger.debug(traceback.format_exc())

        # Update success count náº¿u chÆ°a cÃ³
        if self.stats["success_count"] == 0 and self.stats["file_loaded"] > 0:
            self.stats["success_count"] = self.stats["file_loaded"]

        return self.stats

    def load_from_file(
        self,
        input_file: str,
        save_to_db: bool = True,
        save_to_file: str | None = None,
        upsert: bool = True,
    ) -> dict[str, Any]:
        """
        Load products tá»« file JSON

        Args:
            input_file: ÄÆ°á»ng dáº«n file JSON input
            save_to_db: CÃ³ lÆ°u vÃ o database khÃ´ng
            save_to_file: ÄÆ°á»ng dáº«n file output (náº¿u cáº§n)
            upsert: Náº¿u True, update náº¿u Ä‘Ã£ tá»“n táº¡i

        Returns:
            Stats dictionary
        """
        file_path = Path(input_file)
        if not file_path.exists():
            error_msg = f"File khÃ´ng tá»“n táº¡i: {input_file}"
            self.stats["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
            return self.stats

        try:
            with open(file_path, encoding="utf-8") as f:
                data = json.load(f)

            # Extract products tá»« data
            # Há»— trá»£ nhiá»u format:
            # - {"products": [...]}
            # - {"data": {"products": [...]}}
            # - [...] (trá»±c tiáº¿p lÃ  list)
            products = []
            if isinstance(data, list):
                products = data
            elif isinstance(data, dict):
                if "products" in data:
                    products = data["products"]
                elif "data" in data and isinstance(data["data"], dict):
                    products = data["data"].get("products", [])

            if not products:
                logger.warning("âš ï¸  KhÃ´ng tÃ¬m tháº¥y products trong file")
                return self.stats

            logger.info(f"ğŸ“‚ ÄÃ£ load {len(products)} products tá»« file: {input_file}")

            # Load vÃ o database vÃ /hoáº·c file
            return self.load_products(
                products,
                save_to_file=save_to_file,
                upsert=upsert,
                validate_before_load=True,
            )

        except json.JSONDecodeError as e:
            error_msg = f"Lá»—i parse JSON: {str(e)}"
            self.stats["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
            return self.stats
        except Exception as e:
            error_msg = f"Lá»—i khi load tá»« file: {str(e)}"
            self.stats["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
            return self.stats

    def get_stats(self) -> dict[str, Any]:
        """Láº¥y thá»‘ng kÃª load"""
        return self.stats.copy()

    def close(self):
        """ÄÃ³ng káº¿t ná»‘i database"""
        if self.db_storage:
            self.db_storage.close()
            logger.info("âœ… ÄÃ£ Ä‘Ã³ng káº¿t ná»‘i database")
