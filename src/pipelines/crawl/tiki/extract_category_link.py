
import os
import sys
import re
import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse

# Fix encoding on Windows
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


# Cáº¥u hÃ¬nh
FIRECRAWL_API_URL = os.getenv("FIRECRAWL_API_URL", "http://localhost:3002")
TIKI_BASE_URL = "https://tiki.vn"


def extract_category_id(url):
    """Extract category ID tá»« URL (pattern: /c1234)"""
    match = re.search(r'/c(\d+)', url)
    return match.group(1) if match else None


def extract_categories_from_markdown(markdown_text):
    """
    Extract category links tá»« markdown text
    Returns: List of dicts vá»›i 'name', 'url', 'category_id'
    """
    categories = []
    
    # Pattern Ä‘á»ƒ tÃ¬m markdown links: [text](url)
    link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    matches = re.findall(link_pattern, markdown_text)
    
    for name, url in matches:
        # Filter chá»‰ láº¥y links tá»« tiki.vn vÃ  cÃ³ chá»©a "danh-muc" hoáº·c category
        if 'tiki.vn' in url or url.startswith('/'):
            # Normalize URL
            if url.startswith('/'):
                full_url = urljoin(TIKI_BASE_URL, url)
            else:
                full_url = url
            
            # Check náº¿u lÃ  category link - chá»‰ láº¥y links cÃ³ pattern /cXXXX
            # Pattern: /c1234 (category ID)
            category_id = extract_category_id(url)
            is_category = category_id is not None
            
            # Exclude non-category links
            exclude_keywords = [
                'search?', 'checkout', 'cart', 'hotro', 'mailto:', 
                'javascript:', 'data:', 'account', 'login', 'register',
                'help', 'about', 'contact', 'policy', 'terms'
            ]
            is_excluded = any(kw in url.lower() for kw in exclude_keywords)
            
            # Exclude náº¿u khÃ´ng cÃ³ category ID
            if is_category and not is_excluded:
                categories.append({
                    'name': name.strip(),
                    'url': full_url,
                    'category_id': category_id,
                    'slug': url.split('/')[-1].split('?')[0]  # Extract slug
                })
    
    return categories


def extract_categories_from_html(html_text):
    """
    Extract category links tá»« HTML (náº¿u cÃ³ trong response)
    """
    categories = []
    soup = BeautifulSoup(html_text, 'html.parser')
    
    # TÃ¬m táº¥t cáº£ links
    links = soup.find_all('a', href=True)
    
    for link in links:
        href = link.get('href', '')
        text = link.get_text(strip=True)
        
        # Filter category links - chá»‰ láº¥y links cÃ³ pattern /cXXXX
        if href and ('tiki.vn' in href or href.startswith('/')):
            # Check category pattern - chá»‰ láº¥y /cXXXX
            category_id = extract_category_id(href)
            is_category = category_id is not None
            
            # Exclude non-category links
            exclude_keywords = [
                'search?', 'checkout', 'cart', 'hotro', 'mailto:', 
                'javascript:', 'data:', 'account', 'login', 'register'
            ]
            is_excluded = any(kw in href.lower() for kw in exclude_keywords)
            
            if is_category and not is_excluded:
                if href.startswith('/'):
                    full_url = urljoin(TIKI_BASE_URL, href)
                else:
                    full_url = href
                
                categories.append({
                    'name': text or href,
                    'url': full_url,
                    'category_id': category_id,
                    'slug': href.split('/')[-1].split('?')[0]
                })
    
    return categories


def parse_firecrawl_response(response_data):
    """
    Parse response tá»« Firecrawl vÃ  extract categories
    """
    categories = []
    
    # Check náº¿u cÃ³ markdown
    if 'data' in response_data and 'markdown' in response_data['data']:
        markdown = response_data['data']['markdown']
        categories.extend(extract_categories_from_markdown(markdown))
    
    # Check náº¿u cÃ³ HTML
    if 'data' in response_data and 'html' in response_data['data']:
        html = response_data['data']['html']
        categories.extend(extract_categories_from_html(html))
    
    # Remove duplicates - Æ°u tiÃªn theo category_id vÃ  URL
    seen_urls = set()
    seen_ids = set()
    unique_categories = []
    
    for cat in categories:
        url = cat['url']
        cat_id = cat.get('category_id')
        
        # Remove query params Ä‘á»ƒ so sÃ¡nh
        clean_url = url.split('?')[0]
        
        # Check duplicate by URL hoáº·c category_id
        is_duplicate = (
            clean_url in seen_urls or 
            (cat_id and cat_id in seen_ids)
        )
        
        if not is_duplicate:
            seen_urls.add(clean_url)
            if cat_id:
                seen_ids.add(cat_id)
            unique_categories.append(cat)
    
    # Sort by category_id Ä‘á»ƒ dá»… Ä‘á»c
    unique_categories.sort(key=lambda x: int(x.get('category_id', 0)) if x.get('category_id') else 999999)
    
    return unique_categories


def crawl_sub_categories(category_url, parent_category_id=None, parent_name=None):
    """
    Crawl sub-categories tá»« má»™t category URL
    
    Args:
        category_url: URL cá»§a category cáº§n crawl sub-categories
        parent_category_id: ID cá»§a category cha (náº¿u cÃ³)
        parent_name: TÃªn cá»§a category cha (náº¿u cÃ³)
    
    Returns:
        List of sub-categories vá»›i parent_id
    """
    payload = {
        "url": category_url,
        "onlyMainContent": True,
        "maxAge": 172800000,
        "parsers": [],
        "formats": ["html"]
    }
    
    url = f"{FIRECRAWL_API_URL}/v2/scrape"
    
    try:
        response = requests.post(url, json=payload, timeout=60)
        response.raise_for_status()
        
        data = response.json()
        sub_categories = parse_firecrawl_response(data)
        
        # ThÃªm parent_id vÃ  parent_name vÃ o má»—i sub-category
        for sub_cat in sub_categories:
            sub_cat['parent_id'] = parent_category_id
            sub_cat['parent_name'] = parent_name
            sub_cat['parent_url'] = category_url
        
        return sub_categories
        
    except requests.exceptions.RequestException as e:
        print(f"  âš ï¸  Lá»—i khi crawl {category_url}: {e}")
        return []
    except Exception as e:
        print(f"  âš ï¸  Lá»—i: {e}")
        return []


def load_categories_from_json(json_file):
    """
    Load categories tá»« file JSON
    """
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸  File khÃ´ng tá»“n táº¡i: {json_file}")
        return []
    except json.JSONDecodeError as e:
        print(f"âš ï¸  Lá»—i khi parse JSON: {e}")
        return []


def build_hierarchical_structure(categories):
    """
    Chuyá»ƒn Ä‘á»•i danh sÃ¡ch pháº³ng categories sang cáº¥u trÃºc phÃ¢n cáº¥p (hierarchical)
    
    Thuáº­t toÃ¡n:
    1. Táº¡o dict Ä‘á»ƒ tra cá»©u nhanh cÃ¡c categories
    2. ÄÃ¡nh dáº¥u root categories (parent_id = None)
    3. XÃ¢y dá»±ng quan há»‡ parent-child
    4. Kiá»ƒm tra vÃ  loáº¡i bá» circular references
    5. Sáº¯p xáº¿p theo category_id
    
    Args:
        categories: List cÃ¡c categories vá»›i parent_id
    
    Returns:
        List cÃ¡c categories á»Ÿ level 1 vá»›i sub_categories Ä‘Æ°á»£c lá»“ng bÃªn trong
    """
    if not categories:
        return []
    
    # ===== BÆ¯á»šC 0: REMOVE DUPLICATES =====
    # Giá»¯ láº¡i TOÃ€N Bá»˜ dá»¯ liá»‡u, chá»‰ remove duplicates
    seen_ids = set()
    unique_categories = []
    duplicates_removed = 0
    skipped_no_id = 0
    
    for cat in categories:
        cat_id = cat.get('category_id')
        
        # Categories khÃ´ng cÃ³ category_id - váº«n giá»¯ láº¡i nhÆ°ng track
        if not cat_id:
            skipped_no_id += 1
            unique_categories.append(cat)  # Keep it for manual review
            continue
        
        # Duplicate - skip
        if cat_id in seen_ids:
            duplicates_removed += 1
            continue
        
        seen_ids.add(cat_id)
        unique_categories.append(cat)
    
    if duplicates_removed > 0:
        print(f"  âš ï¸  Removed {duplicates_removed} duplicate categories (kept latest)")
    if skipped_no_id > 0:
        print(f"  âš ï¸  Found {skipped_no_id} categories without category_id (kept for review)")
    
    categories = unique_categories
    
    # ===== BÆ¯á»šC 1: CHUáº¨N Bá»Š Dá»® LIá»†U =====
    categories_dict = {}
    root_category_ids = set()
    parent_child_map = {}  # {parent_id: [child_ids]}
    issues = {'circular_refs': [], 'orphaned': [], 'missing_parents': []}
    
    # Táº¡o dictionary lookup vÃ  initialize
    for cat in categories:
        cat_id = cat.get('category_id')
        if not cat_id:
            continue
        
        cat_copy = cat.copy()
        cat_copy['sub_categories'] = []
        categories_dict[cat_id] = cat_copy
        
        parent_id = cat.get('parent_id')
        
        # XÃ¡c Ä‘á»‹nh root categories (khÃ´ng cÃ³ parent)
        if not parent_id:
            root_category_ids.add(cat_id)
        else:
            # Track parent-child relationship
            if parent_id not in parent_child_map:
                parent_child_map[parent_id] = []
            parent_child_map[parent_id].append(cat_id)
    
    # ===== BÆ¯á»šC 2: Xá»¬ LÃ CIRCULAR REFERENCES =====
    def has_circular_reference(parent_id, child_id, visited=None, max_depth=50):
        """Kiá»ƒm tra náº¿u thÃªm child vÃ o parent sáº½ táº¡o circular reference"""
        if visited is None:
            visited = set()
        
        if parent_id == child_id:
            return True
        
        if parent_id in visited or len(visited) >= max_depth:
            return False
        
        visited.add(parent_id)
        
        # TÃ¬m parent cá»§a parent_id hiá»‡n táº¡i
        if parent_id in categories_dict:
            parent_of_parent = categories_dict[parent_id].get('parent_id')
            if parent_of_parent and parent_of_parent == child_id:
                return True
            if parent_of_parent:
                return has_circular_reference(parent_of_parent, child_id, visited.copy(), max_depth)
        
        return False
    
    # Validate vÃ  GIá»® Láº I táº¥t cáº£ categories há»£p lá»‡
    validated_categories = []
    rejected_categories = []
    
    for cat in categories:
        cat_id = cat.get('category_id')
        parent_id = cat.get('parent_id')
        
        # Categories khÃ´ng cÃ³ category_id - giá»¯ láº¡i vá»›i warning
        if not cat_id:
            issues['orphaned'].append(f"No category_id: {cat}")
            validated_categories.append(cat)  # Keep it
            continue
        
        # Self-references - REJECT (khÃ´ng thá»ƒ fix)
        if parent_id == cat_id:
            issues['circular_refs'].append(f"Self-reference: {cat_id} -> {cat_id}")
            rejected_categories.append((cat, f"Self-reference: {cat_id}"))
            continue
        
        # Circular references - REJECT (khÃ´ng thá»ƒ fix)
        if parent_id and has_circular_reference(parent_id, cat_id):
            issues['circular_refs'].append(f"Circular: {parent_id} <-> {cat_id}")
            rejected_categories.append((cat, f"Circular ref with {parent_id}"))
            continue
        
        # Missing parent - KEEP NHÆ¯ ROOT (cÃ³ thá»ƒ fix báº±ng cÃ¡ch treat as root)
        if parent_id and parent_id not in categories_dict:
            issues['missing_parents'].append(f"Missing parent {parent_id} for {cat_id}, treating as root")
            cat_copy = cat.copy()
            cat_copy['parent_id'] = None
            cat_copy['parent_name'] = None
            cat_copy['parent_url'] = None
            cat_copy['sub_categories'] = []
            validated_categories.append(cat_copy)
            root_category_ids.add(cat_id)
        else:
            # All other valid categories
            validated_categories.append(cat)
    
    # ===== BÆ¯á»šC 3: XÃ‚Y Dá»°NG QUAN Há»† PARENT-CHILD =====
    categories_dict = {}
    orphaned_categories = []  # Track categories without ID
    
    for cat in validated_categories:
        cat_id = cat.get('category_id')
        if cat_id:
            cat_copy = cat.copy()
            cat_copy['sub_categories'] = []
            categories_dict[cat_id] = cat_copy
        else:
            # Keep track of categories without ID (orphaned)
            orphaned_categories.append(cat)
    
    # XÃ¢y dá»±ng parent-child relationships - GIá»® Láº I toÃ n bá»™ dá»¯ liá»‡u há»£p lá»‡
    for cat in validated_categories:
        cat_id = cat.get('category_id')
        parent_id = cat.get('parent_id')
        
        # Skip chá»‰ náº¿u khÃ´ng cÃ³ cat_id hoáº·c khÃ´ng cÃ³ parent_id (lÃ  root)
        if not cat_id:
            continue  # KhÃ´ng thá»ƒ xá»­ lÃ½, bá» qua
        
        if not parent_id:
            continue  # LÃ  root, Ä‘Ã£ xá»­ lÃ½ á»Ÿ bÆ°á»›c 1
        
        # ThÃªm cat vÃ o sub_categories cá»§a parent
        if cat_id in categories_dict and parent_id in categories_dict:
            # Check xem Ä‘Ã£ cÃ³ chÆ°a Ä‘á»ƒ trÃ¡nh duplicate
            existing_ids = {sc.get('category_id') for sc in categories_dict[parent_id]['sub_categories']}
            if cat_id not in existing_ids:
                categories_dict[parent_id]['sub_categories'].append(categories_dict[cat_id])
        elif cat_id in categories_dict and parent_id not in categories_dict:
            # Parent khÃ´ng tá»“n táº¡i nhÆ°ng category cÃ³ ID - Ä‘Ã£ Ä‘Æ°á»£c treat as root á»Ÿ bÆ°á»›c trÆ°á»›c
            pass  # OK, Ä‘Ã£ xá»­ lÃ½
    
    # ===== BÆ¯á»šC 4: EXTRACT ROOT CATEGORIES =====
    root_categories = []
    for cat_id in root_category_ids:
        if cat_id in categories_dict:
            root_categories.append(categories_dict[cat_id])
    
    # ThÃªm orphaned categories (khÃ´ng cÃ³ category_id) vÃ o root
    # Ä‘á»ƒ khÃ´ng máº¥t dá»¯ liá»‡u
    for orphan in orphaned_categories:
        orphan_copy = orphan.copy()
        orphan_copy['sub_categories'] = []
        root_categories.append(orphan_copy)
    
    # ===== BÆ¯á»šC 5: Sáº®P Xáº¾P =====
    def get_sort_key(cat):
        """Extract sort key tá»« category_id"""
        try:
            return int(cat.get('category_id', 999999))
        except (ValueError, TypeError):
            return 999999
    
    def sort_tree(cats, max_depth=100, current_depth=0):
        """Sáº¯p xáº¿p cÃ¢y categories recursively"""
        if current_depth >= max_depth or not cats:
            return
        
        # Sáº¯p xáº¿p list hiá»‡n táº¡i
        cats.sort(key=get_sort_key)
        
        # Äá»‡ quy sáº¯p xáº¿p sub_categories
        for cat in cats:
            if 'sub_categories' in cat and cat['sub_categories']:
                sort_tree(cat['sub_categories'], max_depth, current_depth + 1)
    
    sort_tree(root_categories)
    
    # ===== BÆ¯á»šC 6: REPORT =====
    if issues['circular_refs'] or issues['missing_parents'] or issues['orphaned']:
        print("\nâš ï¸  Issues found during hierarchy building:")
        if issues['circular_refs']:
            for issue in issues['circular_refs'][:5]:
                print(f"  - Circular ref: {issue}")
            if len(issues['circular_refs']) > 5:
                print(f"  ... and {len(issues['circular_refs']) - 5} more")
        
        if issues['missing_parents']:
            print(f"  - Missing parents: {len(issues['missing_parents'])} categories")
        
        if issues['orphaned']:
            print(f"  - Orphaned: {len(issues['orphaned'])} categories")
    
    return root_categories




def validate_hierarchical_structure(hierarchical_categories, all_categories):
    """
    Validate cáº¥u trÃºc phÃ¢n cáº¥p - kiá»ƒm tra:
    1. Táº¥t cáº£ categories Ä‘á»u Ä‘Æ°á»£c bao gá»“m
    2. KhÃ´ng cÃ³ duplicate (cÃ¹ng category_id xuáº¥t hiá»‡n 2 láº§n)
    3. parent_id vÃ  category_id Ä‘Ãºng match
    4. KhÃ´ng cÃ³ circular references
    
    Args:
        hierarchical_categories: Cáº¥u trÃºc phÃ¢n cáº¥p Ä‘Ã£ build
        all_categories: Danh sÃ¡ch táº¥t cáº£ categories ban Ä‘áº§u
    
    Returns:
        dict: {
            'is_valid': bool,
            'stats': {...},
            'errors': [...]
        }
    """
    errors = []
    collected_ids = set()
    collected_categories = []
    
    def collect_all(cats):
        """Collect all categories from hierarchical structure"""
        for cat in cats:
            cat_id = cat.get('category_id')
            if cat_id:
                if cat_id in collected_ids:
                    errors.append(f"Duplicate category_id found: {cat_id}")
                else:
                    collected_ids.add(cat_id)
                    collected_categories.append(cat)
            
            # Äá»‡ quy collect sub_categories
            if cat.get('sub_categories'):
                collect_all(cat['sub_categories'])
    
    collect_all(hierarchical_categories)
    
    # Kiá»ƒm tra xem cÃ³ categories bá»‹ máº¥t khÃ´ng
    original_ids = {cat.get('category_id') for cat in all_categories if cat.get('category_id')}
    missing_ids = original_ids - collected_ids
    
    if missing_ids:
        errors.append(f"Missing {len(missing_ids)} categories in hierarchy")
        # Show first 5
        for cat_id in list(missing_ids)[:5]:
            errors.append(f"  - Missing: {cat_id}")
        if len(missing_ids) > 5:
            errors.append(f"  ... and {len(missing_ids) - 5} more")
    
    # Kiá»ƒm tra parent_id Ä‘Ãºng match
    for cat in collected_categories:
        cat_id = cat.get('category_id')
        for sub_cat in cat.get('sub_categories', []):
            sub_id = sub_cat.get('category_id')
            sub_parent_id = sub_cat.get('parent_id')
            
            # Náº¿u parent_id trong sub_cat khÃ¡c vá»›i parent (category hiá»‡n táº¡i), warning
            if sub_parent_id and str(sub_parent_id) != str(cat_id):
                errors.append(f"Mismatch parent_id: {sub_id} has parent_id={sub_parent_id} but is under {cat_id}")
    
    # Kiá»ƒm tra circular references
    def check_circular(cat, path=None):
        """Check for circular references in tree"""
        if path is None:
            path = []
        
        cat_id = cat.get('category_id')
        if cat_id in path:
            errors.append(f"Circular reference detected: {' -> '.join(path)} -> {cat_id}")
            return
        
        new_path = path + [cat_id]
        for sub_cat in cat.get('sub_categories', []):
            check_circular(sub_cat, new_path)
    
    for root_cat in hierarchical_categories:
        check_circular(root_cat)
    
    # Stats
    stats = {
        'total_collected': len(collected_ids),
        'total_original': len(original_ids),
        'total_missing': len(missing_ids),
        'total_root': len(hierarchical_categories),
        'max_depth': _get_max_depth(hierarchical_categories),
        'total_errors': len(errors)
    }
    
    return {
        'is_valid': len(errors) == 0,
        'stats': stats,
        'errors': errors
    }


def _get_max_depth(cats, current_depth=1):
    """Get maximum depth of hierarchical structure"""
    if not cats:
        return current_depth - 1
    
    max_depth = current_depth
    for cat in cats:
        if cat.get('sub_categories'):
            depth = _get_max_depth(cat['sub_categories'], current_depth + 1)
            max_depth = max(max_depth, depth)
    
    return max_depth


def create_merged_categories_file():
    """
    Táº¡o file JSON há»£p nháº¥t vá»›i cáº¥u trÃºc phÃ¢n cáº¥p tá»« táº¥t cáº£ cÃ¡c file categories
    """
    print("=" * 60)
    print("Táº¡o file JSON há»£p nháº¥t vá»›i cáº¥u trÃºc phÃ¢n cáº¥p...")
    print("=" * 60)
    
    # Load táº¥t cáº£ categories tá»« file all_categories
    all_categories_file = "data/raw/tiki_all_categories.json"
    
    if not os.path.exists(all_categories_file):
        print(f"âš ï¸  File khÃ´ng tá»“n táº¡i: {all_categories_file}")
        print("   Äang thá»­ há»£p nháº¥t tá»« cÃ¡c file riÃªng láº»...")
        
        # Thá»­ há»£p nháº¥t tá»« cÃ¡c file riÃªng láº»
        all_categories = []
        
        # Load level 1
        categories_file = "data/raw/tiki_categories.json"
        if os.path.exists(categories_file):
            parent_cats = load_categories_from_json(categories_file)
            for cat in parent_cats:
                cat_copy = cat.copy()
                cat_copy['parent_id'] = None
                cat_copy['parent_name'] = None
                cat_copy['parent_url'] = None
                all_categories.append(cat_copy)
        
        # Load level 2
        sub_categories_file = "data/raw/tiki_sub_categories.json"
        if os.path.exists(sub_categories_file):
            level2_cats = load_categories_from_json(sub_categories_file)
            all_categories.extend(level2_cats)
        
        # Load level 3
        level3_file = "data/raw/tiki_sub_categories_level3.json"
        if os.path.exists(level3_file):
            level3_cats = load_categories_from_json(level3_file)
            all_categories.extend(level3_cats)
        
        if not all_categories:
            print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y file categories nÃ o Ä‘á»ƒ há»£p nháº¥t")
            return None
    else:
        all_categories = load_categories_from_json(all_categories_file)
    
    print(f"\n[1] ÄÃ£ load {len(all_categories)} categories")
    
    # XÃ¢y dá»±ng cáº¥u trÃºc phÃ¢n cáº¥p
    print("[2] Äang xÃ¢y dá»±ng cáº¥u trÃºc phÃ¢n cáº¥p...")
    hierarchical_categories = build_hierarchical_structure(all_categories)
    
    print(f"[3] ÄÃ£ táº¡o cáº¥u trÃºc phÃ¢n cáº¥p vá»›i {len(hierarchical_categories)} root categories")
    
    # Validate cáº¥u trÃºc phÃ¢n cáº¥p
    print("[4] Äang validate cáº¥u trÃºc phÃ¢n cáº¥p...")
    validation_result = validate_hierarchical_structure(hierarchical_categories, all_categories)
    
    print(f"\nğŸ“Š Validation Results:")
    print(f"    - Valid: {validation_result['is_valid']}")
    print(f"    - Total collected: {validation_result['stats']['total_collected']}")
    print(f"    - Total original: {validation_result['stats']['total_original']}")
    print(f"    - Missing: {validation_result['stats']['total_missing']}")
    print(f"    - Root categories: {validation_result['stats']['total_root']}")
    print(f"    - Max depth: {validation_result['stats']['max_depth']}")
    print(f"    - Errors: {validation_result['stats']['total_errors']}")
    
    if validation_result['errors']:
        print(f"\nâš ï¸  Issues found:")
        for error in validation_result['errors'][:10]:
            print(f"    - {error}")
        if len(validation_result['errors']) > 10:
            print(f"    ... and {len(validation_result['errors']) - 10} more")
    
    # LÆ°u file há»£p nháº¥t
    merged_file = "data/raw/tiki_categories_merged.json"
    os.makedirs(os.path.dirname(merged_file), exist_ok=True)
    
    with open(merged_file, 'w', encoding='utf-8') as f:
        json.dump(hierarchical_categories, f, indent=2, ensure_ascii=False)
    
    print(f"\n[5] ÄÃ£ lÆ°u file há»£p nháº¥t vÃ o: {merged_file}")
    
    return merged_file


def crawl_categories_recursive(
    categories, 
    visited_ids=None, 
    max_depth=10, 
    current_depth=0,
    max_categories_per_level=None,
    stats=None
):
    """
    Crawl sub-categories Ä‘á»‡ quy Ä‘á»ƒ crawl táº¥t cáº£ cÃ¡c level
    
    Args:
        categories: List cÃ¡c categories cáº§n crawl sub-categories
        visited_ids: Set cÃ¡c category_id Ä‘Ã£ crawl (Ä‘á»ƒ trÃ¡nh duplicate)
        max_depth: Äá»™ sÃ¢u tá»‘i Ä‘a Ä‘á»ƒ crawl (None = khÃ´ng giá»›i háº¡n)
        current_depth: Äá»™ sÃ¢u hiá»‡n táº¡i
        max_categories_per_level: Giá»›i háº¡n sá»‘ categories má»—i level (None = táº¥t cáº£)
        stats: Dict Ä‘á»ƒ track statistics
    
    Returns:
        List táº¥t cáº£ sub-categories vá»›i parent_id vÃ  level info
    """
    if visited_ids is None:
        visited_ids = set()
    
    if stats is None:
        stats = {
            'total_crawled': 0,
            'total_found': 0,
            'by_level': {},
            'errors': 0
        }
    
    all_sub_categories = []
    
    # Giá»›i háº¡n sá»‘ lÆ°á»£ng categories náº¿u cáº§n
    categories_to_crawl = categories
    if max_categories_per_level:
        categories_to_crawl = categories[:max_categories_per_level]
    
    total = len(categories_to_crawl)
    level_indicator = "  " * current_depth + "â”‚" if current_depth > 0 else ""
    
    if current_depth == 0:
        print(f"\n[Level {current_depth}] Äang crawl {total} root categories...")
    else:
        print(f"\n{level_indicator}[Level {current_depth}] Äang crawl {total} categories...")
    
    for i, cat in enumerate(categories_to_crawl, 1):
        cat_id = cat.get('category_id')
        cat_name = cat.get('name', 'N/A')
        cat_url = cat.get('url', '')
        parent_id = cat.get('parent_id')
        parent_name = cat.get('parent_name', '')
        
        # Skip náº¿u Ä‘Ã£ crawl rá»“i
        if cat_id and cat_id in visited_ids:
            continue
        
        # Skip náº¿u cÃ³ circular reference
        if parent_id and parent_id == cat_id:
            continue
        
        # Kiá»ƒm tra max depth
        if max_depth is not None and current_depth >= max_depth:
            if current_depth == max_depth:
                print(f"{level_indicator}âš ï¸  Äáº¡t Ä‘á»™ sÃ¢u tá»‘i Ä‘a {max_depth}, dá»«ng crawl sÃ¢u hÆ¡n")
            continue
        
        stats['total_crawled'] += 1
        
        # Hiá»ƒn thá»‹ progress
        indent = "  " * current_depth
        print(f"{indent}[{i}/{total}] ğŸ“‚ {cat_name} (ID: {cat_id}, Level: {current_depth})")
        
        try:
            # Crawl sub-categories cá»§a category nÃ y
            sub_cats = crawl_sub_categories(
                category_url=cat_url,
                parent_category_id=cat_id,
                parent_name=cat_name
            )
            
            # ÄÃ¡nh dáº¥u Ä‘Ã£ crawl
            if cat_id:
                visited_ids.add(cat_id)
            
            if sub_cats:
                # Filter bá» circular references vÃ  duplicates
                valid_sub_cats = []
                for sub_cat in sub_cats:
                    sub_cat_id = sub_cat.get('category_id')
                    
                    # Skip náº¿u lÃ  self-reference
                    if sub_cat_id == cat_id:
                        continue
                    
                    # Skip náº¿u Ä‘Ã£ crawl rá»“i
                    if sub_cat_id and sub_cat_id in visited_ids:
                        continue
                    
                    # ThÃªm level info
                    sub_cat['level'] = current_depth + 1
                    valid_sub_cats.append(sub_cat)
                
                if valid_sub_cats:
                    print(f"{indent}   âœ“ TÃ¬m tháº¥y {len(valid_sub_cats)} sub-categories")
                    all_sub_categories.extend(valid_sub_cats)
                    stats['total_found'] += len(valid_sub_cats)
                    
                    # Track by level
                    level_key = f"level_{current_depth + 1}"
                    if level_key not in stats['by_level']:
                        stats['by_level'][level_key] = 0
                    stats['by_level'][level_key] += len(valid_sub_cats)
                    
                    # Crawl Ä‘á»‡ quy sub-categories
                    if current_depth + 1 < (max_depth if max_depth else 999):
                        deeper_cats = crawl_categories_recursive(
                            valid_sub_cats,
                            visited_ids=visited_ids,
                            max_depth=max_depth,
                            current_depth=current_depth + 1,
                            max_categories_per_level=max_categories_per_level,
                            stats=stats
                        )
                        all_sub_categories.extend(deeper_cats)
                else:
                    print(f"{indent}   - KhÃ´ng cÃ³ sub-categories há»£p lá»‡ (cÃ³ thá»ƒ do duplicate/circular)")
            else:
                print(f"{indent}   - KhÃ´ng tÃ¬m tháº¥y sub-categories")
                
        except Exception as e:
            stats['errors'] += 1
            print(f"{indent}   âœ— Lá»—i: {e}")
            continue
    
    return all_sub_categories


def crawl_all_sub_categories(categories, max_categories=None, recursive=True, max_depth=10):
    """
    Crawl sub-categories tá»« táº¥t cáº£ cÃ¡c categories
    
    Args:
        categories: List cÃ¡c categories cáº§n crawl sub-categories
        max_categories: Giá»›i háº¡n sá»‘ lÆ°á»£ng categories Ä‘á»ƒ crawl (None = táº¥t cáº£)
        recursive: Náº¿u True, crawl Ä‘á»‡ quy táº¥t cáº£ cÃ¡c level. Náº¿u False, chá»‰ crawl 1 level
        max_depth: Äá»™ sÃ¢u tá»‘i Ä‘a khi recursive=True
    
    Returns:
        List táº¥t cáº£ sub-categories vá»›i parent_id
    """
    if recursive:
        # Crawl Ä‘á»‡ quy táº¥t cáº£ cÃ¡c level
        print(f"\n[5] Äang crawl sub-categories Ä‘á»‡ quy tá»« {len(categories)} categories...")
        print(f"    Max depth: {max_depth if max_depth else 'unlimited'}")
        print("-" * 60)
        
        stats = {
            'total_crawled': 0,
            'total_found': 0,
            'by_level': {},
            'errors': 0
        }
        
        all_sub_categories = crawl_categories_recursive(
            categories,
            max_depth=max_depth,
            max_categories_per_level=max_categories,
            stats=stats
        )
        
        # Remove duplicates dá»±a trÃªn category_id
        seen_ids = set()
        unique_sub_categories = []
        
        for sub_cat in all_sub_categories:
            cat_id = sub_cat.get('category_id')
            if cat_id and cat_id not in seen_ids:
                seen_ids.add(cat_id)
                unique_sub_categories.append(sub_cat)
        
        print(f"\n[6] Thá»‘ng kÃª crawl:")
        print(f"    - Tá»•ng categories Ä‘Ã£ crawl: {stats['total_crawled']}")
        print(f"    - Tá»•ng sub-categories tÃ¬m tháº¥y: {stats['total_found']}")
        print(f"    - Unique sub-categories: {len(unique_sub_categories)}")
        print(f"    - Lá»—i: {stats['errors']}")
        if stats['by_level']:
            print(f"    - PhÃ¢n bá»‘ theo level:")
            for level, count in sorted(stats['by_level'].items()):
                print(f"      {level}: {count} categories")
        
        return unique_sub_categories
    else:
        # Chá»‰ crawl 1 level (giá»¯ nguyÃªn logic cÅ©)
        all_sub_categories = []
        total = len(categories) if max_categories is None else min(max_categories, len(categories))
        
        print(f"\n[5] Äang crawl sub-categories tá»« {total} categories (1 level)...")
        print("-" * 60)
        
        for i, cat in enumerate(categories[:total], 1):
            cat_name = cat.get('name', 'N/A')
            cat_url = cat.get('url', '')
            cat_id = cat.get('category_id', '')
            
            print(f"\n[{i}/{total}] Äang crawl sub-categories cá»§a: {cat_name}")
            print(f"   URL: {cat_url}")
            
            sub_cats = crawl_sub_categories(
                category_url=cat_url,
                parent_category_id=cat_id,
                parent_name=cat_name
            )
            
            if sub_cats:
                print(f"   âœ“ TÃ¬m tháº¥y {len(sub_cats)} sub-categories")
                all_sub_categories.extend(sub_cats)
            else:
                print(f"   - KhÃ´ng tÃ¬m tháº¥y sub-categories")
        
        # Remove duplicates dá»±a trÃªn category_id
        seen_ids = set()
        unique_sub_categories = []
        
        for sub_cat in all_sub_categories:
            cat_id = sub_cat.get('category_id')
            if cat_id and cat_id not in seen_ids:
                seen_ids.add(cat_id)
                unique_sub_categories.append(sub_cat)
        
        print(f"\n[6] Tá»•ng cá»™ng tÃ¬m tháº¥y {len(unique_sub_categories)} unique sub-categories")
        
        return unique_sub_categories


def crawl_deep_sub_categories_from_file(sub_categories_file, max_categories=None, exclude_self_ref=True):
    """
    Crawl tiáº¿p cÃ¡c sub-categories tá»« file sub_categories Ä‘Ã£ cÃ³
    
    Args:
        sub_categories_file: ÄÆ°á»ng dáº«n Ä‘áº¿n file sub_categories.json
        max_categories: Giá»›i háº¡n sá»‘ lÆ°á»£ng categories Ä‘á»ƒ crawl (None = táº¥t cáº£)
        exclude_self_ref: Loáº¡i bá» cÃ¡c category cÃ³ parent_id trÃ¹ng vá»›i category_id (self-reference)
    
    Returns:
        List cÃ¡c sub-categories level tiáº¿p theo
    """
    print("=" * 60)
    print("Crawling deep sub-categories tá»« file...")
    print("=" * 60)
    
    # Load sub-categories tá»« file
    sub_categories = load_categories_from_json(sub_categories_file)
    
    if not sub_categories:
        print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y sub-categories trong file")
        return []
    
    print(f"\n[0] ÄÃ£ load {len(sub_categories)} sub-categories tá»« file")
    
    # Lá»c bá» cÃ¡c self-reference (category cÃ³ parent_id == category_id)
    if exclude_self_ref:
        filtered_categories = []
        for cat in sub_categories:
            cat_id = cat.get('category_id')
            parent_id = cat.get('parent_id')
            # Loáº¡i bá» náº¿u parent_id == category_id (self-reference)
            if cat_id and parent_id and cat_id != parent_id:
                filtered_categories.append(cat)
            elif not parent_id or not cat_id:
                filtered_categories.append(cat)
        
        print(f"[1] Sau khi lá»c self-reference: {len(filtered_categories)} categories")
        sub_categories = filtered_categories
    
    # Crawl tiáº¿p tá»« cÃ¡c sub-categories
    deep_sub_categories = crawl_all_sub_categories(sub_categories, max_categories)
    
    return deep_sub_categories


def main():
    """Main function Ä‘á»ƒ crawl vÃ  extract categories"""
    
    print("=" * 60)
    print("Crawling Tiki.vn vÃ  extract category links...")
    print("=" * 60)
    
    # Kiá»ƒm tra xem cÃ³ file sub_categories chÆ°a Ä‘á»ƒ crawl tiáº¿p
    sub_categories_file = "data/raw/tiki_sub_categories.json"
    
    if os.path.exists(sub_categories_file):
        print("\n[INFO] TÃ¬m tháº¥y file sub_categories, Ä‘ang crawl tiáº¿p level 3...")
        
        # Crawl tiáº¿p tá»« sub_categories
        deep_sub_categories = crawl_deep_sub_categories_from_file(
            sub_categories_file,
            max_categories=None,  # Crawl táº¥t cáº£
            exclude_self_ref=True
        )
        
        if deep_sub_categories:
            # LÆ°u deep sub-categories
            deep_sub_categories_file = "data/raw/tiki_sub_categories_level3.json"
            os.makedirs(os.path.dirname(deep_sub_categories_file), exist_ok=True)
            
            with open(deep_sub_categories_file, 'w', encoding='utf-8') as f:
                json.dump(deep_sub_categories, f, indent=2, ensure_ascii=False)
            
            print(f"\n[7] ÄÃ£ lÆ°u deep sub-categories vÃ o: {deep_sub_categories_file}")
            
            # Load táº¥t cáº£ categories Ä‘Ã£ cÃ³
            all_existing = []
            
            # Load parent categories
            categories_file = "data/raw/tiki_categories.json"
            if os.path.exists(categories_file):
                parent_cats = load_categories_from_json(categories_file)
                for cat in parent_cats:
                    cat_copy = cat.copy()
                    cat_copy['parent_id'] = None
                    cat_copy['parent_name'] = None
                    cat_copy['parent_url'] = None
                    all_existing.append(cat_copy)
            
            # Load level 2 sub-categories
            level2_cats = load_categories_from_json(sub_categories_file)
            all_existing.extend(level2_cats)
            
            # ThÃªm level 3 sub-categories
            all_existing.extend(deep_sub_categories)
            
            # LÆ°u file tá»•ng há»£p
            all_categories_file = "data/raw/tiki_all_categories.json"
            with open(all_categories_file, 'w', encoding='utf-8') as f:
                json.dump(all_existing, f, indent=2, ensure_ascii=False)
            
            # Äáº¿m sá»‘ lÆ°á»£ng theo level
            level1_count = len([c for c in all_existing if c.get('parent_id') is None])
            level3_ids = set(x.get('category_id') for x in deep_sub_categories if x.get('category_id'))
            # Level 2: cÃ³ parent_id nhÆ°ng khÃ´ng cÃ³ trong level3_ids
            level2_count = len([c for c in level2_cats if c.get('category_id') not in level3_ids])
            
            print(f"[8] ÄÃ£ lÆ°u táº¥t cáº£ categories (level 1 + 2 + 3) vÃ o: {all_categories_file}")
            print(f"    Tá»•ng cá»™ng: {len(all_existing)} categories")
            print(f"    - Level 1 (parent): {level1_count}")
            print(f"    - Level 2: {level2_count}")
            print(f"    - Level 3: {len(deep_sub_categories)}")
            
            # Táº¡o file há»£p nháº¥t vá»›i cáº¥u trÃºc phÃ¢n cáº¥p
            print("\n" + "=" * 60)
            create_merged_categories_file()
        
        return deep_sub_categories if deep_sub_categories else []
    
    # Náº¿u chÆ°a cÃ³ file sub_categories, crawl tá»« Ä‘áº§u
    categories_file = "data/raw/tiki_categories.json"
    categories = []
    
    if os.path.exists(categories_file):
        print("\n[0] ÄÃ£ tÃ¬m tháº¥y file categories, Ä‘ang load...")
        categories = load_categories_from_json(categories_file)
        print(f"   ÄÃ£ load {len(categories)} categories tá»« file")
    else:
        # Crawl vá»›i Firecrawl náº¿u chÆ°a cÃ³ file
        payload = {
            "url": "https://tiki.vn/",
            "onlyMainContent": True,
            "maxAge": 172800000,
            "parsers": [],
            "formats": ["html"]
        }
        
        url = f"{FIRECRAWL_API_URL}/v2/scrape"
        
        try:
            print("\n[1] Äang crawl tá»« Firecrawl...")
            response = requests.post(url, json=payload, timeout=60)
            response.raise_for_status()
            
            data = response.json()
            
            print("[2] Äang parse vÃ  extract categories...")
            categories = parse_firecrawl_response(data)
            
            print(f"\n[3] TÃ¬m tháº¥y {len(categories)} categories:")
            print("-" * 60)
            
            for i, cat in enumerate(categories, 1):
                print(f"{i}. {cat['name']}")
                print(f"   ID: {cat.get('category_id', 'N/A')}")
                print(f"   URL: {cat['url']}")
                print()
            
            # Save to JSON
            os.makedirs(os.path.dirname(categories_file), exist_ok=True)
            
            with open(categories_file, 'w', encoding='utf-8') as f:
                json.dump(categories, f, indent=2, ensure_ascii=False)
            
            print(f"[4] ÄÃ£ lÆ°u vÃ o: {categories_file}")
            
        except requests.exceptions.RequestException as e:
            print(f"Error khi crawl: {e}")
            return []
        except Exception as e:
            print(f"Error: {e}")
            return []
    
    # Crawl sub-categories tá»« cÃ¡c categories Ä‘Ã£ cÃ³
    if categories:
        # Sá»­ dá»¥ng recursive=True Ä‘á»ƒ crawl táº¥t cáº£ cÃ¡c level
        # max_depth=None Ä‘á»ƒ khÃ´ng giá»›i háº¡n Ä‘á»™ sÃ¢u (hoáº·c set sá»‘ cá»¥ thá»ƒ nhÆ° 10)
        sub_categories = crawl_all_sub_categories(
            categories, 
            max_categories=None,
            recursive=True,  # Crawl Ä‘á»‡ quy táº¥t cáº£ cÃ¡c level
            max_depth=None   # None = khÃ´ng giá»›i háº¡n, hoáº·c set sá»‘ nhÆ° 10, 15
        )
        
        # LÆ°u sub-categories
        if sub_categories:
            os.makedirs(os.path.dirname(sub_categories_file), exist_ok=True)
            
            with open(sub_categories_file, 'w', encoding='utf-8') as f:
                json.dump(sub_categories, f, indent=2, ensure_ascii=False)
            
            print(f"\n[7] ÄÃ£ lÆ°u sub-categories vÃ o: {sub_categories_file}")
            
            # Táº¡o file tá»•ng há»£p táº¥t cáº£ categories (parent + sub)
            all_categories = []
            
            # ThÃªm parent categories (khÃ´ng cÃ³ parent_id)
            for cat in categories:
                cat_copy = cat.copy()
                cat_copy['parent_id'] = None
                cat_copy['parent_name'] = None
                cat_copy['parent_url'] = None
                all_categories.append(cat_copy)
            
            # ThÃªm sub-categories
            all_categories.extend(sub_categories)
            
            all_categories_file = "data/raw/tiki_all_categories.json"
            with open(all_categories_file, 'w', encoding='utf-8') as f:
                json.dump(all_categories, f, indent=2, ensure_ascii=False)
            
            print(f"[8] ÄÃ£ lÆ°u táº¥t cáº£ categories (parent + sub) vÃ o: {all_categories_file}")
            print(f"    Tá»•ng cá»™ng: {len(all_categories)} categories")
            
            # Táº¡o file há»£p nháº¥t vá»›i cáº¥u trÃºc phÃ¢n cáº¥p
            print("\n" + "=" * 60)
            create_merged_categories_file()
        
        return all_categories if sub_categories else categories
    
    return categories


if __name__ == "__main__":
    main()