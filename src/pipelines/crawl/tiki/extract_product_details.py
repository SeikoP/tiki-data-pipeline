"""
Extract product details t·ª´ Tiki product pages
S·ª≠ d·ª•ng AI extraction v·ªõi Firecrawl + Groq
"""
import os
import sys
import json
import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from bs4 import BeautifulSoup

# Fix encoding on Windows
if sys.platform == "win32":
    import io
    try:
        if not hasattr(sys.stdout, 'buffer') or (hasattr(sys.stdout, 'encoding') and sys.stdout.encoding != 'utf-8'):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    except (AttributeError, ValueError):
        pass

from .config import GROQ_CONFIG, get_config, FIRECRAWL_API_URL, TIKI_API_BASE_URL, TIKI_API_TOKEN
from .extract_products import extract_product_id

config = get_config()

# Import Groq key manager
try:
    from .groq_config import get_groq_api_key
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    get_groq_api_key = None

# Check if Groq is enabled
GROQ_ENABLED = GROQ_CONFIG.get("enabled", False) and GROQ_AVAILABLE

# Import requests (c·∫ßn cho c·∫£ Groq API v√† Tiki API)
import requests

# Groq API setup
if GROQ_ENABLED:
    GROQ_API_BASE = GROQ_CONFIG.get("base_url", "https://api.groq.com/openai/v1")
    GROQ_MODEL = GROQ_CONFIG.get("model", "llama-3.1-70b-versatile")


# ===== PRODUCT DETAILS SCHEMA =====
PRODUCT_DETAILS_SCHEMA = {
    "type": "object",
    "properties": {
        "product_id": {
            "type": "string",
            "description": "Product ID t·ª´ URL (v√≠ d·ª•: 123345348)"
        },
        "name": {
            "type": "string",
            "description": "T√™n s·∫£n ph·∫©m ƒë·∫ßy ƒë·ªß"
        },
        "price": {
            "type": "object",
            "properties": {
                "current_price": {
                    "type": "number",
                    "description": "Gi√° hi·ªán t·∫°i sau gi·∫£m gi√° (VND)"
                },
                "original_price": {
                    "type": "number",
                    "description": "Gi√° g·ªëc tr∆∞·ªõc gi·∫£m gi√° (VND)"
                },
                "discount_percent": {
                    "type": "number",
                    "description": "Ph·∫ßn trƒÉm gi·∫£m gi√° (v√≠ d·ª•: 23 cho 23%)"
                },
                "currency": {
                    "type": "string",
                    "description": "ƒê∆°n v·ªã ti·ªÅn t·ªá (m·∫∑c ƒë·ªãnh: VND)"
                }
            },
            "required": ["current_price"]
        },
        "description": {
            "type": "string",
            "description": "M√¥ t·∫£ s·∫£n ph·∫©m chi ti·∫øt"
        },
        "specifications": {
            "type": "object",
            "description": "Th√¥ng s·ªë k·ªπ thu·∫≠t d·∫°ng key-value",
            "additionalProperties": {
                "type": "string"
            }
        },
        "detailed_info": {
            "type": "string",
            "description": "Th√¥ng tin chi ti·∫øt s·∫£n ph·∫©m (ph·∫ßn 'Th√¥ng tin chi ti·∫øt' tr√™n trang)"
        },
        "customer_reviews": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "reviewer_name": {
                        "type": "string",
                        "description": "T√™n ng∆∞·ªùi ƒë√°nh gi√°"
                    },
                    "rating": {
                        "type": "number",
                        "description": "ƒêi·ªÉm ƒë√°nh gi√° (1-5 sao)"
                    },
                    "review_text": {
                        "type": "string",
                        "description": "N·ªôi dung ƒë√°nh gi√°"
                    },
                    "review_date": {
                        "type": "string",
                        "description": "Ng√†y ƒë√°nh gi√°"
                    },
                    "verified_purchase": {
                        "type": "boolean",
                        "description": "ƒê√£ mua h√†ng x√°c th·ª±c"
                    }
                }
            },
            "description": "Danh s√°ch ƒë√°nh gi√° t·ª´ kh√°ch h√†ng (l·∫•y t·ª´ c√°c ƒë√°nh gi√° m·ªõi nh·∫•t)"
        },
        "rating": {
            "type": "object",
            "properties": {
                "average": {
                    "type": "number",
                    "description": "ƒêi·ªÉm ƒë√°nh gi√° trung b√¨nh (0-5)"
                },
                "total_reviews": {
                    "type": "integer",
                    "description": "T·ªïng s·ªë ƒë√°nh gi√°"
                },
                "rating_distribution": {
                    "type": "object",
                    "description": "Ph√¢n b·ªë ƒë√°nh gi√° (5 sao, 4 sao, ...)",
                    "additionalProperties": {
                        "type": "integer"
                    }
                }
            }
        },
        "seller": {
            "type": "object",
            "properties": {
                "name": {
                    "type": "string",
                    "description": "T√™n ng∆∞·ªùi b√°n/shop"
                },
                "is_official": {
                    "type": "boolean",
                    "description": "C√≥ ph·∫£i h√†ng ch√≠nh h√£ng kh√¥ng"
                },
                "seller_id": {
                    "type": "string",
                    "description": "ID c·ªßa seller"
                }
            }
        },
        "shipping": {
            "type": "object",
            "properties": {
                "free_shipping": {
                    "type": "boolean",
                    "description": "C√≥ mi·ªÖn ph√≠ ship kh√¥ng"
                },
                "fast_delivery": {
                    "type": "boolean",
                    "description": "C√≥ giao nhanh (2H, TikiNOW) kh√¥ng"
                },
                "delivery_time": {
                    "type": "string",
                    "description": "Th·ªùi gian giao h√†ng (v√≠ d·ª•: 'Giao th·ª© 6, 14/11')"
                }
            }
        },
        "stock": {
            "type": "object",
            "properties": {
                "available": {
                    "type": "boolean",
                    "description": "C√≤n h√†ng kh√¥ng"
                },
                "quantity": {
                    "type": "integer",
                    "description": "S·ªë l∆∞·ª£ng c√≤n l·∫°i (n·∫øu c√≥)"
                },
                "stock_status": {
                    "type": "string",
                    "description": "Tr·∫°ng th√°i t·ªìn kho (v√≠ d·ª•: 'C√≤n h√†ng', 'H·∫øt h√†ng')"
                }
            }
        },
        "category_path": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "ƒê∆∞·ªùng d·∫´n category (v√≠ d·ª•: ['ƒêi·ªán tho·∫°i', 'Smartphone', 'iPhone'])"
        },
        "brand": {
            "type": "string",
            "description": "Th∆∞∆°ng hi·ªáu s·∫£n ph·∫©m (v√≠ d·ª•: Apple, Samsung)"
        },
        "warranty": {
            "type": "string",
            "description": "Th√¥ng tin b·∫£o h√†nh (v√≠ d·ª•: '12 th√°ng', 'Ch√≠nh h√£ng Apple 1 nƒÉm', v.v.)"
        },
        "promotions": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "Danh s√°ch khuy·∫øn m√£i (v√≠ d·ª•: ['Gi·∫£m 10%', 'T·∫∑ng k√®m ·ªëp l∆∞ng'])"
        },
        "ai_summary": {
            "type": "object",
            "properties": {
                "product_summary": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Danh s√°ch c√°c nh·∫≠n x√©t t√≠ch c·ª±c/ti√™u c·ª±c v·ªÅ s·∫£n ph·∫©m t·ª´ AI t·ªïng h·ª£p (v√≠ d·ª•: t·ª´ ph·∫ßn 'Tr·ª£ l√Ω AI t·ªïng h·ª£p t·ª´ c√°c ƒë√°nh gi√° m·ªõi nh·∫•t')"
                },
                "service_summary": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Danh s√°ch c√°c nh·∫≠n x√©t t√≠ch c·ª±c/ti√™u c·ª±c v·ªÅ d·ªãch v·ª• t·ª´ AI t·ªïng h·ª£p"
                },
                "positive_count": {
                    "type": "object",
                    "description": "S·ªë l∆∞·ª£ng ƒë√°nh gi√° t√≠ch c·ª±c (d·∫°ng: {'product': 88, 'service': 85})",
                    "additionalProperties": {
                        "type": "integer"
                    }
                },
                "negative_count": {
                    "type": "object",
                    "description": "S·ªë l∆∞·ª£ng ƒë√°nh gi√° ti√™u c·ª±c (d·∫°ng: {'product': 1, 'service': 3})",
                    "additionalProperties": {
                        "type": "integer"
                    }
                }
            },
            "description": "T√≥m t·∫Øt ƒë√°nh gi√° t·ª´ Tr·ª£ l√Ω AI (n·∫øu trang c√≥ ph·∫ßn n√†y)"
        }
    },
    "required": ["product_id", "name", "price"]
}


def create_extraction_prompt(product_url: str, product_id: str, product_name: str = None) -> str:
    """
    T·∫°o prompt cho AI extraction
    
    Args:
        product_url: URL c·ªßa product page
        product_id: Product ID
        product_name: T√™n s·∫£n ph·∫©m (optional)
    
    Returns:
        Extraction prompt
    """
    prompt = f"""
B·∫†N PH·∫¢I EXTRACT ƒê·∫¶Y ƒê·ª¶ T·∫§T C·∫¢ TH√îNG TIN c√≥ s·∫µn tr√™n trang Tiki.vn.

Product Information:
- Product ID: {product_id}
- Product Name: {product_name or 'N/A'}
- URL: {product_url}

H√£y ƒë·ªçc K·ª∏ L∆Ø·ª†NG to√†n b·ªô n·ªôi dung trang v√† extract T·∫§T C·∫¢ th√¥ng tin sau:

1. **Th√¥ng tin c∆° b·∫£n (B·∫ÆT BU·ªòC):**
   - T√™n s·∫£n ph·∫©m ƒë·∫ßy ƒë·ªß (l·∫•y t·ª´ ti√™u ƒë·ªÅ ch√≠nh)
   - Product ID: {product_id}
   - Brand/Th∆∞∆°ng hi·ªáu (t√¨m trong t√™n s·∫£n ph·∫©m ho·∫∑c th√¥ng s·ªë)

2. **Gi√° c·∫£ (QUAN TR·ªåNG):**
   - Gi√° hi·ªán t·∫°i (sau gi·∫£m gi√°) - T√åM K·ª∏ trong trang
   - Gi√° g·ªëc (gi√° c≈©, gi√° ni√™m y·∫øt) - th∆∞·ªùng c√≥ d·∫•u g·∫°ch ngang
   - Ph·∫ßn trƒÉm gi·∫£m gi√° (t√≠nh t·ª´ gi√° g·ªëc v√† gi√° hi·ªán t·∫°i)
   - Currency: "VND"

3. **M√¥ t·∫£ s·∫£n ph·∫©m (QUAN TR·ªåNG - PH·∫¢I C√ì):**
   - T√¨m ph·∫ßn "M√¥ t·∫£ s·∫£n ph·∫©m", "Th√¥ng tin s·∫£n ph·∫©m", "Gi·ªõi thi·ªáu", "M√¥ t·∫£", "Chi ti·∫øt s·∫£n ph·∫©m"
   - T√¨m c√°c ƒëo·∫°n vƒÉn m√¥ t·∫£ v·ªÅ s·∫£n ph·∫©m (kh√¥ng ph·∫£i th√¥ng s·ªë k·ªπ thu·∫≠t, kh√¥ng ph·∫£i "ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t")
   - Extract to√†n b·ªô m√¥ t·∫£, kh√¥ng b·ªè s√≥t, kh√¥ng c·∫Øt ng·∫Øn
   - N·∫øu c√≥ nhi·ªÅu ƒëo·∫°n, g·ªôp l·∫°i th√†nh m·ªôt chu·ªói
   - N·∫øu trang c√≥ m√¥ t·∫£, PH·∫¢I extract, kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ r·ªóng ""
   - L∆ØU √ù: "ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t" KH√îNG ph·∫£i l√† m√¥ t·∫£, ƒë√≥ l√† th√¥ng tin t√≥m t·∫Øt

4. **Th√¥ng s·ªë k·ªπ thu·∫≠t (R·∫§T QUAN TR·ªåNG - PH·∫¢I C√ì):**
   - T√¨m b·∫£ng "Th√¥ng s·ªë k·ªπ thu·∫≠t", "Specifications", "ƒê·∫∑c ƒëi·ªÉm", "Th√¥ng s·ªë", "Th√¥ng tin k·ªπ thu·∫≠t"
   - T√¨m c√°c d√≤ng c√≥ format "T√™n th√¥ng s·ªë: Gi√° tr·ªã" ho·∫∑c b·∫£ng 2 c·ªôt
   - Extract T·∫§T C·∫¢ c√°c th√¥ng s·ªë d·∫°ng key-value
   - V√≠ d·ª• cho ƒëi·ªán tho·∫°i: "RAM": "8GB", "ROM": "128GB", "M√†n h√¨nh": "6.1 inch", "CPU": "A14 Bionic", "Camera sau": "12MP", "Camera tr∆∞·ªõc": "12MP", "Pin": "2815 mAh", "H·ªá ƒëi·ªÅu h√†nh": "iOS 14", "K√≠ch th∆∞·ªõc": "146.7 x 71.5 x 7.4 mm", "Tr·ªçng l∆∞·ª£ng": "162g"
   - PH·∫¢I c√≥ √≠t nh·∫•t 5-15 th√¥ng s·ªë n·∫øu trang c√≥ b·∫£ng th√¥ng s·ªë
   - KH√îNG ƒë∆∞·ª£c ƒë·ªÉ specifications r·ªóng {{}} n·∫øu trang c√≥ th√¥ng s·ªë k·ªπ thu·∫≠t

5. **Th√¥ng tin chi ti·∫øt (QUAN TR·ªåNG):**
   - T√¨m ph·∫ßn "Th√¥ng tin chi ti·∫øt", "Chi ti·∫øt s·∫£n ph·∫©m", "M√¥ t·∫£ chi ti·∫øt", "Th√¥ng tin s·∫£n ph·∫©m"
   - Trong HTML, t√¨m c√°c selector: div[class*="detail"], div[id*="detail"], section[class*="detail"]
   - T√¨m heading (h1-h6) ch·ª©a "Th√¥ng tin chi ti·∫øt" v√† l·∫•y n·ªôi dung sau ƒë√≥
   - Extract to√†n b·ªô n·ªôi dung ph·∫ßn n√†y (c√≥ th·ªÉ l√† HTML, text, ho·∫∑c structured content)
   - Bao g·ªìm c√°c th√¥ng tin b·ªï sung v·ªÅ s·∫£n ph·∫©m KH√îNG n·∫±m trong m√¥ t·∫£ ng·∫Øn
   - KH√ÅC v·ªõi description: detailed_info l√† ph·∫ßn m·ªü r·ªông, chi ti·∫øt h∆°n, c√≥ th·ªÉ c√≥ b·∫£ng, danh s√°ch, HTML
   - N·∫øu c√≥ nhi·ªÅu ph·∫ßn, g·ªôp l·∫°i th√†nh m·ªôt chu·ªói
   - N·∫øu kh√¥ng c√≥ ph·∫ßn ri√™ng "Th√¥ng tin chi ti·∫øt", ƒë·ªÉ detailed_info = ""

6. **Kh√°ch h√†ng ƒë√°nh gi√° (QUAN TR·ªåNG):**
   - T√¨m ph·∫ßn "Kh√°ch h√†ng ƒë√°nh gi√°", "ƒê√°nh gi√°", "Reviews", "Nh·∫≠n x√©t", "B√¨nh lu·∫≠n"
   - Extract T·∫§T C·∫¢ c√°c ƒë√°nh gi√° m·ªõi nh·∫•t t·ª´ kh√°ch h√†ng (√≠t nh·∫•t 5-10 ƒë√°nh gi√°)
   - M·ªói ƒë√°nh gi√° c·∫ßn c√≥:
     * T√™n ng∆∞·ªùi ƒë√°nh gi√° (t√™n th·∫≠t, kh√¥ng ph·∫£i "Kh√°ch h√†ng 1", "User 1", v.v.)
     * ƒêi·ªÉm ƒë√°nh gi√° (s·ªë sao: 1-5)
     * N·ªôi dung ƒë√°nh gi√° (to√†n b·ªô text)
     * Ng√†y ƒë√°nh gi√° (n·∫øu c√≥)
     * Tr·∫°ng th√°i ƒë√£ mua h√†ng x√°c th·ª±c (n·∫øu c√≥)
   - S·∫Øp x·∫øp theo th·ª© t·ª± m·ªõi nh·∫•t tr∆∞·ªõc
   - QUAN TR·ªåNG: CH·ªà extract reviews c√≥ th·∫≠t trong n·ªôi dung trang, KH√îNG t·ª± t·∫°o reviews gi·∫£
   - N·∫øu kh√¥ng c√≥ reviews trong n·ªôi dung, ƒë·ªÉ customer_reviews = []

7. **ƒê√°nh gi√° t·ªïng quan:**
   - ƒêi·ªÉm ƒë√°nh gi√° trung b√¨nh (s·ªë t·ª´ 0-5, c√≥ th·ªÉ c√≥ s·ªë th·∫≠p ph√¢n)
   - T·ªïng s·ªë ƒë√°nh gi√° (s·ªë l∆∞·ª£ng reviews)
   - Ph√¢n b·ªë ƒë√°nh gi√° (5 sao: X, 4 sao: Y, ...) n·∫øu c√≥

8. **Ng∆∞·ªùi b√°n (QUAN TR·ªåNG):**
   - T√™n shop/ng∆∞·ªùi b√°n (t√¨m "B·ªüi", "Ng∆∞·ªùi b√°n", "Shop")
   - C√≥ ph·∫£i h√†ng ch√≠nh h√£ng kh√¥ng (t√¨m "Ch√≠nh h√£ng", "Official")
   - Seller ID n·∫øu c√≥

9. **V·∫≠n chuy·ªÉn:**
   - C√≥ mi·ªÖn ph√≠ ship kh√¥ng (t√¨m "Mi·ªÖn ph√≠ v·∫≠n chuy·ªÉn", "Freeship")
   - C√≥ giao nhanh kh√¥ng (t√¨m "TikiNOW", "Giao nhanh", "2H")
   - Th·ªùi gian giao h√†ng (v√≠ d·ª•: "Giao th·ª© 6, 14/11")

10. **T·ªìn kho:**
   - C√≤n h√†ng kh√¥ng (t√¨m "C√≤n h√†ng", "H·∫øt h√†ng", "S·∫Øp c√≥ h√†ng")
   - S·ªë l∆∞·ª£ng c√≤n l·∫°i n·∫øu c√≥
   - Tr·∫°ng th√°i t·ªìn kho (text m√¥ t·∫£)

11. **Category path:**
    - T√¨m breadcrumb, ƒë∆∞·ªùng d·∫´n category (v√≠ d·ª•: ƒêi·ªán tho·∫°i > Smartphone > iPhone)
    - Extract th√†nh array: ["ƒêi·ªán tho·∫°i", "Smartphone", "iPhone"]

12. **B·∫£o h√†nh (QUAN TR·ªåNG):**
    - T√¨m ph·∫ßn "B·∫£o h√†nh", "Warranty", "Th√¥ng tin b·∫£o h√†nh"
    - Extract th√¥ng tin b·∫£o h√†nh (v√≠ d·ª•: "12 th√°ng", "B·∫£o h√†nh ch√≠nh h√£ng", "Apple Care 1 nƒÉm")
    - C√≥ th·ªÉ l√† trong ph·∫ßn th√¥ng s·ªë k·ªπ thu·∫≠t ho·∫∑c ph·∫ßn ri√™ng
    - N·∫øu trang c√≥ b·∫£o h√†nh, PH·∫¢I extract, kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ null ""

13. **Khuy·∫øn m√£i:**
    - T√¨m t·∫•t c·∫£ khuy·∫øn m√£i, ∆∞u ƒë√£i
    - V√≠ d·ª•: "Gi·∫£m 10%", "T·∫∑ng k√®m ·ªëp l∆∞ng", "Tr·∫£ g√≥p 0%"
    - Extract th√†nh array

14. **AI T√≥m T·∫Øt ƒê√°nh Gi√° (N·∫æU C√ì - R·∫§T QUAN TR·ªåNG):**
    - T√¨m ph·∫ßn "Tr·ª£ l√Ω AI t·ªïng h·ª£p t·ª´ c√°c ƒë√°nh gi√° m·ªõi nh·∫•t" ho·∫∑c "AI Summary"
    - TRONG HTML: T√¨m div v·ªõi id="ai-summary" ho·∫∑c div[id="ai-summary"] ho·∫∑c div[class*="ai-summary"]
    - Selector c·ª• th·ªÉ: div#ai-summary, div[id="ai-summary"], div[class*="ai-summary"]
    - N·∫øu t√¨m th·∫•y ph·∫ßn n√†y, extract:
      * product_summary: Danh s√°ch c√°c nh·∫≠n x√©t t√≠ch c·ª±c/ti√™u c·ª±c v·ªÅ s·∫£n ph·∫©m (t·ª´ c√°c list items, paragraphs trong div#ai-summary)
      * service_summary: Danh s√°ch c√°c nh·∫≠n x√©t t√≠ch c·ª±c/ti√™u c·ª±c v·ªÅ d·ªãch v·ª• (t·ª´ c√°c list items, paragraphs trong div#ai-summary)
      * positive_count: S·ªë l∆∞·ª£ng positive v·ªÅ s·∫£n ph·∫©m v√† d·ªãch v·ª• (v√≠ d·ª•: {{"product": 88, "service": 85}})
      * negative_count: S·ªë l∆∞·ª£ng negative v·ªÅ s·∫£n ph·∫©m v√† d·ªãch v·ª• (v√≠ d·ª•: {{"product": 1, "service": 3}})
    - Ph√¢n lo·∫°i c√°c items th√†nh product_summary ho·∫∑c service_summary d·ª±a tr√™n t·ª´ kh√≥a (s·∫£n ph·∫©m/product vs d·ªãch v·ª•/service)
    - N·∫øu kh√¥ng c√≥ ph·∫ßn n√†y trong HTML ho·∫∑c markdown, ƒë·ªÉ ai_summary = {{"product_summary": [], "service_summary": [], "positive_count": {{}}, "negative_count": {{}}}}

QUAN TR·ªåNG:
- PH·∫¢I ƒë·ªçc K·ª∏ to√†n b·ªô n·ªôi dung trang, kh√¥ng b·ªè s√≥t
- Extract T·∫§T C·∫¢ th√¥ng tin c√≥ s·∫µn, kh√¥ng ƒë·ªÉ null n·∫øu th√¥ng tin c√≥ tr√™n trang
- Gi√° c·∫£ ph·∫£i l√† s·ªë nguy√™n (VND), kh√¥ng c√≥ d·∫•u ph·∫©y, d·∫•u ch·∫•m
- Warranty: extract n·∫øu c√≥, kh√¥ng ƒë·ªÉ r·ªóng n·∫øu trang c√≥ th√¥ng tin b·∫£o h√†nh
- Specifications PH·∫¢I c√≥ √≠t nh·∫•t 5-10 th√¥ng s·ªë n·∫øu trang c√≥
- Description PH·∫¢I c√≥ n·ªôi dung n·∫øu trang c√≥ m√¥ t·∫£
- Seller info PH·∫¢I c√≥ n·∫øu trang hi·ªÉn th·ªã
- Detailed info: T√¨m k·ªπ ph·∫ßn "Th√¥ng tin chi ti·∫øt" trong HTML, c√≥ th·ªÉ n·∫±m trong div/section c√≥ class/id ch·ª©a "detail" ho·∫∑c "info"
- AI Summary: T√åM K·ª∏ div#ai-summary ho·∫∑c div[id="ai-summary"] trong HTML. CH·ªà extract n·∫øu th·ª±c s·ª± c√≥ ph·∫ßn n√†y tr√™n trang, KH√îNG t·ª± t·∫°o. N·∫øu kh√¥ng t√¨m th·∫•y, ƒë·ªÉ ai_summary v·ªõi c√°c m·∫£ng r·ªóng
"""
    return prompt


def create_system_prompt() -> str:
    """T·∫°o system prompt cho AI extraction"""
    return """B·∫°n l√† chuy√™n gia extract d·ªØ li·ªáu t·ª´ trang web Tiki.vn v·ªõi ƒë·ªô ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß cao.

NHI·ªÜM V·ª§ C·ª¶A B·∫†N:
1. ƒê·ªçc K·ª∏ L∆Ø·ª†NG to√†n b·ªô n·ªôi dung trang web Tiki product page
2. Extract ƒê·∫¶Y ƒê·ª¶ T·∫§T C·∫¢ th√¥ng tin c√≥ s·∫µn tr√™n trang
3. Kh√¥ng ƒë∆∞·ª£c b·ªè s√≥t b·∫•t k·ª≥ th√¥ng tin n√†o
4. Tr·∫£ v·ªÅ JSON object thu·∫ßn t√∫y, KH√îNG c√≥ text gi·∫£i th√≠ch tr∆∞·ªõc/sau JSON

QUY T·∫ÆC QUAN TR·ªåNG:
- Gi√° c·∫£: s·ªë nguy√™n (VND), kh√¥ng c√≥ d·∫•u ph·∫©y, d·∫•u ch·∫•m (v√≠ d·ª•: 16990000)
- Th√¥ng s·ªë k·ªπ thu·∫≠t: extract T·∫§T C·∫¢ th√†nh key-value pairs, KH√îNG ƒë·ªÉ r·ªóng {{}} n·∫øu c√≥ th√¥ng s·ªë
- M√¥ t·∫£: extract to√†n b·ªô n·ªôi dung m√¥ t·∫£, kh√¥ng c·∫Øt ng·∫Øn
- Detailed info: extract to√†n b·ªô ph·∫ßn "Th√¥ng tin chi ti·∫øt", kh√¥ng b·ªè s√≥t
- Customer reviews: extract T·∫§T C·∫¢ c√°c ƒë√°nh gi√° m·ªõi nh·∫•t CH·ªà n·∫øu c√≥ trong n·ªôi dung trang, KH√îNG t·ª± t·∫°o reviews gi·∫£. N·∫øu kh√¥ng c√≥ reviews trong markdown, ƒë·ªÉ customer_reviews = []
- Specifications: ph·∫£i c√≥ √≠t nh·∫•t 5-10 th√¥ng s·ªë n·∫øu trang c√≥ b·∫£ng th√¥ng s·ªë
- Seller: ph·∫£i extract t√™n shop, tr·∫°ng th√°i ch√≠nh h√£ng n·∫øu c√≥ tr√™n trang
- Shipping: ph·∫£i extract th√¥ng tin v·∫≠n chuy·ªÉn n·∫øu c√≥
- Category path: extract t·ª´ breadcrumb (v√≠ d·ª•: ["ƒêi·ªán tho·∫°i", "Smartphone"])
- Promotions: extract t·∫•t c·∫£ khuy·∫øn m√£i th√†nh array

FORMAT OUTPUT:
- Ch·ªâ tr·∫£ v·ªÅ JSON object thu·∫ßn t√∫y
- KH√îNG c√≥ text gi·∫£i th√≠ch nh∆∞ "D∆∞·ªõi ƒë√¢y l√†...", "JSON object:", v.v.
- KH√îNG c√≥ markdown code blocks n·∫øu kh√¥ng c·∫ßn thi·∫øt
- B·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp b·∫±ng {{ v√† k·∫øt th√∫c b·∫±ng }}

N·∫øu th√¥ng tin th·ª±c s·ª± kh√¥ng c√≥ tr√™n trang, m·ªõi ƒë·ªÉ null."""


def scrape_with_firecrawl_v2(product_url: str, timeout: int = 60) -> Optional[Dict[str, Any]]:
    """
    Scrape product page s·ª≠ d·ª•ng Firecrawl v2/scrape ƒë·ªÉ l·∫•y c·∫£ markdown v√† HTML
    
    Args:
        product_url: URL c·ªßa product page
        timeout: Timeout cho request (seconds)
    
    Returns:
        Dict v·ªõi 'markdown' v√† 'html' ho·∫∑c None n·∫øu l·ªói
    """
    try:
        # Th·ª≠ v0/scrape tr∆∞·ªõc (ƒë√£ test ho·∫°t ƒë·ªông)
        scrape_url = f"{FIRECRAWL_API_URL}/v2/scrape"
        
        payload = {
            "url": product_url,
            "formats": ["html", "markdown"],
            "onlyMainContent": False,  # L·∫•y to√†n b·ªô content ƒë·ªÉ c√≥ reviews
            "maxAge": 172800000,  # 2 days
            "waitFor": 8000,  # TƒÉng wait time ƒë·ªÉ load all dynamic content (reviews, AI summary)
            "timeout": timeout * 1000  # Convert to milliseconds for Firecrawl
        }
        
        response = requests.post(scrape_url, json=payload, timeout=timeout)
        response.raise_for_status()
        
        data = response.json()
        
        # Handle v0/scrape response format
        result = {}
        
        # Extract markdown v√† HTML t·ª´ data.data
        if data.get("data"):
            content_data = data.get("data", {})
            if content_data.get("markdown"):
                result["markdown"] = content_data.get("markdown")
            if content_data.get("html"):
                result["html"] = content_data.get("html")
        
        # Fallback: check root level
        if not result.get("markdown") and data.get("markdown"):
            result["markdown"] = data.get("markdown")
        if not result.get("html") and data.get("html"):
            result["html"] = data.get("html")
        
        if result.get("markdown") or result.get("html"):
            return result
        else:
            try:
                print(f"‚ö†Ô∏è  Firecrawl scrape failed: {data.get('error', 'No content in response')}")
            except:
                pass
            return None
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói scrape Firecrawl: {str(e)[:100]}")
        except:
            pass
        return None


def extract_ai_summary_from_html(html_content: str) -> Optional[Dict[str, Any]]:
    """
    Extract AI summary t·ª´ HTML b·∫±ng c√°ch t√¨m div#ai-summary
    
    Args:
        html_content: HTML content t·ª´ Firecrawl
    
    Returns:
        Dict ch·ª©a ai_summary structure ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    if not html_content:
        return None
    
    try:
        soup = BeautifulSoup(html_content, 'lxml')
        
        # T√¨m div v·ªõi id="ai-summary"
        ai_summary_div = soup.find('div', id='ai-summary')
        if not ai_summary_div:
            # Th·ª≠ t√¨m v·ªõi class ch·ª©a "ai-summary" ho·∫∑c "aiSummary"
            ai_summary_div = soup.find('div', class_=re.compile(r'ai[-_]?summary', re.I))
        
        if not ai_summary_div:
            return None
        
        # Extract text content
        text_content = ai_summary_div.get_text(separator='\n', strip=True)
        
        # Parse structure t·ª´ text
        # C·∫•u tr√∫c th∆∞·ªùng c√≥:
        # - product_summary: c√°c ƒëi·ªÉm t√≠ch c·ª±c/ti√™u c·ª±c v·ªÅ s·∫£n ph·∫©m
        # - service_summary: c√°c ƒëi·ªÉm t√≠ch c·ª±c/ti√™u c·ª±c v·ªÅ d·ªãch v·ª•
        # - positive_count: s·ªë l∆∞·ª£ng positive (product: X, service: Y)
        # - negative_count: s·ªë l∆∞·ª£ng negative (product: X, service: Y)
        
        result = {
            "product_summary": [],
            "service_summary": [],
            "positive_count": {},
            "negative_count": {}
        }
        
        # T√¨m c√°c ph·∫ßn t·ª≠ con c√≥ th·ªÉ ch·ª©a summary
        # Th·ª≠ t√¨m c√°c list items, paragraphs, ho·∫∑c divs ch·ª©a th√¥ng tin
        summary_items = ai_summary_div.find_all(['li', 'p', 'div'], class_=re.compile(r'summary|review|point|item', re.I))
        
        product_items = []
        service_items = []
        
        for item in summary_items:
            item_text = item.get_text(strip=True)
            if not item_text:
                continue
            
            # Ph√¢n lo·∫°i d·ª±a tr√™n t·ª´ kh√≥a
            text_lower = item_text.lower()
            if any(keyword in text_lower for keyword in ['s·∫£n ph·∫©m', 'product', 'm√°y', 'ƒëi·ªán tho·∫°i', 'thi·∫øt b·ªã']):
                product_items.append(item_text)
            elif any(keyword in text_lower for keyword in ['d·ªãch v·ª•', 'service', 'giao h√†ng', 'v·∫≠n chuy·ªÉn', 'ƒë√≥ng g√≥i']):
                service_items.append(item_text)
            else:
                # M·∫∑c ƒë·ªãnh th√™m v√†o product_summary
                product_items.append(item_text)
        
        result["product_summary"] = product_items[:20]  # Gi·ªõi h·∫°n 20 items
        result["service_summary"] = service_items[:20]
        
        # T√¨m s·ªë l∆∞·ª£ng positive/negative
        # Th∆∞·ªùng c√≥ format: "product: 88", "service: 85", ho·∫∑c "88 positive", "1 negative"
        count_patterns = [
            r'product[:\s]+(\d+)',
            r'service[:\s]+(\d+)',
            r'(\d+)\s*positive',
            r'(\d+)\s*negative',
            r't√≠ch c·ª±c[:\s]+(\d+)',
            r'ti√™u c·ª±c[:\s]+(\d+)',
        ]
        
        full_text = text_content.lower()
        for pattern in count_patterns:
            matches = re.findall(pattern, full_text, re.I)
            if matches:
                # N·∫øu t√¨m th·∫•y s·ªë, th·ª≠ ph√¢n lo·∫°i
                for match in matches:
                    num = int(match) if match.isdigit() else 0
                    if 'product' in pattern or 's·∫£n ph·∫©m' in pattern:
                        result["positive_count"]["product"] = num
                    elif 'service' in pattern or 'd·ªãch v·ª•' in pattern:
                        result["positive_count"]["service"] = num
                    elif 'positive' in pattern or 't√≠ch c·ª±c' in pattern:
                        if "product" not in result["positive_count"]:
                            result["positive_count"]["product"] = num
                        elif "service" not in result["positive_count"]:
                            result["positive_count"]["service"] = num
                    elif 'negative' in pattern or 'ti√™u c·ª±c' in pattern:
                        if "product" not in result["negative_count"]:
                            result["negative_count"]["product"] = num
                        elif "service" not in result["negative_count"]:
                            result["negative_count"]["service"] = num
        
        # N·∫øu kh√¥ng t√¨m th·∫•y items c·ª• th·ªÉ, l·∫•y to√†n b·ªô text v√† split th√†nh c√°c c√¢u
        if not result["product_summary"] and not result["service_summary"]:
            sentences = [s.strip() for s in text_content.split('\n') if s.strip() and len(s.strip()) > 10]
            if sentences:
                # Ph√¢n lo·∫°i c√¢u th√†nh product ho·∫∑c service
                for sentence in sentences[:30]:  # Gi·ªõi h·∫°n 30 c√¢u
                    sentence_lower = sentence.lower()
                    if any(keyword in sentence_lower for keyword in ['d·ªãch v·ª•', 'service', 'giao h√†ng', 'v·∫≠n chuy·ªÉn']):
                        result["service_summary"].append(sentence)
                    else:
                        result["product_summary"].append(sentence)
        
        # Ch·ªâ tr·∫£ v·ªÅ n·∫øu c√≥ √≠t nh·∫•t m·ªôt ph·∫ßn t·ª≠
        if result["product_summary"] or result["service_summary"] or result["positive_count"] or result["negative_count"]:
            return result
        
        return None
        
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói parse AI summary t·ª´ HTML: {str(e)[:100]}")
        except:
            pass
        return None


def extract_detailed_info_from_html(html_content: str) -> Optional[str]:
    """
    Extract ph·∫ßn "Th√¥ng tin chi ti·∫øt" t·ª´ HTML
    
    Args:
        html_content: HTML content t·ª´ Firecrawl
    
    Returns:
        String ch·ª©a th√¥ng tin chi ti·∫øt ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    if not html_content:
        return None
    
    try:
        soup = BeautifulSoup(html_content, 'lxml')
        
        # T√¨m ph·∫ßn "Th√¥ng tin chi ti·∫øt" b·∫±ng nhi·ªÅu c√°ch:
        # 1. T√¨m heading/ti√™u ƒë·ªÅ ch·ª©a "Th√¥ng tin chi ti·∫øt"
        # 2. T√¨m section/div c√≥ class/id li√™n quan
        # 3. T√¨m theo text content
        
        detailed_info = None
        
        # C√°ch 1: T√¨m heading (h1, h2, h3, h4) ch·ª©a "Th√¥ng tin chi ti·∫øt"
        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        for heading in headings:
            heading_text = heading.get_text(strip=True)
            if 'th√¥ng tin chi ti·∫øt' in heading_text.lower() or 'chi ti·∫øt s·∫£n ph·∫©m' in heading_text.lower():
                # L·∫•y ph·∫ßn t·ª≠ ti·∫øp theo ho·∫∑c parent ch·ª©a n·ªôi dung
                parent = heading.find_next_sibling()
                if not parent:
                    parent = heading.parent
                
                if parent:
                    # L·∫•y t·∫•t c·∫£ text t·ª´ ph·∫ßn t·ª≠ n√†y
                    detailed_info = parent.get_text(separator='\n', strip=True)
                    # Lo·∫°i b·ªè heading text kh·ªèi k·∫øt qu·∫£
                    if heading_text in detailed_info:
                        detailed_info = detailed_info.replace(heading_text, '', 1).strip()
                    break
        
        # C√°ch 2: T√¨m div/section c√≥ class/id ch·ª©a "detail", "info", "specification"
        if not detailed_info:
            detail_selectors = [
                'div[class*="detail"]',
                'div[class*="info"]',
                'div[id*="detail"]',
                'div[id*="info"]',
                'section[class*="detail"]',
                'section[class*="info"]',
            ]
            
            for selector in detail_selectors:
                try:
                    elements = soup.select(selector)
                    for elem in elements:
                        elem_text = elem.get_text(strip=True)
                        # Ki·ªÉm tra xem c√≥ ch·ª©a t·ª´ kh√≥a "th√¥ng tin chi ti·∫øt" kh√¥ng
                        if 'th√¥ng tin chi ti·∫øt' in elem_text.lower() or 'chi ti·∫øt' in elem_text.lower():
                            if len(elem_text) > 100:  # ƒê·∫£m b·∫£o c√≥ ƒë·ªß n·ªôi dung
                                detailed_info = elem_text
                                break
                    if detailed_info:
                        break
                except:
                    continue
        
        # C√°ch 3: T√¨m theo text pattern
        if not detailed_info:
            # T√¨m t·∫•t c·∫£ text v√† t√¨m ph·∫ßn sau "Th√¥ng tin chi ti·∫øt"
            all_text = soup.get_text()
            pattern = r'(?:th√¥ng tin chi ti·∫øt|chi ti·∫øt s·∫£n ph·∫©m)[:\s]*(.+?)(?:\n\n|\n[A-Z]|$)'
            match = re.search(pattern, all_text, re.IGNORECASE | re.DOTALL)
            if match:
                detailed_info = match.group(1).strip()
                # Gi·ªõi h·∫°n ƒë·ªô d√†i
                if len(detailed_info) > 10000:
                    detailed_info = detailed_info[:10000]
        
        # C√°ch 4: T√¨m trong c√°c div c√≥ class ƒë·∫∑c bi·ªát c·ªßa Tiki
        if not detailed_info:
            # Tiki th∆∞·ªùng d√πng c√°c class nh∆∞ "product-detail", "product-info", "specification"
            tiki_selectors = [
                'div.product-detail',
                'div.product-info',
                'div.product-specification',
                'div[data-testid*="detail"]',
                'div[data-testid*="info"]',
            ]
            
            for selector in tiki_selectors:
                try:
                    elements = soup.select(selector)
                    for elem in elements:
                        elem_text = elem.get_text(separator='\n', strip=True)
                        if len(elem_text) > 200:  # ƒê·∫£m b·∫£o c√≥ ƒë·ªß n·ªôi dung
                            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† ph·∫ßn th√¥ng tin chi ti·∫øt kh√¥ng (kh√¥ng ph·∫£i spec)
                            if 'th√¥ng tin chi ti·∫øt' in elem_text.lower() or \
                               ('m√¥ t·∫£' in elem_text.lower() and 'th√¥ng s·ªë' not in elem_text.lower()):
                                detailed_info = elem_text
                                break
                    if detailed_info:
                        break
                except:
                    continue
        
        # Clean up text
        if detailed_info:
            # Lo·∫°i b·ªè c√°c d√≤ng tr·ªëng nhi·ªÅu
            lines = [line.strip() for line in detailed_info.split('\n') if line.strip()]
            detailed_info = '\n'.join(lines)
            
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt
            detailed_info = re.sub(r'\s+', ' ', detailed_info)  # Nhi·ªÅu space th√†nh 1
            detailed_info = re.sub(r'\n{3,}', '\n\n', detailed_info)  # Nhi·ªÅu newline th√†nh 2
            
            if len(detailed_info) > 50:  # Ch·ªâ tr·∫£ v·ªÅ n·∫øu c√≥ ƒë·ªß n·ªôi dung
                return detailed_info
        
        return None
        
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói parse detailed info t·ª´ HTML: {str(e)[:100]}")
        except:
            pass
        return None


def extract_with_groq_ai(
    markdown_content: str = None,
    html_content: str = None,
    product_id: str = None,
    product_name: str = None
) -> Optional[Dict[str, Any]]:
    """
    Extract structured data t·ª´ markdown v√†/ho·∫∑c HTML b·∫±ng Groq AI
    
    Args:
        markdown_content: Markdown content t·ª´ Firecrawl (optional)
        html_content: HTML content t·ª´ Firecrawl (optional)
        product_id: Product ID
        product_name: Product name (optional)
    
    Returns:
        Dict ch·ª©a product details theo schema, ho·∫∑c None n·∫øu l·ªói
    """
    if not GROQ_ENABLED or not get_groq_api_key:
        return None
    
    try:
        # L·∫•y Groq API key (round-robin)
        groq_api_key = get_groq_api_key()
        if not groq_api_key:
            try:
                print("‚ö†Ô∏è  Kh√¥ng c√≥ Groq API key kh·∫£ d·ª•ng")
            except:
                pass
            return None
        
        # T·∫°o prompt
        prompt = create_extraction_prompt(f"(Product ID: {product_id})", product_id, product_name)
        system_prompt = create_system_prompt()
        
        # G·ªçi Groq API v·ªõi structured output (JSON mode)
        extract_url = f"{GROQ_API_BASE}/chat/completions"
        
        # Combine markdown and HTML content
        content_parts = []
        
        if markdown_content:
            # Limit markdown content ƒë·ªÉ tr√°nh token limit
            markdown_limited = markdown_content[:15000] if len(markdown_content) > 15000 else markdown_content
            content_parts.append(f"=== MARKDOWN CONTENT ===\n{markdown_limited}")
            try:
                print(f"   üìä Using {len(markdown_limited)}/{len(markdown_content)} chars of markdown")
            except:
                pass
        
        if html_content:
            # Limit HTML content (l·∫•y text t·ª´ HTML, kh√¥ng l·∫•y to√†n b·ªô HTML)
            # C√≥ th·ªÉ parse HTML ƒë·ªÉ l·∫•y text quan tr·ªçng
            html_limited = html_content[:10000] if len(html_content) > 10000 else html_content
            content_parts.append(f"=== HTML CONTENT (TEXT EXTRACTED) ===\n{html_limited}")
            try:
                print(f"   üìä Using {len(html_limited)}/{len(html_content)} chars of HTML")
            except:
                pass
        
        if not content_parts:
            try:
                print("‚ö†Ô∏è  Kh√¥ng c√≥ content ƒë·ªÉ extract")
            except:
                pass
            return None
        
        combined_content = "\n\n".join(content_parts)
        
        # T·∫°o user message v·ªõi schema instruction (r√∫t g·ªçn)
        schema_summary = """{
  "product_id": "string",
  "name": "string",
  "price": {"current_price": number, "original_price": number, "discount_percent": number, "currency": "VND"},
  "description": "string",
  "specifications": {"key": "value"},
  "detailed_info": "string",
  "customer_reviews": [
    {
      "reviewer_name": "string",
      "rating": number,
      "review_text": "string",
      "review_date": "string",
      "verified_purchase": boolean
    }
  ],
  "rating": {"average": number, "total_reviews": number},
  "seller": {"name": "string", "is_official": boolean},
  "shipping": {"free_shipping": boolean, "fast_delivery": boolean, "delivery_time": "string"},
  "stock": {"available": boolean, "quantity": number, "stock_status": "string"},
  "category_path": ["string"],
  "brand": "string",
  "warranty": "string",
  "promotions": ["string"],
  "ai_summary": {
    "product_summary": ["string"],
    "service_summary": ["string"],
    "positive_count": {"product": number, "service": number},
    "negative_count": {"product": number, "service": number}
  }
}"""
        
        user_content = f"""{prompt}

{combined_content}

=== INSTRUCTIONS ===
Tr·∫£ v·ªÅ JSON object ƒë√∫ng theo format sau (kh√¥ng c√≥ markdown code blocks, ch·ªâ JSON thu·∫ßn):
{schema_summary}

QUAN TR·ªåNG:
- CH·ªà extract th√¥ng tin c√≥ TH·∫¨T trong n·ªôi dung tr√™n, KH√îNG t·ª± t·∫°o/suy ƒëo√°n
- N·∫øu kh√¥ng th·∫•y reviews trong n·ªôi dung, ƒë·ªÉ customer_reviews = []
- N·∫øu kh√¥ng th·∫•y detailed_info ri√™ng, ƒë·ªÉ detailed_info = ""
- Gi·ªØ nguy√™n th√¥ng tin t·ª´ trang, kh√¥ng thay ƒë·ªïi"""
        
        payload = {
            "model": GROQ_MODEL,
            "messages": [
                {
                    "role": "system",
                    "content": f"{system_prompt}\n\nB·∫°n PH·∫¢I tr·∫£ v·ªÅ JSON object h·ª£p l·ªá, kh√¥ng c√≥ markdown code blocks, kh√¥ng c√≥ text th√™m."
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ],
            "temperature": 0.1
        }
        
        # Ch·ªâ th√™m response_format n·∫øu model support (m·ªôt s·ªë model kh√¥ng support)
        # Th·ª≠ kh√¥ng d√πng response_format tr∆∞·ªõc, n·∫øu c·∫ßn s·∫Ω parse t·ª´ text
        
        headers = {
            "Authorization": f"Bearer {groq_api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(extract_url, json=payload, headers=headers, timeout=60)
        
        # Handle model decommissioned error - fallback to newer model
        if response.status_code == 400:
            try:
                error_data = response.json()
                error_msg = error_data.get("error", {}).get("message", "")
                if "decommissioned" in error_msg.lower() or "model_decommissioned" in str(error_data):
                    # Try v·ªõi model m·ªõi h∆°n
                    fallback_models = ["llama-3.3-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768"]
                    for fallback_model in fallback_models:
                        if fallback_model != GROQ_MODEL:
                            try:
                                print(f"   üîÑ Retrying v·ªõi model: {fallback_model}")
                                payload["model"] = fallback_model
                                response = requests.post(extract_url, json=payload, headers=headers, timeout=60)
                                if response.status_code == 200:
                                    # Success v·ªõi fallback model
                                    break
                                else:
                                    # Log error ƒë·ªÉ debug
                                    try:
                                        error_data = response.json()
                                        print(f"   ‚ö†Ô∏è  Fallback model {fallback_model} failed: {error_data.get('error', {}).get('message', 'Unknown')[:100]}")
                                    except:
                                        pass
                            except:
                                continue
            except:
                pass
        
        # Debug: check error response
        if response.status_code != 200:
            try:
                error_data = response.json()
                print(f"‚ö†Ô∏è  Groq API error {response.status_code}: {error_data}")
            except:
                print(f"‚ö†Ô∏è  Groq API error {response.status_code}: {response.text[:200]}")
            response.raise_for_status()
        
        data = response.json()
        
        # Debug: log response ƒë·ªÉ hi·ªÉu structure
        try:
            print(f"   üìä Response keys: {list(data.keys())}")
            if "choices" in data:
                print(f"   üìä Choices count: {len(data['choices'])}")
        except:
            pass
        
        # Debug: log response structure
        if not data.get("choices"):
            try:
                print(f"‚ö†Ô∏è  Response kh√¥ng c√≥ choices. Keys: {list(data.keys())}")
                print(f"   Full response: {json.dumps(data, indent=2)[:500]}")
            except:
                pass
            return None
        
        # Parse JSON t·ª´ response
        if data.get("choices") and len(data["choices"]) > 0:
            choice = data["choices"][0]
            
            # Debug: log choice structure
            try:
                print(f"   üìä Choice keys: {list(choice.keys())}")
                if "finish_reason" in choice:
                    print(f"   üìä Finish reason: {choice['finish_reason']}")
            except:
                pass
            
            if "message" not in choice:
                try:
                    print(f"‚ö†Ô∏è  Choice kh√¥ng c√≥ message: {choice.keys()}")
                    print(f"   Full choice: {json.dumps(choice, indent=2)[:500]}")
                except:
                    pass
                return None
            
            content = choice["message"].get("content", "").strip()
            
            # Debug: log content
            if not content:
                try:
                    print(f"‚ö†Ô∏è  Content tr·ªëng. Message keys: {list(choice['message'].keys())}")
                    print(f"   Full message: {json.dumps(choice['message'], indent=2)[:500]}")
                except:
                    pass
                return None
            
            # Debug: log content length v√† preview
            try:
                print(f"   üìä Content length: {len(content)} chars")
                print(f"   üìä Content preview (first 200): {content[:200]}")
            except:
                pass
            
            # Remove markdown code blocks v√† text tr∆∞·ªõc JSON
            content_stripped = content.strip()
            
            # X·ª≠ l√Ω markdown code blocks
            if content_stripped.startswith("```"):
                # Extract JSON t·ª´ code block
                lines = content.split("\n")
                json_start = None
                json_end = None
                
                for i, line in enumerate(lines):
                    line_stripped = line.strip()
                    # T√¨m d√≤ng b·∫Øt ƒë·∫ßu code block (```json ho·∫∑c ```)
                    if line_stripped.startswith("```json") or (line_stripped.startswith("```") and json_start is None):
                        json_start = i + 1
                    # T√¨m d√≤ng k·∫øt th√∫c code block
                    elif line_stripped == "```" and json_start is not None:
                        json_end = i
                        break
                
                if json_start is not None:
                    if json_end is not None:
                        content = "\n".join(lines[json_start:json_end]).strip()
                    else:
                        # Kh√¥ng c√≥ closing ```, l·∫•y t·ª´ json_start ƒë·∫øn cu·ªëi
                        content = "\n".join(lines[json_start:]).strip()
            
            # X·ª≠ l√Ω text tr∆∞·ªõc JSON (nh∆∞ "D∆∞·ªõi ƒë√¢y l√† JSON object...")
            # T√¨m v·ªã tr√≠ b·∫Øt ƒë·∫ßu c·ªßa JSON object {
            lines = content.split("\n")
            json_start_idx = None
            for i, line in enumerate(lines):
                line_stripped = line.strip()
                # T√¨m d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng { (JSON object)
                if line_stripped.startswith("{"):
                    json_start_idx = i
                    break
            
            if json_start_idx is not None and json_start_idx > 0:
                # C√≥ text tr∆∞·ªõc JSON, ch·ªâ l·∫•y ph·∫ßn JSON
                content = "\n".join(lines[json_start_idx:]).strip()
                try:
                    print(f"   üìä Removed {json_start_idx} lines of text before JSON")
                except:
                    pass
            
            # T√¨m v·ªã tr√≠ k·∫øt th√∫c c·ªßa JSON object }
            # ƒê·∫øm s·ªë { v√† } ƒë·ªÉ t√¨m JSON object ho√†n ch·ªânh
            brace_count = 0
            json_end_idx = None
            lines = content.split("\n")
            for i, line in enumerate(lines):
                brace_count += line.count("{") - line.count("}")
                if brace_count == 0 and i > 0:
                    json_end_idx = i + 1
                    break
            
            if json_end_idx is not None and json_end_idx < len(lines):
                # C√≥ text sau JSON, ch·ªâ l·∫•y ph·∫ßn JSON
                content = "\n".join(lines[:json_end_idx]).strip()
                try:
                    print(f"   üìä Removed text after JSON")
                except:
                    pass
            
            # Debug
            try:
                print(f"   üìä After cleaning: {len(content)} chars")
            except:
                pass
            
            try:
                extracted = json.loads(content)
                return extracted
            except json.JSONDecodeError as e:
                try:
                    print(f"‚ö†Ô∏è  JSON parse error: {str(e)[:100]}")
                    print(f"   Content preview: {content[:200]}")
                except:
                    pass
                return None
        else:
            try:
                print(f"‚ö†Ô∏è  Groq response kh√¥ng c√≥ choices")
            except:
                pass
            return None
            
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói extract Groq AI: {str(e)[:100]}")
        except:
            pass
        return None


def extract_product_details_from_api(
    product_id: str,
    timeout: int = 30
) -> Optional[Dict[str, Any]]:
    """
    Extract product details t·ª´ Tiki API
    
    Args:
        product_id: Product ID t·ª´ Tiki
        timeout: Timeout cho request (seconds)
    
    Returns:
        Dict ch·ª©a product details theo schema, ho·∫∑c None n·∫øu l·ªói
    
    Reference: https://open.tiki.vn/docs/docs/current/api-references/product-api/#get-a-product-v2-1
    """
    if not TIKI_API_TOKEN:
        try:
            print("‚ö†Ô∏è  TIKI_API_TOKEN ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh!")
            print("   H√£y set TIKI_API_TOKEN trong .env file")
            print("   V√≠ d·ª•: TIKI_API_TOKEN=your_token_here")
        except:
            pass
        return None
    
    if not product_id:
        try:
            print("‚ö†Ô∏è  Product ID kh√¥ng ƒë∆∞·ª£c cung c·∫•p")
        except:
            pass
        return None
    
    try:
        # G·ªçi Tiki API ƒë·ªÉ l·∫•y product details
        api_url = f"{TIKI_API_BASE_URL}/products/{product_id}"
        
        headers = {
            "tiki-api": TIKI_API_TOKEN,
            "Content-Type": "application/json"
        }
        
        try:
            print(f"   üì° G·ªçi Tiki API: {api_url}")
        except:
            pass
        
        response = requests.get(api_url, headers=headers, timeout=timeout)
        
        if response.status_code == 404:
            try:
                print(f"   ‚ö†Ô∏è  Product kh√¥ng t·ªìn t·∫°i (404)")
            except:
                pass
            return None
        
        if response.status_code == 401:
            try:
                print(f"   ‚ö†Ô∏è  Unauthorized - Token kh√¥ng h·ª£p l·ªá (401)")
            except:
                pass
            return None
        
        if response.status_code == 429:
            try:
                print(f"   ‚ö†Ô∏è  Rate limit exceeded (429)")
            except:
                pass
            return None
        
        response.raise_for_status()
        api_data = response.json()
        
        try:
            print(f"   ‚úì Nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ API")
        except:
            pass
        
        # Transform API response th√†nh schema c·ªßa ch√∫ng ta
        # API response structure c√≥ th·ªÉ kh√°c, c·∫ßn map l·∫°i
        details = {
            "product_id": str(product_id),
            "name": api_data.get("name", ""),
            "price": {
                "current_price": api_data.get("price", 0),
                "original_price": api_data.get("original_price", api_data.get("price", 0)),
                "discount_percent": 0,
                "currency": "VND"
            },
            "description": api_data.get("description", ""),
            "specifications": {},
            "detailed_info": api_data.get("description", ""),  # C√≥ th·ªÉ l·∫•y t·ª´ description
            "customer_reviews": [],
            "rating": {
                "average": api_data.get("rating_average", 0),
                "total_reviews": api_data.get("review_count", 0)
            },
            "seller": {
                "name": api_data.get("seller_name", ""),
                "is_official": api_data.get("is_official", False)
            },
            "shipping": {
                "free_shipping": api_data.get("free_shipping", False),
                "fast_delivery": api_data.get("fast_delivery", False),
                "delivery_time": ""
            },
            "stock": {
                "available": api_data.get("inventory_status", "available") == "available",
                "quantity": api_data.get("inventory_quantity", 0),
                "stock_status": api_data.get("inventory_status", "")
            },
            "category_path": [],
            "brand": api_data.get("brand", ""),
            "warranty": api_data.get("warranty", ""),
            "promotions": [],
            "ai_summary": {
                "product_summary": [],
                "service_summary": [],
                "positive_count": {},
                "negative_count": {}
            }
        }
        
        # Extract specifications t·ª´ attributes n·∫øu c√≥
        if "attributes" in api_data and isinstance(api_data["attributes"], list):
            for attr in api_data["attributes"]:
                if isinstance(attr, dict) and "name" in attr and "value" in attr:
                    details["specifications"][attr["name"]] = str(attr["value"])
        
        # Extract category path n·∫øu c√≥
        if "category" in api_data:
            category = api_data["category"]
            if isinstance(category, dict) and "path" in category:
                # Category path c√≥ th·ªÉ l√† string ho·∫∑c array
                path = category["path"]
                if isinstance(path, str):
                    details["category_path"] = [p.strip() for p in path.split(">") if p.strip()]
                elif isinstance(path, list):
                    details["category_path"] = [str(p) for p in path]
        
        # Calculate discount percent
        if details["price"]["original_price"] and details["price"]["current_price"]:
            if details["price"]["original_price"] > details["price"]["current_price"]:
                discount = ((details["price"]["original_price"] - details["price"]["current_price"]) / details["price"]["original_price"]) * 100
                details["price"]["discount_percent"] = round(discount, 1)
        
        # Validate v√† enrich
        details = validate_and_enrich_product_details(details, product_id, f"https://tiki.vn/p{product_id}")
        
        return details
        
    except requests.exceptions.RequestException as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói khi g·ªçi Tiki API: {str(e)[:100]}")
        except:
            pass
        return None
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ API: {str(e)[:100]}")
        except:
            pass
        return None


def extract_product_details_from_api_endpoints(
    product_url: str,
    product_id: str = None,
    timeout: int = 30
) -> Optional[Dict[str, Any]]:
    """
    Extract product details b·∫±ng c√°ch t·ª± ƒë·ªông ph√°t hi·ªán v√† g·ªçi c√°c API endpoints c·ªßa Tiki
    
    C√°c API endpoints ƒë∆∞·ª£c th·ª≠:
    - https://tiki.vn/api/v2/products/{product_id}
    - https://tiki.vn/api/reviews?product_id={product_id}
    - https://tiki.vn/api/nps/summary/{product_id} (AI summary)
    - https://tiki.vn/api/pdp/quickview (v·ªõi product_id)
    
    Args:
        product_url: URL c·ªßa product page
        product_id: Product ID (optional, s·∫Ω extract t·ª´ URL n·∫øu kh√¥ng c√≥)
        timeout: Timeout cho m·ªói request (seconds)
    
    Returns:
        Dict ch·ª©a product details theo schema, ho·∫∑c None n·∫øu l·ªói
    """
    if not product_id:
        product_id = extract_product_id(product_url)
        if not product_id:
            try:
                print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ extract product_id t·ª´ URL: {product_url}")
            except:
                pass
            return None
    
    # Headers gi·ªëng browser
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": product_url,
        "Origin": "https://tiki.vn"
    }
    
    result = {
        "product_id": str(product_id),
        "name": "",
        "brand": "",
        "categories": [],
        "price": {
            "current": 0,
            "original": 0,
            "discount_percent": 0
        },
        "stock_status": "",
        "seller": {
            "name": "",
            "is_official_store": False
        },
        "shipping": {
            "methods": [],
            "delivery_time_estimate": ""
        },
        "promotions": [],
        "specifications_table": [],
        "ai_review_summary": {
            "product_positive": [],
            "product_negative": [],
            "service_positive": [],
            "service_negative": [],
            "counts": {
                "product_positive": 0,
                "product_negative": 0,
                "service_positive": 0,
                "service_negative": 0
            }
        }
    }
    
    # API endpoints ƒë·ªÉ th·ª≠
    api_endpoints = [
        {
            "name": "product_details",
            "url": f"https://tiki.vn/api/v2/products/{product_id}",
            "method": "GET"
        },
        {
            "name": "quickview",
            "url": f"https://tiki.vn/api/pdp/quickview",
            "method": "POST",
            "data": {"product_id": product_id}
        },
        {
            "name": "reviews",
            "url": f"https://tiki.vn/api/reviews",
            "method": "GET",
            "params": {"product_id": product_id, "limit": 50}
        },
        {
            "name": "ai_summary",
            "url": f"https://tiki.vn/api/nps/summary/{product_id}",
            "method": "GET"
        }
    ]
    
    api_responses = {}
    
    # G·ªçi t·∫•t c·∫£ c√°c API endpoints
    for endpoint in api_endpoints:
        try:
            if endpoint["method"] == "GET":
                if "params" in endpoint:
                    response = requests.get(
                        endpoint["url"],
                        headers=headers,
                        params=endpoint["params"],
                        timeout=timeout
                    )
                else:
                    response = requests.get(
                        endpoint["url"],
                        headers=headers,
                        timeout=timeout
                    )
            elif endpoint["method"] == "POST":
                response = requests.post(
                    endpoint["url"],
                    headers={**headers, "Content-Type": "application/json"},
                    json=endpoint.get("data", {}),
                    timeout=timeout
                )
            else:
                continue
            
            if response.status_code == 200:
                try:
                    api_responses[endpoint["name"]] = response.json()
                    try:
                        print(f"   ‚úì {endpoint['name']}: OK")
                    except:
                        pass
                except json.JSONDecodeError:
                    try:
                        print(f"   ‚ö†Ô∏è  {endpoint['name']}: Invalid JSON")
                    except:
                        pass
            else:
                try:
                    print(f"   ‚ö†Ô∏è  {endpoint['name']}: {response.status_code}")
                except:
                    pass
        except requests.exceptions.RequestException as e:
            try:
                print(f"   ‚úó {endpoint['name']}: {str(e)[:50]}")
            except:
                pass
        except Exception as e:
            try:
                print(f"   ‚úó {endpoint['name']}: {str(e)[:50]}")
            except:
                pass
    
    # Parse product_details ho·∫∑c quickview
    product_data = api_responses.get("product_details") or api_responses.get("quickview") or {}
    
    if not product_data:
        try:
            print("‚ö†Ô∏è  Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu product t·ª´ API")
        except:
            pass
        return None
    
    # Extract basic info
    result["name"] = product_data.get("name") or product_data.get("title", "")
    result["brand"] = product_data.get("brand") or product_data.get("brand_name", "")
    
    # Extract price
    if "price" in product_data:
        result["price"]["current"] = int(product_data["price"])
    if "original_price" in product_data:
        result["price"]["original"] = int(product_data["original_price"])
    elif "list_price" in product_data:
        result["price"]["original"] = int(product_data["list_price"])
    
    if result["price"]["original"] and result["price"]["current"]:
        if result["price"]["original"] > result["price"]["current"]:
            discount = ((result["price"]["original"] - result["price"]["current"]) / result["price"]["original"]) * 100
            result["price"]["discount_percent"] = round(discount, 1)
    
    # Extract stock
    result["stock_status"] = product_data.get("inventory_status", product_data.get("stock_status", ""))
    
    # Extract seller
    if "seller" in product_data:
        seller_data = product_data["seller"]
        if isinstance(seller_data, dict):
            result["seller"]["name"] = seller_data.get("name", "")
            result["seller"]["is_official_store"] = seller_data.get("is_official", False)
        elif isinstance(seller_data, str):
            result["seller"]["name"] = seller_data
    
    # Extract categories
    if "categories" in product_data:
        categories = product_data["categories"]
        if isinstance(categories, list):
            result["categories"] = [str(c) for c in categories]
        elif isinstance(categories, dict) and "path" in categories:
            path = categories["path"]
            if isinstance(path, str):
                result["categories"] = [p.strip() for p in path.split(">") if p.strip()]
            elif isinstance(path, list):
                result["categories"] = [str(p) for p in path]
    
    # Extract specifications
    if "specifications" in product_data:
        specs = product_data["specifications"]
        if isinstance(specs, list):
            for spec in specs:
                if isinstance(spec, dict):
                    label = spec.get("name") or spec.get("label", "")
                    value = spec.get("value") or spec.get("text", "")
                    if label and value:
                        result["specifications_table"].append({
                            "label": str(label),
                            "value": str(value)
                        })
        elif isinstance(specs, dict):
            for key, value in specs.items():
                result["specifications_table"].append({
                    "label": str(key),
                    "value": str(value)
                })
    
    # Extract promotions
    if "promotions" in product_data:
        promotions = product_data["promotions"]
        if isinstance(promotions, list):
            result["promotions"] = [str(p) for p in promotions]
    
    # Extract shipping
    if "shipping" in product_data:
        shipping_data = product_data["shipping"]
        if isinstance(shipping_data, dict):
            if "methods" in shipping_data:
                result["shipping"]["methods"] = shipping_data["methods"]
            if "delivery_time" in shipping_data:
                result["shipping"]["delivery_time_estimate"] = shipping_data["delivery_time"]
    
    # Parse AI summary t·ª´ nps/summary endpoint
    ai_summary_data = api_responses.get("ai_summary", {})
    if ai_summary_data:
        # Parse structure t·ª´ AI summary API
        if "product" in ai_summary_data:
            product_summary = ai_summary_data["product"]
            if isinstance(product_summary, dict):
                if "positive" in product_summary:
                    positives = product_summary["positive"]
                    if isinstance(positives, list):
                        result["ai_review_summary"]["product_positive"] = [str(p) for p in positives]
                if "negative" in product_summary:
                    negatives = product_summary["negative"]
                    if isinstance(negatives, list):
                        result["ai_review_summary"]["product_negative"] = [str(n) for n in negatives]
                if "positive_count" in product_summary:
                    result["ai_review_summary"]["counts"]["product_positive"] = int(product_summary["positive_count"])
                if "negative_count" in product_summary:
                    result["ai_review_summary"]["counts"]["product_negative"] = int(product_summary["negative_count"])
        
        if "service" in ai_summary_data:
            service_summary = ai_summary_data["service"]
            if isinstance(service_summary, dict):
                if "positive" in service_summary:
                    positives = service_summary["positive"]
                    if isinstance(positives, list):
                        result["ai_review_summary"]["service_positive"] = [str(p) for p in positives]
                if "negative" in service_summary:
                    negatives = service_summary["negative"]
                    if isinstance(negatives, list):
                        result["ai_review_summary"]["service_negative"] = [str(n) for n in negatives]
                if "positive_count" in service_summary:
                    result["ai_review_summary"]["counts"]["service_positive"] = int(service_summary["positive_count"])
                if "negative_count" in service_summary:
                    result["ai_review_summary"]["counts"]["service_negative"] = int(service_summary["negative_count"])
    
    # Parse reviews n·∫øu c√≥
    reviews_data = api_responses.get("reviews", {})
    if reviews_data and "data" in reviews_data:
        # Reviews c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u v√†o result n·∫øu c·∫ßn
        pass
    
    return result


def extract_product_details_ai(
    product_url: str,
    product_id: str = None,
    product_name: str = None,
    timeout: int = 120
) -> Optional[Dict[str, Any]]:
    """
    Extract product details s·ª≠ d·ª•ng AI (Firecrawl v2/scrape + Groq)
    
    Args:
        product_url: URL c·ªßa product page
        product_id: Product ID (optional, s·∫Ω extract t·ª´ URL n·∫øu kh√¥ng c√≥)
        product_name: T√™n s·∫£n ph·∫©m (optional)
        timeout: Timeout cho request (seconds)
    
    Returns:
        Dict ch·ª©a product details theo schema, ho·∫∑c None n·∫øu l·ªói
    """
    # Check if Groq is enabled
    if not GROQ_ENABLED:
        try:
            print("‚ö†Ô∏è  Groq API ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh!")
            print("   H√£y set GROQ_API_KEY ho·∫∑c GROQ_API_KEYS trong .env file")
            print("   V√≠ d·ª•: GROQ_API_KEY=gsk_your_key_here")
        except:
            pass
        return None
    
    # Extract product_id t·ª´ URL n·∫øu ch∆∞a c√≥
    if not product_id:
        product_id = extract_product_id(product_url)
        if not product_id:
            try:
                print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ extract product_id t·ª´ URL: {product_url}")
            except:
                pass
            return None
    
    # Step 1: Scrape v·ªõi Firecrawl v2 (c·∫£ markdown v√† HTML)
    try:
        print(f"   üì• Scraping v·ªõi Firecrawl v2 (markdown + HTML)...")
    except:
        pass
    
    scrape_result = scrape_with_firecrawl_v2(product_url, timeout=timeout)
    if not scrape_result:
        try:
            print(f"   ‚úó Scrape th·∫•t b·∫°i")
        except:
            pass
        return None
    
    markdown = scrape_result.get("markdown", "")
    html = scrape_result.get("html", "")
    
    try:
        markdown_len = len(markdown) if markdown else 0
        html_len = len(html) if html else 0
        print(f"   ‚úì Scraped: {markdown_len} chars markdown, {html_len} chars HTML")
    except:
        pass
    
    # Step 1.5: Parse HTML tr·ª±c ti·∫øp ƒë·ªÉ extract AI summary v√† detailed info
    html_parsed_data = {}
    
    if html:
        try:
            print(f"   üîç Parsing HTML ƒë·ªÉ extract AI summary v√† th√¥ng tin chi ti·∫øt...")
        except:
            pass
        
        # Extract AI summary t·ª´ HTML
        ai_summary = extract_ai_summary_from_html(html)
        if ai_summary:
            html_parsed_data["ai_summary"] = ai_summary
            try:
                product_count = len(ai_summary.get("product_summary", []))
                service_count = len(ai_summary.get("service_summary", []))
                print(f"   ‚úì Extracted AI summary: {product_count} product items, {service_count} service items")
            except:
                pass
        
        # Extract detailed info t·ª´ HTML
        detailed_info = extract_detailed_info_from_html(html)
        if detailed_info:
            html_parsed_data["detailed_info"] = detailed_info
            try:
                print(f"   ‚úì Extracted detailed info: {len(detailed_info)} chars")
            except:
                pass
    
    # Step 2: Extract v·ªõi Groq AI (s·ª≠ d·ª•ng c·∫£ markdown v√† HTML)
    try:
        print(f"   üß† Extracting v·ªõi Groq AI...")
    except:
        pass
    
    details = extract_with_groq_ai(
        markdown_content=markdown if markdown else None,
        html_content=html if html else None,
        product_id=product_id,
        product_name=product_name
    )
    
    if details:
        try:
            print(f"   ‚úì Extract th√†nh c√¥ng")
        except:
            pass
        
        # Merge d·ªØ li·ªáu t·ª´ HTML parsing v√†o details (∆∞u ti√™n HTML parsing n·∫øu c√≥)
        if html_parsed_data:
            # Merge ai_summary
            if "ai_summary" in html_parsed_data:
                # N·∫øu AI ƒë√£ extract ƒë∆∞·ª£c m·ªôt ph·∫ßn, merge l·∫°i
                if "ai_summary" in details and details["ai_summary"]:
                    # Merge: ∆∞u ti√™n HTML parsing, nh∆∞ng gi·ªØ l·∫°i d·ªØ li·ªáu t·ª´ AI n·∫øu HTML kh√¥ng c√≥
                    html_ai = html_parsed_data["ai_summary"]
                    ai_ai = details["ai_summary"]
                    
                    merged_ai_summary = {
                        "product_summary": html_ai.get("product_summary") or ai_ai.get("product_summary", []),
                        "service_summary": html_ai.get("service_summary") or ai_ai.get("service_summary", []),
                        "positive_count": {**ai_ai.get("positive_count", {}), **html_ai.get("positive_count", {})},
                        "negative_count": {**ai_ai.get("negative_count", {}), **html_ai.get("negative_count", {})}
                    }
                    details["ai_summary"] = merged_ai_summary
                else:
                    # Ch·ªâ c√≥ HTML parsing
                    details["ai_summary"] = html_parsed_data["ai_summary"]
            
            # Merge detailed_info (∆∞u ti√™n HTML parsing)
            if "detailed_info" in html_parsed_data and html_parsed_data["detailed_info"]:
                # Ch·ªâ ghi ƒë√® n·∫øu HTML parsing c√≥ d·ªØ li·ªáu v√† AI kh√¥ng c√≥ ho·∫∑c c√≥ √≠t h∆°n
                current_detailed_info = details.get("detailed_info", "")
                if not current_detailed_info or len(current_detailed_info) < len(html_parsed_data["detailed_info"]):
                    details["detailed_info"] = html_parsed_data["detailed_info"]
        
        # Validate v√† enrich data
        details = validate_and_enrich_product_details(details, product_id, product_url)
    else:
        try:
            print(f"   ‚úó Extract th·∫•t b·∫°i")
        except:
            pass
        # N·∫øu AI extraction th·∫•t b·∫°i nh∆∞ng c√≥ d·ªØ li·ªáu t·ª´ HTML parsing, v·∫´n tr·∫£ v·ªÅ
        if html_parsed_data:
            try:
                print(f"   ‚ö†Ô∏è  S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ HTML parsing")
            except:
                pass
            # T·∫°o structure c∆° b·∫£n
            details = {
                "product_id": product_id,
                "name": product_name or "",
                "price": {},
                "detailed_info": html_parsed_data.get("detailed_info", ""),
                "ai_summary": html_parsed_data.get("ai_summary", {
                    "product_summary": [],
                    "service_summary": [],
                    "positive_count": {},
                    "negative_count": {}
                })
            }
            details = validate_and_enrich_product_details(details, product_id, product_url)
    
    return details


def validate_and_enrich_product_details(
    details: Dict[str, Any],
    product_id: str,
    product_url: str
) -> Dict[str, Any]:
    """
    Validate v√† enrich product details
    
    Args:
        details: Raw extracted details
        product_id: Product ID
        product_url: Product URL
    
    Returns:
        Validated and enriched details
    """
    # Ensure product_id is set
    if not details.get("product_id"):
        details["product_id"] = product_id
    
    # Ensure price structure
    if "price" not in details:
        details["price"] = {}
    
    if "currency" not in details["price"]:
        details["price"]["currency"] = "VND"
    
    # Ensure specifications is object
    if "specifications" not in details:
        details["specifications"] = {}
    elif not isinstance(details["specifications"], dict):
        details["specifications"] = {}
    
    # Ensure detailed_info is string
    if "detailed_info" not in details:
        details["detailed_info"] = ""
    elif not isinstance(details["detailed_info"], str):
        details["detailed_info"] = str(details["detailed_info"])
    
    # Ensure customer_reviews is array
    if "customer_reviews" not in details:
        details["customer_reviews"] = []
    elif not isinstance(details["customer_reviews"], list):
        details["customer_reviews"] = []
    else:
        # Validate each review structure
        validated_reviews = []
        for review in details["customer_reviews"]:
            if isinstance(review, dict):
                validated_review = {
                    "reviewer_name": review.get("reviewer_name", ""),
                    "rating": review.get("rating", 0),
                    "review_text": review.get("review_text", ""),
                    "review_date": review.get("review_date", ""),
                    "verified_purchase": review.get("verified_purchase", False)
                }
                validated_reviews.append(validated_review)
        details["customer_reviews"] = validated_reviews
    
    # Ensure category_path is array
    if "category_path" not in details:
        details["category_path"] = []
    elif not isinstance(details["category_path"], list):
        details["category_path"] = []
    
    # Ensure promotions is array
    if "promotions" not in details:
        details["promotions"] = []
    elif not isinstance(details["promotions"], list):
        details["promotions"] = []
    
    # Ensure ai_summary is object
    if "ai_summary" not in details:
        details["ai_summary"] = {}
    elif not isinstance(details["ai_summary"], dict):
        details["ai_summary"] = {}
    else:
        # Validate ai_summary structure
        ai_summary = details["ai_summary"]
        if not isinstance(ai_summary.get("product_summary"), list):
            ai_summary["product_summary"] = ai_summary.get("product_summary") if ai_summary.get("product_summary") else []
        if not isinstance(ai_summary.get("service_summary"), list):
            ai_summary["service_summary"] = ai_summary.get("service_summary") if ai_summary.get("service_summary") else []
        if not isinstance(ai_summary.get("positive_count"), dict):
            ai_summary["positive_count"] = ai_summary.get("positive_count") if ai_summary.get("positive_count") else {}
        if not isinstance(ai_summary.get("negative_count"), dict):
            ai_summary["negative_count"] = ai_summary.get("negative_count") if ai_summary.get("negative_count") else {}
    
    # Add metadata
    details["_metadata"] = {
        "extracted_at": datetime.now().isoformat(),
        "source_url": product_url,
        "extraction_method": "ai_groq"
    }
    
    return details


def crawl_product_details(
    products: List[Dict[str, Any]],
    max_products: int = None,
    timeout: int = 120,
    delay_between_requests: float = 1.0
) -> List[Dict[str, Any]]:
    """
    Crawl product details t·ª´ list products
    
    Args:
        products: List products (c√≥ 'url', 'product_id', 'name')
        max_products: Gi·ªõi h·∫°n s·ªë products
        timeout: Timeout cho m·ªói request (seconds)
        delay_between_requests: Delay gi·ªØa c√°c requests (seconds)
    
    Returns:
        List product details
    """
    import time
    
    if max_products:
        products = products[:max_products]
    
    all_details = []
    total = len(products)
    
    for i, product in enumerate(products, 1):
        product_url = product.get('url', '')
        product_id = product.get('product_id', '')
        product_name = product.get('name', 'N/A')
        
        if not product_url:
            continue
        
        try:
            print(f"[{i}/{total}] üì¶ Extracting details: {product_name} (ID: {product_id})")
        except (ValueError, OSError):
            try:
                print(f"[{i}/{total}] Extracting: {product_name} (ID: {product_id})", file=sys.stderr)
            except:
                pass
        
        details = extract_product_details_ai(
            product_url=product_url,
            product_id=product_id,
            product_name=product_name,
            timeout=timeout
        )
        
        if details:
            try:
                print(f"   ‚úì Th√†nh c√¥ng")
            except (ValueError, OSError):
                try:
                    print(f"   Success", file=sys.stderr)
                except:
                    pass
            all_details.append(details)
        else:
            try:
                print(f"   ‚úó Th·∫•t b·∫°i")
            except (ValueError, OSError):
                try:
                    print(f"   Failed", file=sys.stderr)
                except:
                    pass
        
        # Delay gi·ªØa c√°c requests
        if i < total and delay_between_requests > 0:
            time.sleep(delay_between_requests)
    
    return all_details


def save_product_details_to_json(
    product_details: List[Dict[str, Any]],
    output_file: str
):
    """
    L∆∞u product details v√†o file JSON
    
    Args:
        product_details: List c√°c product details
        output_file: ƒê∆∞·ªùng d·∫´n file output
    """
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    result = {
        "crawl_time": datetime.now().isoformat(),
        "total_products": len(product_details),
        "products": product_details
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    try:
        print(f"üíæ ƒê√£ l∆∞u {len(product_details)} product details v√†o: {output_file}")
    except (ValueError, OSError):
        try:
            print(f"Saved {len(product_details)} product details to: {output_file}", file=sys.stderr)
        except:
            pass


def load_product_details_from_json(json_file: str) -> List[Dict[str, Any]]:
    """
    Load product details t·ª´ file JSON
    
    Args:
        json_file: ƒê∆∞·ªùng d·∫´n file JSON
    
    Returns:
        List c√°c product details
    """
    if not os.path.exists(json_file):
        return []
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if isinstance(data, dict) and 'products' in data:
                return data['products']
            elif isinstance(data, list):
                return data
            return []
    except json.JSONDecodeError as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói khi parse JSON: {e}")
        except:
            pass
        return []
    except Exception as e:
        try:
            print(f"‚ö†Ô∏è  L·ªói khi load file: {e}")
        except:
            pass
        return []

