"""
Configuration module cho common modules
Load t·ª´ file .env trong src/common/ ho·∫∑c t·ª´ environment variables
"""

import logging
import os
from pathlib import Path

logger = logging.getLogger(__name__)

# T√¨m file .env ·ªü root (l√™n 2 c·∫•p t·ª´ src/common/)
current_dir = Path(__file__).parent
env_file = current_dir.parent.parent / ".env"

# Load .env n·∫øu c√≥
if env_file.exists():
    try:
        from dotenv import load_dotenv

        # Load v·ªõi override=True ƒë·ªÉ ƒë·∫£m b·∫£o c√°c gi√° tr·ªã t·ª´ .env ƒë∆∞·ª£c s·ª≠ d·ª•ng
        load_dotenv(env_file, override=True)
        logger.info(f"‚úÖ ƒê√£ load .env t·ª´: {env_file.absolute()}")
    except ImportError:
        # N·∫øu kh√¥ng c√≥ python-dotenv, b·ªè qua
        logger.warning("‚ö†Ô∏è  python-dotenv ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, kh√¥ng th·ªÉ load .env")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  L·ªói khi load .env: {e}")
else:
    logger.debug(f"üìù File .env kh√¥ng t·ªìn t·∫°i t·∫°i: {env_file.absolute()}")

# Groq configuration
# C√°c model Groq c√≥ s·∫µn: openai/gpt-oss-120b, llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768, gemma2-9b-it
GROQ_CONFIG = {
    "enabled": os.getenv("GROQ_ENABLED", "false").lower() == "true",
    "api_key": os.getenv("GROQ_API_KEY", ""),
    "base_url": os.getenv("GROQ_API_BASE", "https://api.groq.com/openai/v1"),
    "model": os.getenv("GROQ_MODEL", "openai/gpt-oss-120b"),  # Model m·∫∑c ƒë·ªãnh Groq
}

# Discord configuration
DISCORD_CONFIG = {
    "webhook_url": os.getenv("DISCORD_WEBHOOK_URL", ""),
    "enabled": os.getenv("DISCORD_ENABLED", "false").lower() == "true",
}
