"""
Configuration module cho common modules Load t·ª´ file .env trong src/common/ ho·∫∑c t·ª´ environment
variables.
"""

import logging
import os
from pathlib import Path

logger = logging.getLogger(__name__)

# T√¨m file .env ·ªü root (l√™n 2 c·∫•p t·ª´ src/common/)
current_dir = Path(__file__).parent
env_file = current_dir.parent.parent / ".env"

# Load .env n·∫øu c√≥
if env_file.exists():
    try:
        from dotenv import load_dotenv

        # Load v·ªõi override=True ƒë·ªÉ ƒë·∫£m b·∫£o c√°c gi√° tr·ªã t·ª´ .env ƒë∆∞·ª£c s·ª≠ d·ª•ng
        load_dotenv(env_file, override=True)
        logger.info(f"‚úÖ ƒê√£ load .env t·ª´: {env_file.absolute()}")
    except ImportError:
        # N·∫øu kh√¥ng c√≥ python-dotenv, b·ªè qua
        logger.warning("‚ö†Ô∏è  python-dotenv ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, kh√¥ng th·ªÉ load .env")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  L·ªói khi load .env: {e}")
else:
    logger.debug(f"üìù File .env kh√¥ng t·ªìn t·∫°i t·∫°i: {env_file.absolute()}")

# AI configuration (Groq or OpenRouter)
# Models examples: 
# Groq: llama-3.3-70b-versatile, llama-3.1-8b-instant
# OpenRouter: arcee-ai/trinity-large-preview:free, google/learnlm-1.5-pro-experimental:free
AI_CONFIG = {
    "enabled": os.getenv("AI_ENABLED", os.getenv("GROQ_ENABLED", "false")).lower() == "true",
    "api_key": os.getenv("AI_API_KEY", os.getenv("GROQ_API_KEY", "")),
    "base_url": os.getenv("AI_API_BASE", os.getenv("GROQ_API_BASE", "https://api.groq.com/openai/v1")),
    "model": os.getenv("AI_MODEL", os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")),
}

# Discord configuration
DISCORD_CONFIG = {
    "webhook_url": os.getenv("DISCORD_WEBHOOK_URL", ""),
    "enabled": os.getenv("DISCORD_ENABLED", "false").lower() == "true",
}

# Short Name AI Configuration
SHORT_NAME_CONFIG = {
    "use_ai": os.getenv("SHORT_NAME_USE_AI", "true").lower() == "true",
}
