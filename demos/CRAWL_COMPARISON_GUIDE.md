"""
ğŸ“‹ GUIDE: SELENIUM vs ASYNCHTTP - Chi tiáº¿t so sÃ¡nh & Recommendations

File nÃ y giáº£i thÃ­ch chi tiáº¿t sá»± khÃ¡c biá»‡t giá»¯a 2 cÃ¡ch crawl product detail:
1. Selenium (hiá»‡n táº¡i Ä‘ang dÃ¹ng)
2. AsyncHTTP (má»›i - khÃ´ng dÃ¹ng Selenium)
"""

# ============================================================================
# ğŸ“Œ QUICK SUMMARY
# ============================================================================

"""
SELENIUM
--------
âœ“ Load JavaScript â†’ dynamic content
âœ“ Capture sales_count (sá»‘ lÆ°á»£ng Ä‘Ã£ bÃ¡n)
âœ“ Full page rendering
âœ“ Handle interactive elements
âœ“ Cookie/session management

âœ— Cháº­m: 30-60s per product
âœ— TÃ i nguyÃªn: CPU 50-100%, Memory 200-500MB per instance
âœ— KhÃ³ scale: 1 Selenium driver â‰ˆ 1 process â†’ khÃ´ng thá»ƒ parallel nhiá»u
âœ— Timeout/crash risk cao khi cÃ³ nhiá»u tasks

ASYNCHTTP (no Selenium)
-----------------------
âœ“ Nhanh: 3-8s per product (5-10x faster)
âœ“ TÃ i nguyÃªn: CPU <5%, Memory 50-100MB
âœ“ Dá»… scale: 100+ concurrent requests
âœ“ Lightweight: LÃ½ tÆ°á»Ÿng cho Airflow DAG
âœ“ Reliable: Ãt crash/timeout

âœ— KhÃ´ng load JavaScript â†’ thiáº¿u dynamic content
âœ— Sales_count cÃ³ thá»ƒ khÃ´ng Ä‘áº§y Ä‘á»§ (hoáº·c láº¥y tá»« static page)
âœ— Comments/reviews khÃ´ng láº¥y Ä‘Æ°á»£c (AJAX loading)
âœ— CÃ³ thá»ƒ bá»‹ block náº¿u abuse request rate
"""

# ============================================================================
# ğŸ”„ DETAILED COMPARISON TABLE
# ============================================================================

COMPARISON = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                        â”‚
â”‚          METRIC              SELENIUM         ASYNCHTTP               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  Speed                       30-60s/product   3-8s/product â­â­â­     â”‚
â”‚  Speedup Factor              1x               5-10x faster âœ“           â”‚
â”‚                                                                        â”‚
â”‚  CPU Usage                   50-100% Ã— cores  <5% Ã— cores âœ“           â”‚
â”‚  Memory per product          100-200MB        10-20MB âœ“               â”‚
â”‚  Parallelization             Hard, 1:1        Easy, 100:1 âœ“           â”‚
â”‚                              mapping          concurrent              â”‚
â”‚                                                                        â”‚
â”‚  Data Completeness           95-100%          80-90%                  â”‚
â”‚  Sales count (qty sold)      âœ“ Got it         âœ— Missing (usually)     â”‚
â”‚  Product name                âœ“ Got it         âœ“ Got it                â”‚
â”‚  Price                       âœ“ Got it         âœ“ Got it                â”‚
â”‚  Rating/Reviews              âœ“ Got it         âœ“ Got it                â”‚
â”‚  Images                      âœ“ Got it         âœ“ Got it                â”‚
â”‚  Specifications              âœ“ Got it         âœ“ Got it                â”‚
â”‚  Comments                    âœ“ Got it         âœ— AJAX (need Selenium)  â”‚
â”‚                                                                        â”‚
â”‚  Setup Complexity            Low              Very Low âœ“              â”‚
â”‚  Error Handling              Medium           Easy âœ“                  â”‚
â”‚  Maintenance Cost            High             Low âœ“                   â”‚
â”‚                                                                        â”‚
â”‚  Best for:                   Complete data,   Bulk crawling,          â”‚
â”‚                              details only     fast processing âœ“       â”‚
â”‚                                                                        â”‚
â”‚  100 Products:               ~1-2 hours âŒ    ~8-15 min âœ“             â”‚
â”‚  1000 Products:              ~10-20 hours âŒ  ~1.5-2 hours âœ“          â”‚
â”‚  10000 Products:             ~4-9 days âŒâŒ   ~15-24 hours âœ“          â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

# ============================================================================
# ğŸ’¡ USE CASES & RECOMMENDATIONS
# ============================================================================

USE_CASES = """
USE CASE 1: Crawl thá»‰nh thoáº£ng (1-10 products)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ RECOMMENDATION: Selenium âœ“
WHY: Setup simple, khÃ´ng cáº§n worry vá» rate limit, data Ä‘áº§y Ä‘á»§
EXAMPLE: Admin crawl tá»«ng sáº£n pháº©m Ä‘á»ƒ verify data


USE CASE 2: Batch crawl hÃ ng ngÃ y (100-500 products)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ RECOMMENDATION: AsyncHTTP âœ“â­
WHY: 
  - Nhanh hÆ¡n 10x â†’ crawl 500 products trong 1-2 tiáº¿ng
  - Selenium sáº½ máº¥t 10-20 tiáº¿ng (cháº¡y qua Ä‘Ãªm)
  - 80-90% dá»¯ liá»‡u Ä‘á»§ dÃ¹ng cho analytics
  - TÃ i nguyÃªn server tiáº¿t kiá»‡m
EXAMPLE: Daily product crawl tá»« Tiki catalog


USE CASE 3: Real-time crawl (on-demand)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ RECOMMENDATION: AsyncHTTP + Fallback âœ“â­â­
HYBRID APPROACH:
  1. Thá»­ AsyncHTTP trÆ°á»›c (3-8s, success rate 90%)
  2. Náº¿u bá»‹ block/timeout â†’ fallback Selenium (recover)
  3. Náº¿u thiáº¿u sales_count â†’ fallback Selenium
  4. 95% cases giáº£i quyáº¿t báº±ng AsyncHTTP

BENEFIT: Speed + reliability


USE CASE 4: Historical data crawl (1000+ products)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ RECOMMENDATION: AsyncHTTP + Redis Cache + Multi-worker âœ“â­â­â­
ARCHITECTURE:
  - AsyncHTTP: Main crawler (5-8s per product)
  - Redis cache: Avoid re-crawling (24-48h TTL)
  - Airflow workers: Parallel crawling (10 workers Ã— 10 concurrent = 100 concurrent)
  - Result: 1000 products ~15-20 min

BENEFIT: Extremely fast + scalable


USE CASE 5: Complete detailed data (need sales_count, comments, etc)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ RECOMMENDATION: Selenium âœ“
WHY: Cáº§n JavaScript rendering + AJAX loading
COST: 30-60s per product acceptable for 1x detailed crawl
"""

# ============================================================================
# ğŸ› ï¸ IMPLEMENTATION GUIDE
# ============================================================================

IMPLEMENTATION = """
CURRENT STATE (100% Selenium):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
src/pipelines/crawl/crawl_products_detail.py
  â””â”€ crawl_product_detail_with_selenium()
  â””â”€ crawl_product_detail_with_driver()

PROBLEM: Slow â†’ crawl 100 products = 1-2 hours âŒ


RECOMMENDED MIGRATION PATH:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 1 (QUICK WIN): Add AsyncHTTP option
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Modify: crawl_products_detail.py
Add:    crawl_product_detail_async_http()
Result: Users can choose which to use
Effort: 2-4 hours

BENEFITS:
  âœ“ Keep Selenium for backward compatibility
  âœ“ Allow users to try AsyncHTTP
  âœ“ No breaking changes


PHASE 2 (RECOMMENDED): Hybrid approach
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Modify: DAG/pipeline code
Add:    Fallback logic (AsyncHTTP â†’ Selenium)
Result: Best of both worlds

ARCHITECTURE:
  1. crawl_product_detail_async_http() with timeout=10s
  2. If timeout/error â†’ crawl_product_detail_with_selenium()
  3. This way: 90% fast (AsyncHTTP), 10% fallback (Selenium)

Effort:  1-2 hours
Benefit: 
  âœ“ 5-8x overall speedup (avg)
  âœ“ Minimal data loss
  âœ“ Progressive degradation (still get data if HTTP fails)


PHASE 3 (ADVANCED): Async scaling
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Use: aiohttp + asyncio for 100+ concurrent requests
Strategy: Crawl multiple products in parallel

BEFORE (Selenium, sequential):
  for url in urls:
    data = crawl_selenium(url)  # 50s Ã— 10 = 500s (8+ min)

AFTER (AsyncHTTP, parallel):
  tasks = [crawl_async(url) for url in urls]
  results = await asyncio.gather(*tasks)  # 50s total (50s)
  â†’ 10x speedup! âœ“

Effort: 3-4 hours
Setup: Airflow + CeleryExecutor for true parallelization
"""

# ============================================================================
# ğŸ“Š PERFORMANCE PROJECTIONS
# ============================================================================

PROJECTIONS = """
Assuming:
- Selenium: 45s avg per product
- AsyncHTTP: 6s avg per product
- Fallback rate: 10% (AsyncHTTP fails, need Selenium)
- Effective AsyncHTTP: 6s + (10% Ã— 45s) = 10.5s per product

CRAWL 1000 PRODUCTS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Current (Selenium only):
  1000 Ã— 45s = 45,000s = 12.5 hours âŒ

Option 1: AsyncHTTP (no fallback):
  1000 Ã— 6s = 6,000s = 1.67 hours âœ“
  Success rate: 90%, may miss 10% data

Option 2: AsyncHTTP + Fallback (Hybrid):
  (900 Ã— 6s) + (100 Ã— 45s) = 9,900s = 2.75 hours âœ“
  Success rate: 100%, complete data âœ“

Option 3: AsyncHTTP (parallel, 10 concurrent):
  1000 Ã— 6s Ã· 10 = 600s = 10 minutes âœ“â­
  Success rate: 90%

Option 4: Hybrid (parallel, 10 concurrent):
  [(900 Ã— 6s) + (100 Ã— 45s)] Ã· 10 = 16.5 minutes âœ“â­
  Success rate: 100%, complete data âœ“

VERDICT:
â†’ Option 4 recommended (16.5 min vs 12.5 hours!)
â†’ 45x speedup compared to current approach
â†’ Still get 100% complete data
"""

# ============================================================================
# ğŸ¯ ACTION PLAN
# ============================================================================

ACTION_PLAN = """
STEP 1: Run Demo Scripts
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python demos/demo_crawl_detail_async.py           # 3 URLs comparison
python demos/demo_crawl_detail_comparison.py      # Detailed benchmark

â†’ Observe: Performance, data quality, success rates
â†’ Review: Output JSON reports


STEP 2: Analyze Results
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Check: demos/data/test_output/
  - demo_crawl_detail_comparison.json
  - demo_crawl_comparison_detailed.json

Expected results:
  âœ“ AsyncHTTP: 5-10x faster
  âœ“ Data completeness: 80-90%
  âœ“ Both methods get product name/price/rating


STEP 3: Decision
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Question: Káº¿t quáº£ tháº¿ nÃ o?

If AsyncHTTP success rate = 100% and data good enough:
  â†’ MIGRATE to AsyncHTTP âœ“
  â†’ Modify DAG to use async crawling
  â†’ 45x speedup achieved!

If AsyncHTTP success rate < 80%:
  â†’ Use Hybrid approach (AsyncHTTP + Selenium fallback)
  â†’ Still get 5-10x speedup with safety net

If AsyncHTTP success rate < 50%:
  â†’ Keep Selenium for now
  â†’ Check Tiki API alternatives
  â†’ Review in 3 months


STEP 4: Implementation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Add crawl_product_detail_async_http() to crawl_products_detail.py
2. Add fallback logic in DAG
3. Update config (add ASYNC_CRAWL_TIMEOUT, FALLBACK_ENABLED)
4. Test with 10 URLs
5. Roll out to staging
6. Monitor performance metrics
7. Deploy to production


TIMELINE:
- Phase 1 (AsyncHTTP option): 1-2 days
- Phase 2 (Hybrid): 2-3 days
- Phase 3 (Parallel): 3-5 days
- Total: ~1 week to full 45x speedup
"""

# ============================================================================
# ğŸ”— TECHNICAL DETAILS
# ============================================================================

TECHNICAL = """
ASYNCHTTP IMPLEMENTATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Basic HTTP fetch (no Selenium):
   import aiohttp
   async with aiohttp.ClientSession() as session:
       async with session.get(url) as response:
           html = await response.text()
   
   â†’ Returns: HTML string (no JavaScript execution)
   â†’ Time: 2-5 seconds


2. Extract data from static HTML:
   data = extract_product_detail(html, url)
   
   â†’ Same extraction logic as Selenium
   â†’ Works on rendered HTML or static HTML


3. Missing dynamic content:
   - sales_count: On Tiki, embedded in __NEXT_DATA__ script âœ“ (can extract)
   - comments: AJAX loaded after page load âœ— (need Selenium)
   - real-time stock: AJAX loaded âœ— (need Selenium)


4. Performance optimization:
   - Connection pooling: limit=100, limit_per_host=10
   - Concurrent requests: asyncio.gather()
   - Timeout: 10-15 seconds (aggressive, fallback on error)
   - Rate limiting: Redis-based (avoid IP ban)


5. Fallback to Selenium:
   if asyncio.TimeoutError or not_enough_data:
       data = crawl_product_detail_with_selenium(url)
   
   â†’ Automatic recovery mechanism
   â†’ Transparent to caller


SELENIUM REUSE (OPTIMIZATION):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Instead of:
  for url in urls:
      driver = create_selenium_driver()
      crawl(url)
      driver.quit()
  â†’ Creates/destroys driver 1000 times = SLOW

Do:
  driver = create_selenium_driver()
  for url in urls:
      data = crawl_with_driver(driver, url)
  driver.quit()
  â†’ Reuse driver = 2-3x faster

But still much slower than AsyncHTTP.


BEST PRACTICE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Try AsyncHTTP first (3-5s, 90% success)
2. If timeout/error â†’ Selenium fallback (50s, 99% success)
3. Result: 95% speed, 99% success rate
"""

# ============================================================================
# âš ï¸ CAVEATS & PITFALLS
# âš ï¸ ============================================================================

PITFALLS = """
PITFALL 1: Rate limiting from Tiki
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Crawl too fast â†’ IP banned for 1 hour
Solution: 
  - Add delay between requests (1-2 seconds)
  - Use proxy rotation (if available)
  - Redis-based rate limiter (already implemented)
  - Check X-RateLimit headers

Prevention: AsyncHTTP allows controlled rate limiting


PITFALL 2: Missing sales_count (sá»‘ lÆ°á»£ng Ä‘Ã£ bÃ¡n)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: AsyncHTTP can't load "Sá»‘ sáº£n pháº©m Ä‘Ã£ bÃ¡n" if it's JavaScript
Solution:
  - Check if sales_count in __NEXT_DATA__ (it usually is!)
  - If missing â†’ fallback Selenium OR
  - Accept missing field for speed benefit

Tiki structure: sales_count usually in JSON payload âœ“


PITFALL 3: Proxy/VPN issues
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Tiki detects and blocks automated requests
Solution:
  - Add User-Agent headers (already done)
  - Add referer headers
  - Randomize request timing
  - Use proxy service (if available)

Prevention: aiohttp easier to manage than Selenium


PITFALL 4: Async concurrency limits
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Too many concurrent connections â†’ 429 Too Many Requests
Solution:
  - Limit concurrent connections: limit_per_host=10
  - Queue-based approach: process URLs in batches
  - Add backoff retry logic

Prevention: Configure TCPConnector properly


PITFALL 5: Database connection pool
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
If crawling 1000 products in parallel:
- Each needs DB connection
- Default pool size: 5-10
- Need to increase pool size

Solution: Configure in Airflow/app:
  sqlalchemy.pool_size = 50
  sqlalchemy.max_overflow = 100
"""

# ============================================================================
# ğŸ“š RESOURCES & REFERENCES
# ============================================================================

RESOURCES = """
Demo Scripts:
  - demos/demo_crawl_detail_async.py
  - demos/demo_crawl_detail_comparison.py

Source Code:
  - src/pipelines/crawl/crawl_products_detail.py
  - src/pipelines/crawl/utils.py

Documentation:
  - README.md (quick start)
  - This file (detailed guide)

External Resources:
  - aiohttp docs: https://docs.aiohttp.org/
  - asyncio docs: https://docs.python.org/3/library/asyncio.html
  - BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/
  - Selenium: https://www.selenium.dev/documentation/
"""

print(__doc__)
print(COMPARISON)
print(USE_CASES)
print(IMPLEMENTATION)
print(PROJECTIONS)
print(ACTION_PLAN)
print(TECHNICAL)
print(PITFALLS)
print(RESOURCES)
