#!/usr/bin/env python3
"""
Script ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ n√™n x√≥a DB ƒë·ªÉ crawl l·∫°i t·ª´ ƒë·∫ßu kh√¥ng
Ph√¢n t√≠ch t√¨nh h√¨nh hi·ªán t·∫°i v√† recommend actions
"""

import json
import os
import sys
from pathlib import Path

# Try to import psycopg2
try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
    HAS_PSYCOPG2 = True
except ImportError:
    HAS_PSYCOPG2 = False

# Import config
try:
    sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
    from pipelines.crawl.config import (
        POSTGRES_DB,
        POSTGRES_HOST,
        POSTGRES_PASSWORD,
        POSTGRES_PORT,
        POSTGRES_USER,
    )
except ImportError:
    POSTGRES_HOST = os.getenv("POSTGRES_HOST", "localhost")
    POSTGRES_PORT = int(os.getenv("POSTGRES_PORT", 5432))
    POSTGRES_USER = os.getenv("POSTGRES_USER", "postgres")
    POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "postgres")
    POSTGRES_DB = os.getenv("POSTGRES_DB", "crawl_data")

# Color codes
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
BLUE = "\033[94m"
CYAN = "\033[96m"
END = "\033[0m"


def print_section(title: str):
    """Print section header"""
    print(f"\n{BLUE}{'=' * 80}{END}")
    print(f"{BLUE}{title:^80}{END}")
    print(f"{BLUE}{'=' * 80}{END}\n")


def analyze_current_state():
    """Analyze current state of data"""
    print_section("üìä PH√ÇN T√çCH T√åNH H√åNH HI·ªÜN T·∫†I")
    
    # Check file data
    print("üìÇ D·ªÆ LI·ªÜU FILE:")
    files_to_check = [
        ("Categories", Path("data/raw/categories_recursive_optimized.json")),
        ("Products", Path("data/processed/products_final.json")),
    ]
    
    file_stats = {}
    for file_name, file_path in files_to_check:
        if file_path.exists():
            try:
                with open(file_path, encoding="utf-8") as f:
                    data = json.load(f)
                
                count = 0
                if isinstance(data, dict):
                    if "products" in data:
                        count = len(data["products"])
                    elif "categories" in data:
                        count = len(data["categories"])
                elif isinstance(data, list):
                    count = len(data)
                
                print(f"   ‚úÖ {file_name}: {GREEN}{count}{END} items")
                file_stats[file_name] = count
            except Exception as e:
                print(f"   ‚ö†Ô∏è {file_name}: Error - {e}")
        else:
            print(f"   ‚ùå {file_name}: File kh√¥ng t·ªìn t·∫°i")
            file_stats[file_name] = 0
    
    # Check database
    print("\nüóÑÔ∏è D·ªÆ LI·ªÜU DATABASE:")
    if HAS_PSYCOPG2:
        try:
            conn = psycopg2.connect(
                host=POSTGRES_HOST,
                port=POSTGRES_PORT,
                user=POSTGRES_USER,
                password=POSTGRES_PASSWORD,
                database=POSTGRES_DB,
            )
            cur = conn.cursor(cursor_factory=RealDictCursor)
            
            # Check products
            cur.execute("SELECT COUNT(*) as cnt FROM products;")
            products_count = cur.fetchone()["cnt"]
            print(f"   ‚úÖ Products table: {GREEN}{products_count}{END} rows")
            
            # Check products with category_path
            cur.execute("""
                SELECT 
                    COUNT(*) as total,
                    SUM(CASE WHEN category_path IS NOT NULL THEN 1 ELSE 0 END) as with_path
                FROM products;
            """)
            stats = cur.fetchone()
            with_path = stats["with_path"] or 0
            print(f"      - V·ªõi category_path: {GREEN}{with_path}{END}/{products_count}")
            
            # Check categories
            cur.execute("SELECT COUNT(*) as cnt FROM categories;")
            categories_count = cur.fetchone()["cnt"]
            print(f"   ‚úÖ Categories table: {GREEN}{categories_count}{END} rows")
            
            cur.close()
            conn.close()
            
            db_stats = {
                "products": products_count,
                "products_with_path": with_path,
                "categories": categories_count,
            }
        except Exception as e:
            print(f"   ‚ùå Database error: {e}")
            db_stats = {}
    else:
        print(f"   ‚ö†Ô∏è psycopg2 not installed - cannot check database")
        db_stats = {}
    
    return file_stats, db_stats


def show_analysis(**kwargs):
    """Show analysis and recommendation"""
    print_section("üìã PH√ÇN T√çCH V√Ä KHUY·∫æN C√ÅO")
    
    file_stats = kwargs.get("file_stats", {})
    db_stats = kwargs.get("db_stats", {})
    
    categories = file_stats.get("Categories", 0)
    products = file_stats.get("Products", 0)
    db_products = db_stats.get("products", 0)
    db_products_with_path = db_stats.get("products_with_path", 0)
    
    print("üîç T√åNH H√åNH HI·ªÜN T·∫†I:\n")
    
    # Analyze issues
    issues = []
    
    # Issue 1: Products without category_path
    if db_products > 0 and db_products_with_path < db_products:
        missing_path = db_products - db_products_with_path
        pct = missing_path * 100 / db_products
        issues.append({
            "severity": "HIGH",
            "issue": f"‚ùå {missing_path}/{db_products} products ({pct:.1f}%) KH√îNG c√≥ category_path",
            "impact": "Breadcrumb navigation s·∫Ω kh√¥ng ho·∫°t ƒë·ªông cho nh·ªØng products n√†y",
        })
    
    # Issue 2: File data inconsistency
    if products > 0 and db_products > 0 and abs(products - db_products) > 100:
        issues.append({
            "severity": "MEDIUM",
            "issue": f"‚ö†Ô∏è File c√≥ {products} products nh∆∞ng DB c√≥ {db_products} (kh√°c nhau {abs(products - db_products)})",
            "impact": "D·ªØ li·ªáu trong file v√† database kh√¥ng ƒë·ªìng b·ªô",
        })
    
    # Issue 3: Missing categories
    if categories > 0 and db_stats.get("categories", 0) == 0:
        issues.append({
            "severity": "MEDIUM",
            "issue": f"‚ö†Ô∏è Categories file c√≥ {categories} categories nh∆∞ng DB kh√¥ng c√≥",
            "impact": "Category_path lookup s·∫Ω kh√¥ng ho·∫°t ƒë·ªông",
        })
    
    if issues:
        print("üö® V·∫§N ƒê·ªÄ PH√ÅT HI·ªÜN:\n")
        for i, issue in enumerate(issues, 1):
            severity = issue["severity"]
            if severity == "HIGH":
                color = RED
            elif severity == "MEDIUM":
                color = YELLOW
            else:
                color = BLUE
            
            print(f"{color}{i}. [{severity}]{END}")
            print(f"   {issue['issue']}")
            print(f"   Impact: {issue['impact']}\n")
    else:
        print(f"{GREEN}‚úÖ Kh√¥ng ph√°t hi·ªán v·∫•n ƒë·ªÅ l·ªõn{END}\n")
    
    # Recommendation
    print("\nüìù KHUY·∫æN C√ÅO:\n")
    
    if db_products_with_path < db_products:
        print(f"{YELLOW}1. TR∆Ø·ªúNG H·ª¢P: D·ªØ li·ªáu ƒë√£ t·ªìn t·∫°i nh∆∞ng category_path CH∆ØA HO√ÄN CH·ªàNH{END}")
        print(f"""
   {CYAN}‚úÖ KH√îNG C·∫¶N X√ìA DB{END}
   
   {GREEN}Thay v√†o ƒë√≥, l√†m theo c√°c b∆∞·ªõc:{END}
   
   a) Ch·∫°y enrich script ƒë·ªÉ b·ªï sung category_path:
      $ python scripts/enrich_categories_with_paths.py
      
   b) Restart DAG ƒë·ªÉ enrich products:
      $ docker-compose restart airflow-scheduler airflow-worker
      
   c) Run DAG 'tiki_crawl_products' tr√™n Airflow UI
      - Task 'enrich_products_category_path' s·∫Ω:
        ‚Ä¢ Load categories file (v·ªõi category_path)
        ‚Ä¢ X√¢y d·ª±ng lookup map: category_id -> category_path
        ‚Ä¢ Enrich products b·∫±ng category_path t·ª´ lookup
      
   d) Verify k·∫øt qu·∫£:
      SELECT COUNT(*) as cnt FROM products WHERE category_path IS NOT NULL;
      
   ‚ú® L·ª£i √≠ch:
      - Gi·ªØ l·∫°i d·ªØ li·ªáu crawled c≈© (kh√¥ng m·∫•t c√¥ng)
      - Ch·ªâ c·∫≠p nh·∫≠t category_path missing
      - Ti·∫øt ki·ªám th·ªùi gian crawl
        """)
    
    else:
        print(f"{GREEN}1. TR∆Ø·ªúNG H·ª¢P: D·ªØ li·ªáu ƒë√£ ho√†n ch·ªânh{END}")
        print(f"""
   {GREEN}‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!{END}
   
   {CYAN}B·∫°n c√≥ th·ªÉ:{END}
   - S·ª≠ d·ª•ng d·ªØ li·ªáu hi·ªán t·∫°i cho analysis
   - Ch·∫°y l·∫°i DAG ƒë·ªÉ update t·∫•t c·∫£ d·ªØ li·ªáu
   - X√ìA DB CH·ªà N·∫æU mu·ªën reset to√†n b·ªô
        """)
    
    print(f"\n{BLUE}{'=' * 80}{END}")
    print(f"{BLUE}2. N·∫æUV√å C√ì L√ç DO X√ìA DB (v√≠ d·ª•: test crawl, reset data){END}")
    print(f"""
   {CYAN}C√°c b∆∞·ªõc x√≥a v√† crawl l·∫°i:{END}
   
   a) Backup d·ªØ li·ªáu (optional):
      $ docker-compose exec postgres pg_dump -U postgres crawl_data > backup.sql
      
   b) X√≥a d·ªØ li·ªáu trong tables:
      $ python scripts/reset_database.py
      
      ho·∫∑c x√≥a to√†n b·ªô database:
      $ docker-compose exec postgres dropdb -U postgres crawl_data
      
   c) Restart PostgreSQL ƒë·ªÉ reinitialize database:
      $ docker-compose restart postgres
      
   d) Restart Airflow:
      $ docker-compose restart airflow-scheduler airflow-worker
      
   e) Run DAG 'tiki_crawl_products' t·ª´ ƒë·∫ßu:
      - S·∫Ω crawl l·∫°i t·∫•t c·∫£ categories
      - Crawl products t·ª´ t·ª´ng category
      - Transform v√† load v√†o DB (s·∫°ch v√† ƒë·∫ßy ƒë·ªß)
      
   ‚è±Ô∏è Th·ªùi gian d·ª± ki·∫øn: 1-3 gi·ªù (t√πy thu·ªôc s·ªë categories/products)
        """)
    
    print(f"{BLUE}{'=' * 80}{END}")


def show_menu():
    """Show menu for user to choose action"""
    print_section("üéØ CH·ªåN H√ÄNH ƒê·ªòNG")
    
    print("""
1. ‚úÖ Gi·ªØ DB, ch·ªâ enrich category_path (RECOMMENDED)
   - Nhanh, kh√¥ng m·∫•t d·ªØ li·ªáu
   - B·ªï sung category_path cho products thi·∫øu
   
2. üîÑ Reset to√†n b·ªô DB v√† crawl l·∫°i
   - X√≥a t·∫•t c·∫£ d·ªØ li·ªáu
   - Crawl products t·ª´ ƒë·∫ßu
   - M·∫•t c√¥ng n√™n ch·ªâ d√πng khi th·ª±c s·ª± c·∫ßn
   
3. üíæ Xem th√™m th√¥ng tin v·ªÅ backup/restore
   
4. ‚ùå Tho√°t
    """)
    
    choice = input(f"\n{CYAN}Ch·ªçn (1-4): {END}").strip()
    return choice


def show_reset_warning():
    """Show warning before reset"""
    print_section("‚ö†Ô∏è C·∫¢NH B√ÅO: RESET DATABASE")
    
    print(f"""
{RED}B·∫°n chu·∫©n b·ªã X√ìA T·∫§T C·∫¢ D·ªÆ LI·ªÜU trong database!{END}

{YELLOW}ƒêi·ªÅu n√†y s·∫Ω:{END}
  ‚ùå X√ìA t·∫•t c·∫£ products
  ‚ùå X√ìA t·∫•t c·∫£ categories
  ‚ùå X√ìA crawl history
  ‚úÖ Gi·ªØ l·∫°i database structure (tables, indexes)

{CYAN}B·∫°n c√≥ th·ªÉ:{END}
  1. Backup d·ªØ li·ªáu tr∆∞·ªõc khi x√≥a
  2. Kh√¥i ph·ª•c sau b·∫±ng restore script

{YELLOW}L∆∞u √Ω: H√†nh ƒë·ªông n√†y KH√îNG TH·ªÇ ƒê·∫¢O NG∆Ø·ª¢C!{END}
    """)
    
    confirm = input(f"\n{RED}B·∫°n ch·∫Øc ch·∫Øn mu·ªën ti·∫øp t·ª•c? (yes/NO): {END}").strip().lower()
    return confirm == "yes"


def main():
    """Main function"""
    print(f"\n{YELLOW}{'=' * 80}{END}")
    print(f"{YELLOW}{'üóÑÔ∏è DATABASE RESET ADVISOR':^80}{END}")
    print(f"{YELLOW}{'=' * 80}{END}")
    
    # Analyze current state
    file_stats, db_stats = analyze_current_state()
    
    # Show analysis
    show_analysis(file_stats=file_stats, db_stats=db_stats)
    
    # Show menu
    while True:
        choice = show_menu()
        
        if choice == "1":
            print(f"\n{GREEN}‚úÖ B·∫°n ƒë√£ ch·ªçn: Gi·ªØ DB, enrich category_path{END}")
            print(f"""
{CYAN}C√°c b∆∞·ªõc ti·∫øp theo:{END}

1. Ch·∫°y enrich script:
   $ cd e:\\Project\\tiki-data-pipeline
   $ python scripts/enrich_categories_with_paths.py
   
2. Restart Airflow (n·∫øu ch·∫°y v·ªõi Docker):
   $ docker-compose restart airflow-scheduler airflow-worker
   
3. Truy c·∫≠p Airflow UI: http://localhost:8080
   - T√¨m DAG 'tiki_crawl_products'
   - Click n√∫t Play (‚ñ∂Ô∏è) ƒë·ªÉ trigger DAG
   - Gi√°m s√°t logs
   
4. Verify k·∫øt qu·∫£ sau khi DAG ch·∫°y xong:
   $ python scripts/visualize_final_data.py
            """)
            break
        
        elif choice == "2":
            if show_reset_warning():
                print(f"\n{RED}B·∫Øt ƒë·∫ßu reset...{END}")
                print(f"""
{CYAN}C√°c b∆∞·ªõc:{END}

1. Stop containers (n·∫øu ch·∫°y):
   $ docker-compose stop
   
2. Reset PostgreSQL (x√≥a database):
   $ docker-compose exec postgres dropdb -U postgres crawl_data
   
   ho·∫∑c gi·ªØ database structure:
   $ docker-compose exec postgres psql -U postgres -d crawl_data \\
     -c "TRUNCATE TABLE products CASCADE; TRUNCATE TABLE categories CASCADE;"
   
3. Start containers l·∫°i:
   $ docker-compose up -d
   
4. Verify database ƒë√£ reset:
   $ python scripts/visualize_final_data.py
   
5. Run DAG ƒë·ªÉ crawl l·∫°i t·ª´ ƒë·∫ßu:
   - Truy c·∫≠p http://localhost:8080
   - Trigger 'tiki_crawl_products' DAG
                """)
            break
        
        elif choice == "3":
            print(f"""
{CYAN}üìö TH√îNG TIN BACKUP/RESTORE:{END}

{GREEN}BACKUP:{END}
  # Backup to√†n b·ªô database
  $ docker-compose exec postgres pg_dump -U postgres crawl_data > backup.sql
  
  # Backup ch·ªâ products table
  $ docker-compose exec postgres pg_dump -U postgres -t products crawl_data > products_backup.sql

{GREEN}RESTORE:{END}
  # Restore to√†n b·ªô database
  $ docker-compose exec postgres psql -U postgres crawl_data < backup.sql
  
  # Restore ch·ªâ products table
  $ docker-compose exec postgres psql -U postgres crawl_data < products_backup.sql

{GREEN}BACKUP SCRIPTS:{END}
  $ python scripts/backup-postgres.ps1      # Windows PowerShell
  $ bash scripts/backup-postgres.sh         # Linux/Mac
            """)
        
        elif choice == "4":
            print(f"\n{GREEN}Tho√°t{END}")
            break
        
        else:
            print(f"{RED}L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá{END}")
    
    print(f"\n{BLUE}{'=' * 80}{END}\n")


if __name__ == "__main__":
    main()
