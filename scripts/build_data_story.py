"""
Script ƒë·ªÉ ph√¢n t√≠ch database v√† x√¢y d·ª±ng c√¢u chuy·ªán d·ªØ li·ªáu (Data Story)
T·∫°o file docx ch·ª©a c√¢u chuy·ªán d·ªØ li·ªáu c·ªßa d·ª± √°n Tiki Data Pipeline
"""

import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
except ImportError:
    print("‚ùå C·∫ßn c√†i ƒë·∫∑t psycopg2-binary: pip install psycopg2-binary")
    sys.exit(1)

try:
    from docx import Document
    from docx.shared import Inches, Pt, RGBColor
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.oxml.ns import qn
except ImportError:
    print("‚ùå C·∫ßn c√†i ƒë·∫∑t python-docx: pip install python-docx")
    sys.exit(1)

# Th√™m src v√†o path ƒë·ªÉ import modules
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# ƒê·ªçc th√¥ng tin t·ª´ .env
def load_env_config():
    """ƒê·ªçc c·∫•u h√¨nh t·ª´ file .env"""
    env_file = PROJECT_ROOT / ".env"
    config = {
        "host": "localhost",
        "port": 5432,
        "database": "crawl_data",
        "user": "postgres",
        "password": "postgres",
    }
    
    if env_file.exists():
        with open(env_file, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, value = line.split("=", 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    
                    if key == "POSTGRES_HOST":
                        config["host"] = value
                    elif key == "POSTGRES_PORT":
                        config["port"] = int(value)
                    elif key == "POSTGRES_USER":
                        config["user"] = value
                    elif key == "POSTGRES_PASSWORD":
                        config["password"] = value
                    elif key == "POSTGRES_DB" and value == "crawl_data":
                        config["database"] = value
    
    # Override v·ªõi environment variables n·∫øu c√≥
    config["host"] = os.getenv("POSTGRES_HOST", config["host"])
    config["port"] = int(os.getenv("POSTGRES_PORT", config["port"]))
    config["user"] = os.getenv("POSTGRES_USER", config["user"])
    config["password"] = os.getenv("POSTGRES_PASSWORD", config["password"])
    config["database"] = os.getenv("POSTGRES_DB", config["database"])
    
    return config


def connect_database(config: dict[str, Any]):
    """K·∫øt n·ªëi ƒë·∫øn PostgreSQL database"""
    try:
        conn = psycopg2.connect(
            host=config["host"],
            port=config["port"],
            database=config["database"],
            user=config["user"],
            password=config["password"],
            connect_timeout=10,
        )
        print(f"‚úÖ ƒê√£ k·∫øt n·ªëi ƒë·∫øn database: {config['database']}")
        return conn
    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi database: {e}")
        sys.exit(1)


def analyze_database(conn) -> dict[str, Any]:
    """Ph√¢n t√≠ch d·ªØ li·ªáu trong database"""
    stats = {}
    
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        # 1. T·ªïng quan
        print("üìä ƒêang ph√¢n t√≠ch t·ªïng quan...")
        cur.execute("""
            SELECT 
                (SELECT COUNT(*) FROM categories) as total_categories,
                (SELECT COUNT(*) FROM products) as total_products,
                (SELECT COUNT(DISTINCT category_url) FROM products WHERE category_url IS NOT NULL) as categories_with_products
        """)
        stats["overview"] = dict(cur.fetchone())
        
        # 2. Th·ªëng k√™ categories
        print("üìÅ ƒêang ph√¢n t√≠ch categories...")
        cur.execute("""
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT level) as distinct_levels,
                MIN(level) as min_level,
                MAX(level) as max_level,
                AVG(product_count) as avg_products_per_category,
                SUM(product_count) as total_product_count_in_categories
            FROM categories
        """)
        stats["categories"] = dict(cur.fetchone())
        
        # 3. Th·ªëng k√™ products
        print("üõçÔ∏è ƒêang ph√¢n t√≠ch products...")
        cur.execute("""
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT category_url) as categories_covered,
                COUNT(DISTINCT brand) as distinct_brands,
                COUNT(DISTINCT seller_id) as distinct_sellers,
                COUNT(CASE WHEN seller_is_official = TRUE THEN 1 END) as official_seller_products,
                AVG(sales_count) as avg_sales_count,
                MAX(sales_count) as max_sales_count,
                MIN(sales_count) as min_sales_count,
                AVG(price) as avg_price,
                MAX(price) as max_price,
                MIN(price) as min_price,
                AVG(rating_average) as avg_rating,
                AVG(review_count) as avg_reviews,
                COUNT(CASE WHEN stock_available = TRUE THEN 1 END) as in_stock_count,
                COUNT(CASE WHEN discount_percent > 0 THEN 1 END) as discounted_products,
                AVG(discount_percent) as avg_discount_percent
            FROM products
        """)
        stats["products"] = dict(cur.fetchone())
        
        # 4. Top categories theo s·ªë l∆∞·ª£ng s·∫£n ph·∫©m
        print("üèÜ ƒêang l·∫•y top categories...")
        cur.execute("""
            SELECT 
                c.name,
                c.level,
                COUNT(p.id) as product_count,
                AVG(p.price) as avg_price,
                AVG(p.sales_count) as avg_sales
            FROM categories c
            LEFT JOIN products p ON c.url = p.category_url
            GROUP BY c.id, c.name, c.level
            HAVING COUNT(p.id) > 0
            ORDER BY product_count DESC
            LIMIT 10
        """)
        stats["top_categories"] = [dict(row) for row in cur.fetchall()]
        
        # 5. Top products theo sales_count
        print("‚≠ê ƒêang l·∫•y top products...")
        cur.execute("""
            SELECT 
                product_id,
                name,
                price,
                sales_count,
                rating_average,
                review_count,
                brand,
                seller_name
            FROM products
            WHERE sales_count IS NOT NULL
            ORDER BY sales_count DESC
            LIMIT 10
        """)
        stats["top_products"] = [dict(row) for row in cur.fetchall()]
        
        # 6. Ph√¢n b·ªë gi√°
        print("üí∞ ƒêang ph√¢n t√≠ch ph√¢n b·ªë gi√°...")
        cur.execute("""
            SELECT 
                CASE 
                    WHEN price < 100000 THEN 'D∆∞·ªõi 100k'
                    WHEN price < 500000 THEN '100k - 500k'
                    WHEN price < 1000000 THEN '500k - 1M'
                    WHEN price < 5000000 THEN '1M - 5M'
                    ELSE 'Tr√™n 5M'
                END as price_range,
                COUNT(*) as count,
                AVG(price) as avg_price
            FROM products
            WHERE price IS NOT NULL
            GROUP BY price_range
            ORDER BY MIN(price)
        """)
        stats["price_distribution"] = [dict(row) for row in cur.fetchall()]
        
        # 7. Ph√¢n b·ªë rating
        print("‚≠ê ƒêang ph√¢n t√≠ch rating...")
        cur.execute("""
            SELECT 
                CASE 
                    WHEN rating_average IS NULL THEN 'Ch∆∞a c√≥ rating'
                    WHEN rating_average < 3.0 THEN 'D∆∞·ªõi 3.0'
                    WHEN rating_average < 4.0 THEN '3.0 - 4.0'
                    WHEN rating_average < 4.5 THEN '4.0 - 4.5'
                    ELSE 'Tr√™n 4.5'
                END as rating_range,
                COUNT(*) as count
            FROM products
            GROUP BY rating_range
            ORDER BY MIN(COALESCE(rating_average, 0))
        """)
        stats["rating_distribution"] = [dict(row) for row in cur.fetchall()]
        
        # 8. Th·ªëng k√™ theo brand
        print("üè∑Ô∏è ƒêang ph√¢n t√≠ch brands...")
        cur.execute("""
            SELECT 
                brand,
                COUNT(*) as product_count,
                AVG(price) as avg_price,
                AVG(sales_count) as avg_sales,
                AVG(rating_average) as avg_rating
            FROM products
            WHERE brand IS NOT NULL
            GROUP BY brand
            ORDER BY product_count DESC
            LIMIT 10
        """)
        stats["top_brands"] = [dict(row) for row in cur.fetchall()]
        
        # 9. Ph√¢n t√≠ch computed fields
        print("üìà ƒêang ph√¢n t√≠ch computed fields...")
        cur.execute("""
            SELECT 
                AVG(estimated_revenue) as avg_revenue,
                SUM(estimated_revenue) as total_revenue,
                AVG(popularity_score) as avg_popularity,
                MAX(popularity_score) as max_popularity,
                AVG(value_score) as avg_value_score,
                MAX(value_score) as max_value_score,
                COUNT(CASE WHEN price_category = 'budget' THEN 1 END) as budget_count,
                COUNT(CASE WHEN price_category = 'mid-range' THEN 1 END) as midrange_count,
                COUNT(CASE WHEN price_category = 'premium' THEN 1 END) as premium_count,
                COUNT(CASE WHEN price_category = 'luxury' THEN 1 END) as luxury_count
            FROM products
            WHERE estimated_revenue IS NOT NULL
        """)
        stats["computed_fields"] = dict(cur.fetchone())
        
        # 10. M·ªëi quan h·ªá gi·ªØa gi√° v√† doanh s·ªë
        print("üîó ƒêang ph√¢n t√≠ch m·ªëi quan h·ªá gi√°-doanh s·ªë...")
        cur.execute("""
            SELECT 
                CASE 
                    WHEN price < 100000 THEN 'D∆∞·ªõi 100k'
                    WHEN price < 500000 THEN '100k - 500k'
                    WHEN price < 1000000 THEN '500k - 1M'
                    WHEN price < 5000000 THEN '1M - 5M'
                    ELSE 'Tr√™n 5M'
                END as price_range,
                AVG(sales_count) as avg_sales,
                AVG(rating_average) as avg_rating,
                COUNT(*) as product_count
            FROM products
            WHERE price IS NOT NULL AND sales_count IS NOT NULL
            GROUP BY price_range
            ORDER BY MIN(price)
        """)
        stats["price_sales_relationship"] = [dict(row) for row in cur.fetchall()]
        
        # 11. M·ªëi quan h·ªá gi·ªØa discount v√† sales
        print("üí∞ ƒêang ph√¢n t√≠ch t√°c ƒë·ªông c·ªßa discount...")
        cur.execute("""
            SELECT 
                CASE 
                    WHEN discount_percent = 0 OR discount_percent IS NULL THEN 'Kh√¥ng gi·∫£m gi√°'
                    WHEN discount_percent < 10 THEN 'Gi·∫£m d∆∞·ªõi 10%'
                    WHEN discount_percent < 20 THEN 'Gi·∫£m 10-20%'
                    WHEN discount_percent < 30 THEN 'Gi·∫£m 20-30%'
                    ELSE 'Gi·∫£m tr√™n 30%'
                END as discount_range,
                AVG(sales_count) as avg_sales,
                COUNT(*) as product_count,
                AVG(rating_average) as avg_rating
            FROM products
            WHERE sales_count IS NOT NULL
            GROUP BY discount_range
            ORDER BY MIN(COALESCE(discount_percent, 0))
        """)
        stats["discount_impact"] = [dict(row) for row in cur.fetchall()]
        
        # 12. Top products theo computed fields
        print("‚≠ê ƒêang l·∫•y top products theo computed fields...")
        cur.execute("""
            SELECT 
                product_id,
                name,
                price,
                sales_count,
                rating_average,
                popularity_score,
                value_score,
                estimated_revenue,
                discount_percent
            FROM products
            WHERE popularity_score IS NOT NULL
            ORDER BY popularity_score DESC
            LIMIT 5
        """)
        stats["top_by_popularity"] = [dict(row) for row in cur.fetchall()]
        
        cur.execute("""
            SELECT 
                product_id,
                name,
                price,
                sales_count,
                rating_average,
                popularity_score,
                value_score,
                estimated_revenue
            FROM products
            WHERE value_score IS NOT NULL
            ORDER BY value_score DESC
            LIMIT 5
        """)
        stats["top_by_value"] = [dict(row) for row in cur.fetchall()]
    
    return stats


def safe_format(value: Any, format_str: str = ",.0f") -> str:
    """Format s·ªë an to√†n, x·ª≠ l√Ω None"""
    if value is None:
        return "N/A"
    try:
        return f"{value:{format_str}}"
    except (ValueError, TypeError):
        return str(value) if value else "N/A"


def create_document(stats: dict[str, Any], output_path: Path):
    """T·∫°o file docx v·ªõi c√¢u chuy·ªán d·ªØ li·ªáu"""
    doc = Document()
    
    # C·∫•u h√¨nh font cho ti·∫øng Vi·ªát
    def set_vietnamese_font(run):
        run.font.name = "Times New Roman"
        run._element.rPr.rFonts.set(qn("w:eastAsia"), "Times New Roman")
    
    # Title
    title = doc.add_heading("C√¢u Chuy·ªán D·ªØ Li·ªáu - Tiki Data Pipeline", 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in title.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(20)
        run.font.color.rgb = RGBColor(0, 51, 102)
    
    # Subtitle
    subtitle = doc.add_paragraph(f"Ng√†y t·∫°o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in subtitle.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
        run.font.color.rgb = RGBColor(102, 102, 102)
    
    doc.add_paragraph()  # Spacing
    
    # ============================================
    # PH·∫¶N B·ªêI C·∫¢NH V√Ä GI·ªöI THI·ªÜU
    # ============================================
    
    doc.add_heading("B·ªëi C·∫£nh: Th·ªã Tr∆∞·ªùng Th∆∞∆°ng M·∫°i ƒêi·ªán T·ª≠ Vi·ªát Nam", 1)
    
    # B·ªëi c·∫£nh th·ªã tr∆∞·ªùng
    context_market = doc.add_paragraph()
    context_market.add_run("Th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Vi·ªát Nam ƒëang ph√°t tri·ªÉn m·∫°nh m·∫Ω, d·ª± ki·∫øn ƒë·∫°t 49 t·ª∑ USD v√†o nƒÉm 2025. ")
    context_market.add_run("Tiki.vn l√† m·ªôt trong nh·ªØng n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ h√†ng ƒë·∫ßu, ƒë∆∞·ª£c th√†nh l·∫≠p t·ª´ nƒÉm 2010 v·ªõi h√†ng tri·ªáu s·∫£n ph·∫©m ƒëa d·∫°ng. ")
    context_market.add_run("D·ªØ li·ªáu t·ª´ Tiki.vn ph·∫£n √°nh xu h∆∞·ªõng mua s·∫Øm, h√†nh vi ti√™u d√πng v√† c·∫•u tr√∫c th·ªã tr∆∞·ªùng, c√≥ gi√° tr·ªã nghi√™n c·ª©u cao.")
    
    for run in context_market.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # √ù nghƒ©a c·ªßa dataset
    context_meaning = doc.add_paragraph()
    context_meaning.add_run("Dataset n√†y kh√¥ng ch·ªâ l√† danh s√°ch s·∫£n ph·∫©m, m√† l√† c·ª≠a s·ªï ƒë·ªÉ hi·ªÉu v·ªÅ th·ªã tr∆∞·ªùng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Vi·ªát Nam. ")
    context_meaning.add_run("T·ª´ dataset c√≥ th·ªÉ kh√°m ph√°: xu h∆∞·ªõng ti√™u d√πng, c·∫•u tr√∫c th·ªã tr∆∞·ªùng, h√†nh vi mua s·∫Øm, s·ª± c·∫°nh tranh gi·ªØa c√°c th∆∞∆°ng hi·ªáu, v√† gi√° tr·ªã th·ªã tr∆∞·ªùng.")
    
    for run in context_meaning.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # L√Ω do ch·ªçn ƒë·ªÅ t√†i
    doc.add_heading("L√Ω Do Ch·ªçn ƒê·ªÅ T√†i", 1)
    
    reason_intro = doc.add_paragraph()
    reason_intro.add_run("Vi·ªác x√¢y d·ª±ng dataset v√† ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ Tiki.vn ƒë∆∞·ª£c l·ª±a ch·ªçn d·ª±a tr√™n nh·ªØng l√Ω do sau:")
    
    for run in reason_intro.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    reasons = [
        ("T·∫ßm quan tr·ªçng c·ªßa th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠", 
         "Th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ ƒëang l√† xu h∆∞·ªõng t·∫•t y·∫øu c·ªßa th·ªùi ƒë·∫°i s·ªë. Vi·ªác hi·ªÉu r√µ th·ªã tr∆∞·ªùng n√†y kh√¥ng ch·ªâ quan tr·ªçng ƒë·ªëi v·ªõi c√°c doanh nghi·ªáp, m√† c√≤n c√≥ gi√° tr·ªã nghi√™n c·ª©u v√† h·ªçc thu·∫≠t cao. D·ªØ li·ªáu t·ª´ Tiki.vn cung c·∫•p c√°i nh√¨n to√†n di·ªán v·ªÅ h√†nh vi ti√™u d√πng, xu h∆∞·ªõng th·ªã tr∆∞·ªùng v√† c·∫•u tr√∫c kinh doanh."),
        
        ("Gi√° tr·ªã th·ª±c ti·ªÖn c·ªßa d·ªØ li·ªáu", 
         "Kh√°c v·ªõi c√°c dataset m·∫´u trong s√°ch gi√°o khoa, d·ªØ li·ªáu t·ª´ Tiki.vn l√† d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ th·ªã tr∆∞·ªùng. Dataset n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ nghi√™n c·ª©u th·ªã tr∆∞·ªùng, ph√¢n t√≠ch c·∫°nh tranh, d·ª± ƒëo√°n xu h∆∞·ªõng. ƒê√¢y l√† c∆° h·ªôi ƒë·ªÉ l√†m vi·ªác v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø v√† √°p d·ª•ng ki·∫øn th·ª©c ƒë√£ h·ªçc."),
        
        ("Th√°ch th·ª©c k·ªπ thu·∫≠t v√† c∆° h·ªôi h·ªçc h·ªèi", 
         "X√¢y d·ª±ng h·ªá th·ªëng thu th·∫≠p d·ªØ li·ªáu t·ª´ website ƒë·ªông nh∆∞ Tiki.vn l√† m·ªôt th√°ch th·ª©c k·ªπ thu·∫≠t. D·ª± √°n n√†y ƒë√≤i h·ªèi ki·∫øn th·ª©c v·ªÅ web scraping, x·ª≠ l√Ω d·ªØ li·ªáu, thi·∫øt k·∫ø database, v√† ph√¢n t√≠ch d·ªØ li·ªáu. ƒê√¢y l√† c∆° h·ªôi ƒë·ªÉ √°p d·ª•ng v√† n√¢ng cao c√°c k·ªπ nƒÉng trong lƒ©nh v·ª±c Data Engineering v√† Data Analytics."),
        
        ("T√≠nh m·ªõi v√† ƒë√≥ng g√≥p", 
         "M·∫∑c d√π c√≥ nhi·ªÅu nghi√™n c·ª©u v·ªÅ th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠, nh∆∞ng vi·ªác x√¢y d·ª±ng m·ªôt dataset to√†n di·ªán v√† c√≥ h·ªá th·ªëng t·ª´ Tiki.vn v·∫´n c√≤n h·∫°n ch·∫ø. Dataset n√†y c√≥ th·ªÉ ƒë√≥ng g√≥p cho c·ªông ƒë·ªìng nghi√™n c·ª©u, c√°c nh√† ph√¢n t√≠ch d·ªØ li·ªáu, v√† nh·ªØng ng∆∞·ªùi quan t√¢m ƒë·∫øn th·ªã tr∆∞·ªùng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Vi·ªát Nam."),
        
        ("·ª®ng d·ª•ng trong gi√°o d·ª•c v√† nghi√™n c·ª©u", 
         "Dataset n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ m·ªôt case study trong gi√°o d·ª•c v·ªÅ Data Engineering, Data Analytics, v√† Business Intelligence. N√≥ cung c·∫•p m·ªôt v√≠ d·ª• th·ª±c t·∫ø v·ªÅ c√°ch thu th·∫≠p, x·ª≠ l√Ω, v√† ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ ngu·ªìn th·ª±c t·∫ø, gi√∫p sinh vi√™n v√† nh√† nghi√™n c·ª©u hi·ªÉu r√µ h∆°n v·ªÅ quy tr√¨nh l√†m vi·ªác v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø."),
        
        ("Ti·ªÅm nƒÉng m·ªü r·ªông", 
         "D·ª± √°n n√†y c√≥ ti·ªÅm nƒÉng m·ªü r·ªông l·ªõn. C√≥ th·ªÉ ph√°t tri·ªÉn th√†nh m·ªôt h·ªá th·ªëng monitoring th·ªã tr∆∞·ªùng, m·ªôt c√¥ng c·ª• ph√¢n t√≠ch c·∫°nh tranh, ho·∫∑c m·ªôt n·ªÅn t·∫£ng cung c·∫•p d·ªØ li·ªáu cho c√°c ·ª©ng d·ª•ng kh√°c. Dataset c√≥ th·ªÉ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªãnh k·ª≥ ƒë·ªÉ theo d√µi s·ª± thay ƒë·ªïi c·ªßa th·ªã tr∆∞·ªùng.")
    ]
    
    for idx, (title, content) in enumerate(reasons, 1):
        reason_heading = doc.add_heading(f"{idx}. {title}", 2)
        for run in reason_heading.runs:
            set_vietnamese_font(run)
        
        reason_para = doc.add_paragraph(content)
        for run in reason_para.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # L·ªùi m·ªü ƒë·∫ßu
    doc.add_heading("L·ªùi M·ªü ƒê·∫ßu: C√¢u Chuy·ªán T·ª´ D·ªØ Li·ªáu", 1)
    intro = doc.add_paragraph()
    intro.add_run("ƒê·∫±ng sau m·ªói con s·ªë l√† m·ªôt c√¢u chuy·ªán. ")
    intro.add_run("ƒê·∫±ng sau m·ªói s·∫£n ph·∫©m l√† m·ªôt l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi ti√™u d√πng. ")
    intro.add_run("ƒê·∫±ng sau m·ªói danh m·ª•c l√† m·ªôt xu h∆∞·ªõng th·ªã tr∆∞·ªùng. ")
    intro.add_run("T√†i li·ªáu n√†y tr√¨nh b√†y nh·ªØng c√¢u chuy·ªán ƒë∆∞·ª£c kh√°m ph√° t·ª´ d·ªØ li·ªáu thu th·∫≠p t·ª´ Tiki.vn, m·ªôt trong nh·ªØng n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ h√†ng ƒë·∫ßu Vi·ªát Nam.")
    
    for run in intro.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # Gi·ªõi thi·ªáu v·ªÅ dataset
    doc.add_heading("V·ªÅ Dataset", 2)
    dataset_intro = doc.add_paragraph()
    dataset_intro.add_run("Dataset n√†y ch·ª©a th√¥ng tin v·ªÅ h√†ng ngh√¨n s·∫£n ph·∫©m t·ª´ Tiki.vn, ƒë∆∞·ª£c thu th·∫≠p v√† x·ª≠ l√Ω m·ªôt c√°ch c√≥ h·ªá th·ªëng. ")
    dataset_intro.add_run("M·ªói s·∫£n ph·∫©m trong dataset bao g·ªìm th√¥ng tin chi ti·∫øt v·ªÅ: t√™n s·∫£n ph·∫©m, gi√° c·∫£, m√¥ t·∫£, ƒë√°nh gi√° c·ªßa ng∆∞·ªùi d√πng, th√¥ng tin ng∆∞·ªùi b√°n, th∆∞∆°ng hi·ªáu, s·ªë l∆∞·ª£ng ƒë√£ b√°n, v√† nhi·ªÅu ch·ªâ s·ªë ph√¢n t√≠ch kh√°c. ")
    dataset_intro.add_run("M·ªói d√≤ng d·ªØ li·ªáu kh√¥ng ch·ªâ ph·∫£n √°nh th√¥ng tin v·ªÅ s·∫£n ph·∫©m, m√† c√≤n cho th·∫•y v·ªÅ th·ªã tr∆∞·ªùng, v·ªÅ h√†nh vi mua s·∫Øm c·ªßa ng∆∞·ªùi ti√™u d√πng, v√† v·ªÅ nh·ªØng xu h∆∞·ªõng ƒëang di·ªÖn ra.")
    
    for run in dataset_intro.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # C√¢u chuy·ªán t·ª´ d·ªØ li·ªáu
    doc.add_heading("Nh·ªØng C√¢u H·ªèi Nghi√™n C·ª©u", 2)
    story_intro = doc.add_paragraph()
    story_intro.add_run("Khi b·∫Øt ƒë·∫ßu v·ªõi dataset n√†y, c√≥ nhi·ªÅu c√¢u h·ªèi nghi√™n c·ª©u ƒë∆∞·ª£c ƒë·∫∑t ra. ")
    story_intro.add_run("D·ªØ li·ªáu s·∫Ω gi√∫p tr·∫£ l·ªùi nh·ªØng c√¢u h·ªèi ƒë√≥. ")
    story_intro.add_run("D∆∞·ªõi ƒë√¢y l√† nh·ªØng v·∫•n ƒë·ªÅ c√≥ th·ªÉ kh√°m ph√° t·ª´ dataset:")
    
    for run in story_intro.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    story_points = [
        "Th·ªã tr∆∞·ªùng Tiki c√≥ quy m√¥ nh∆∞ th·∫ø n√†o? C√≥ bao nhi√™u s·∫£n ph·∫©m v√† danh m·ª•c?",
        "Ng∆∞·ªùi ti√™u d√πng ƒëang mua g√¨? S·∫£n ph·∫©m n√†o ƒë∆∞·ª£c mua nhi·ªÅu nh·∫•t?",
        "Gi√° c·∫£ tr√™n th·ªã tr∆∞·ªùng ph√¢n b·ªë nh∆∞ th·∫ø n√†o? Ng∆∞·ªùi ti√™u d√πng th∆∞·ªùng mua ·ªü m·ª©c gi√° n√†o?",
        "Th∆∞∆°ng hi·ªáu n√†o ƒëang d·∫´n ƒë·∫ßu? Ai l√† ng∆∞·ªùi b√°n t·ªët nh·∫•t?",
        "Ng∆∞·ªùi ti√™u d√πng ƒë√°nh gi√° s·∫£n ph·∫©m nh∆∞ th·∫ø n√†o? ƒêi·ªÉm s·ªë v√† review ph·∫£n √°nh ƒëi·ªÅu g√¨?",
        "Gi·∫£m gi√° c√≥ th·ª±c s·ª± ·∫£nh h∆∞·ªüng ƒë·∫øn doanh s·ªë kh√¥ng?"
    ]
    
    for point in story_points:
        p = doc.add_paragraph(point, style="List Bullet")
        for run in p.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # 1. T·ªïng quan
    doc.add_heading("1. T·ªïng Quan D·ªØ Li·ªáu: M·∫´u Nghi√™n C·ª©u", 1)
    overview = stats["overview"]
    overview_text = doc.add_paragraph()
    overview_text.add_run("Sau qu√° tr√¨nh thu th·∫≠p v√† x·ª≠ l√Ω, dataset ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi quy m√¥ ƒë√°ng k·ªÉ. ")
    overview_text.add_run(f"Dataset hi·ªán t·∫°i bao g·ªìm ")
    overview_text.add_run(f"{overview['total_products']:,}").bold = True
    overview_text.add_run(" s·∫£n ph·∫©m t·ª´ ")
    overview_text.add_run(f"{overview['total_categories']:,}").bold = True
    overview_text.add_run(" danh m·ª•c kh√°c nhau. ")
    overview_text.add_run(f"Trong ƒë√≥, c√≥ ")
    overview_text.add_run(f"{overview['categories_with_products']:,}").bold = True
    overview_text.add_run(" danh m·ª•c th·ª±c s·ª± c√≥ s·∫£n ph·∫©m. ")
    overview_text.add_run("C·∫ßn l∆∞u √Ω r·∫±ng ƒë√¢y l√† m·ªôt m·∫´u d·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p, kh√¥ng ph·∫£i to√†n b·ªô s·∫£n ph·∫©m tr√™n Tiki.vn. ")
    overview_text.add_run("Tuy nhi√™n, v·ªõi quy m√¥ n√†y, dataset v·∫´n ƒë·ªß l·ªõn v√† ƒë·∫°i di·ªán ƒë·ªÉ c√≥ th·ªÉ nghi√™n c·ª©u v·ªÅ c√°c xu h∆∞·ªõng v√† ƒë·∫∑c ƒëi·ªÉm c·ªßa th·ªã tr∆∞·ªùng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Vi·ªát Nam.")
    
    for run in overview_text.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    # Insights t·ª´ t·ªïng quan
    insight_para = doc.add_paragraph()
    if overview["categories_with_products"] and overview["total_categories"]:
        coverage_ratio = (overview["categories_with_products"] / overview["total_categories"]) * 100
        insight_para.add_run(f"M·ªôt ph√°t hi·ªán th√∫ v·ªã: trong s·ªë ")
        insight_para.add_run(f"{overview['total_categories']:,}").bold = True
        insight_para.add_run(" danh m·ª•c ƒë∆∞·ª£c thu th·∫≠p, c√≥ ")
        insight_para.add_run(f"{overview['categories_with_products']:,}").bold = True
        insight_para.add_run(f" danh m·ª•c ({coverage_ratio:.1f}%) th·ª±c s·ª± c√≥ s·∫£n ph·∫©m. ")
        insight_para.add_run("ƒêi·ªÅu n√†y cho th·∫•y m·ªôt s·ªë danh m·ª•c c√≥ th·ªÉ l√† danh m·ª•c cha (ch·ªâ ƒë·ªÉ ph√¢n lo·∫°i) ho·∫∑c danh m·ª•c tr·ªëng, ph·∫£n √°nh c√°ch Tiki t·ªï ch·ª©c c·∫•u tr√∫c s·∫£n ph·∫©m.")
    
    for run in insight_para.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # 2. Ph√¢n t√≠ch Categories
    doc.add_heading("2. C√¢u Chuy·ªán V·ªÅ Danh M·ª•c: C·∫•u Tr√∫c Th·ªã Tr∆∞·ªùng", 1)
    cat_stats = stats["categories"]
    cat_text = doc.add_paragraph()
    cat_text.add_run("Danh m·ª•c s·∫£n ph·∫©m ph·∫£n √°nh c√°ch t·ªï ch·ª©c v√† ph√¢n lo·∫°i th·ªã tr∆∞·ªùng. ")
    cat_text.add_run("Tiki.vn t·ªï ch·ª©c s·∫£n ph·∫©m theo c·∫•u tr√∫c ph√¢n c·∫•p ƒëa t·∫ßng v·ªõi ")
    cat_text.add_run(f"{cat_stats['distinct_levels']}").bold = True
    cat_text.add_run(" c·∫•p ƒë·ªô kh√°c nhau, t·ª´ c·∫•p ")
    cat_text.add_run(f"{cat_stats['min_level']}").bold = True
    cat_text.add_run(" ƒë·∫øn c·∫•p ")
    cat_text.add_run(f"{cat_stats['max_level']}").bold = True
    cat_text.add_run(". ")
    if cat_stats["avg_products_per_category"]:
        cat_text.add_run(f"Trung b√¨nh m·ªói danh m·ª•c c√≥ ")
        cat_text.add_run(f"{safe_format(cat_stats.get('avg_products_per_category'), '.0f')}").bold = True
        cat_text.add_run(" s·∫£n ph·∫©m.")
    
    for run in cat_text.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    # Insights v·ªÅ danh m·ª•c
    if stats["top_categories"]:
        top_cat_insight = doc.add_paragraph()
        top_cat = stats["top_categories"][0] if stats["top_categories"] else None
        if top_cat:
            top_cat_insight.add_run("Danh m·ª•c c√≥ nhi·ªÅu s·∫£n ph·∫©m nh·∫•t l√† ")
            top_cat_insight.add_run(f'"{top_cat["name"]}"').bold = True
            top_cat_insight.add_run(f" v·ªõi ")
            top_cat_insight.add_run(f"{top_cat['product_count']:,}").bold = True
            top_cat_insight.add_run(" s·∫£n ph·∫©m. ")
            if top_cat.get("avg_price"):
                top_cat_insight.add_run(f"Gi√° trung b√¨nh trong danh m·ª•c n√†y l√† ")
                top_cat_insight.add_run(f"{safe_format(top_cat.get('avg_price'), ',.0f')} VND").bold = True
                top_cat_insight.add_run(", cho th·∫•y ph√¢n kh√∫c gi√° c·ªßa danh m·ª•c n√†y.")
            
            for run in top_cat_insight.runs:
                set_vietnamese_font(run)
                run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # 3. Ph√¢n t√≠ch Products
    doc.add_heading("3. C√¢u Chuy·ªán V·ªÅ S·∫£n Ph·∫©m: Th·ªã Tr∆∞·ªùng Trong L√≤ng B√†n Tay", 1)
    prod_stats = stats["products"]
    prod_text = doc.add_paragraph()
    prod_text.add_run("M·ªói s·∫£n ph·∫©m trong dataset ph·∫£n √°nh m·ªôt l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi ti√™u d√πng d·ª±a tr√™n nhu c·∫ßu, gi√° c·∫£, v√† ƒë√°nh gi√°. ")
    prod_text.add_run(f"Dataset bao g·ªìm s·∫£n ph·∫©m t·ª´ ")
    prod_text.add_run(f"{prod_stats['distinct_brands']:,}").bold = True
    prod_text.add_run(" th∆∞∆°ng hi·ªáu kh√°c nhau v√† ")
    prod_text.add_run(f"{prod_stats['distinct_sellers']:,}").bold = True
    prod_text.add_run(" ng∆∞·ªùi b√°n. ")
    prod_text.add_run("ƒêi·ªÅu n√†y cho th·∫•y th·ªã tr∆∞·ªùng r·∫•t ƒëa d·∫°ng v√† c·∫°nh tranh, t·∫°o ra nhi·ªÅu l·ª±a ch·ªçn cho ng∆∞·ªùi ti√™u d√πng.")
    
    for run in prod_text.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    # C√¢u chuy·ªán v·ªÅ gi√° c·∫£
    if prod_stats.get("avg_price") is not None:
        price_story = doc.add_paragraph()
        price_story.add_run("M·ªôt c√¢u h·ªèi nghi√™n c·ª©u quan tr·ªçng: Ng∆∞·ªùi ti√™u d√πng th∆∞·ªùng mua ·ªü m·ª©c gi√° n√†o? ")
        if stats["price_distribution"]:
            max_count_range = max(stats["price_distribution"], key=lambda x: x["count"])
            total_products = sum(r["count"] for r in stats["price_distribution"])
            max_percentage = (max_count_range["count"] / total_products) * 100 if total_products > 0 else 0
            price_story.add_run(f"D·ªØ li·ªáu cho th·∫•y ")
            price_story.add_run(f"{max_percentage:.1f}%").bold = True
            price_story.add_run(f" s·∫£n ph·∫©m n·∫±m trong kho·∫£ng ")
            price_story.add_run(f'"{max_count_range["price_range"]}"').bold = True
            price_story.add_run(". ")
            price_story.add_run("ƒêi·ªÅu n√†y ph·∫£n √°nh ph√¢n kh√∫c gi√° m√† ng∆∞·ªùi ti√™u d√πng Vi·ªát Nam th∆∞·ªùng l·ª±a ch·ªçn khi mua s·∫Øm online.")
        else:
            price_story.add_run(f"Gi√° trung b√¨nh l√† ")
            price_story.add_run(f"{safe_format(prod_stats.get('avg_price'), ',.0f')} VND").bold = True
            price_story.add_run(", cho th·∫•y m·ª©c gi√° ph·ªï bi·∫øn tr√™n th·ªã tr∆∞·ªùng.")
        
        for run in price_story.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
    
    # C√¢u chuy·ªán v·ªÅ s·∫£n ph·∫©m b√°n ch·∫°y
    if stats["top_products"]:
        top_prod_story = doc.add_paragraph()
        top_prod = stats["top_products"][0] if stats["top_products"] else None
        if top_prod:
            top_prod_story.add_run("S·∫£n ph·∫©m n√†o ƒë∆∞·ª£c mua nhi·ªÅu nh·∫•t? ")
            top_prod_story.add_run(f'"{top_prod["name"][:60]}"').bold = True
            if top_prod.get("sales_count"):
                top_prod_story.add_run(f" ƒë√£ b√°n ƒë∆∞·ª£c ")
                top_prod_story.add_run(f"{safe_format(top_prod.get('sales_count'), ',')}").bold = True
                top_prod_story.add_run(" s·∫£n ph·∫©m. ")
            top_prod_story.add_run("ƒêi·ªÅu n√†y cho th·∫•y s·∫£n ph·∫©m n√†y ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu v√† s·ªü th√≠ch c·ªßa ƒë√¥ng ƒë·∫£o ng∆∞·ªùi ti√™u d√πng.")
            
            for run in top_prod_story.runs:
                set_vietnamese_font(run)
                run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # 4. Ph√¢n t√≠ch Brands
    if stats["top_brands"]:
        doc.add_heading("4. C√¢u Chuy·ªán V·ªÅ Th∆∞∆°ng Hi·ªáu: Ai ƒêang D·∫´n ƒê·∫ßu?", 1)
        brand_text = doc.add_paragraph()
        brand_text.add_run("Th∆∞∆°ng hi·ªáu ƒë√≥ng vai tr√≤ quan tr·ªçng trong quy·∫øt ƒë·ªãnh mua s·∫Øm c·ªßa ng∆∞·ªùi ti√™u d√πng. ")
        brand_text.add_run("Th∆∞∆°ng hi·ªáu kh√¥ng ch·ªâ l√† t√™n g·ªçi, m√† c√≤n l√† l·ªùi h·ª©a v·ªÅ ch·∫•t l∆∞·ª£ng v√† gi√° tr·ªã. ")
        brand_text.add_run("Tr√™n Tiki, c√≥ r·∫•t nhi·ªÅu th∆∞∆°ng hi·ªáu c·∫°nh tranh v·ªõi nhau ƒë·ªÉ thu h√∫t ng∆∞·ªùi mua, t·∫°o n√™n m·ªôt th·ªã tr∆∞·ªùng ƒëa d·∫°ng v√† s√¥i ƒë·ªông.")
        
        for run in brand_text.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
        
        # C√¢u chuy·ªán v·ªÅ th∆∞∆°ng hi·ªáu h√†ng ƒë·∫ßu
        top_brand = stats["top_brands"][0] if stats["top_brands"] else None
        if top_brand:
            brand_story = doc.add_paragraph()
            brand_story.add_run("Th∆∞∆°ng hi·ªáu c√≥ nhi·ªÅu s·∫£n ph·∫©m nh·∫•t l√† ")
            brand_story.add_run(f'"{top_brand["brand"]}"').bold = True
            brand_story.add_run(f" v·ªõi ")
            brand_story.add_run(f"{top_brand['product_count']:,}").bold = True
            brand_story.add_run(" s·∫£n ph·∫©m. ")
            brand_story.add_run("ƒêi·ªÅu n√†y cho th·∫•y th∆∞∆°ng hi·ªáu n√†y ƒë√£ x√¢y d·ª±ng ƒë∆∞·ª£c m·ªôt danh m·ª•c s·∫£n ph·∫©m ƒëa d·∫°ng v√† c√≥ v·ªã th·∫ø m·∫°nh tr√™n th·ªã tr∆∞·ªùng.")
            
            for run in brand_story.runs:
                set_vietnamese_font(run)
                run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # 5. C√¢u chuy·ªán v·ªÅ gi√° tr·ªã th·ªã tr∆∞·ªùng
    if stats.get("computed_fields"):
        doc.add_heading("5. C√¢u Chuy·ªán V·ªÅ Gi√° Tr·ªã Th·ªã Tr∆∞·ªùng", 1)
        computed = stats["computed_fields"]
        
        # Estimated Revenue - c√¢u chuy·ªán v·ªÅ quy m√¥
        if computed.get("total_revenue"):
            revenue_story = doc.add_paragraph()
            revenue_story.add_run("M·ªôt c√¢u h·ªèi nghi√™n c·ª©u quan tr·ªçng: Th·ªã tr∆∞·ªùng n√†y c√≥ gi√° tr·ªã bao nhi√™u? ")
            revenue_story.add_run("T·ª´ dataset, t·ªïng doanh thu ∆∞·ªõc t√≠nh l√† ")
            revenue_story.add_run(f"{safe_format(computed.get('total_revenue') / 1000000000, '.2f')} t·ª∑ VND").bold = True
            revenue_story.add_run(". ")
            revenue_story.add_run("Con s·ªë n√†y ph·∫£n √°nh quy m√¥ v√† ti·ªÅm nƒÉng c·ªßa th·ªã tr∆∞·ªùng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Vi·ªát Nam.")
            
            for run in revenue_story.runs:
                set_vietnamese_font(run)
                run.font.size = Pt(12)
        
        doc.add_paragraph()  # Spacing
    
    # 6. C√¢u chuy·ªán v·ªÅ m·ªëi quan h·ªá gi√° v√† doanh s·ªë
    if stats.get("price_sales_relationship"):
        doc.add_heading("6. C√¢u Chuy·ªán: Gi√° N√†o B√°n Ch·∫°y Nh·∫•t?", 1)
        relationship_story = doc.add_paragraph()
        relationship_story.add_run("M·ªôt c√¢u h·ªèi nghi√™n c·ª©u quan tr·ªçng: ·ªû m·ª©c gi√° n√†o th√¨ s·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t? ")
        relationship_story.add_run("ƒê√¢y l√† c√¢u h·ªèi m√† nhi·ªÅu ng∆∞·ªùi b√°n v√† doanh nghi·ªáp quan t√¢m. ")
        relationship_story.add_run("D·ªØ li·ªáu c√≥ th·ªÉ gi√∫p tr·∫£ l·ªùi c√¢u h·ªèi n√†y:")
        
        for run in relationship_story.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
        
        # T√¨m kho·∫£ng gi√° c√≥ doanh s·ªë cao nh·∫•t
        max_sales_range = max(stats["price_sales_relationship"], key=lambda x: x.get("avg_sales", 0) or 0)
        if max_sales_range.get("avg_sales"):
            insight_story = doc.add_paragraph()
            insight_story.add_run("Kho·∫£ng gi√° ")
            insight_story.add_run(f'"{max_sales_range["price_range"]}"').bold = True
            insight_story.add_run(" c√≥ doanh s·ªë trung b√¨nh cao nh·∫•t. ")
            insight_story.add_run("ƒêi·ªÅu n√†y cho th·∫•y ƒë√¢y l√† 'v√πng gi√° v√†ng' - m·ª©c gi√° m√† ng∆∞·ªùi ti√™u d√πng c·∫£m th·∫•y h·ª£p l√Ω v√† s·∫µn s√†ng mua nh·∫•t. ")
            insight_story.add_run("ƒê√¢y l√† insight qu√Ω gi√° cho c√°c doanh nghi·ªáp khi ƒë·ªãnh gi√° s·∫£n ph·∫©m.")
            
            for run in insight_story.runs:
                set_vietnamese_font(run)
                run.font.size = Pt(12)
        
        doc.add_paragraph()  # Spacing
    
    # 7. C√¢u chuy·ªán v·ªÅ khuy·∫øn m√£i
    if stats.get("discount_impact"):
        doc.add_heading("7. C√¢u Chuy·ªán: Gi·∫£m Gi√° C√≥ Th·ª±c S·ª± Gi√∫p B√°n ƒê∆∞·ª£c Nhi·ªÅu H∆°n?", 1)
        discount_story = doc.add_paragraph()
        discount_story.add_run("C√°c ch∆∞∆°ng tr√¨nh gi·∫£m gi√° v√† khuy·∫øn m√£i l√† c√¥ng c·ª• marketing ph·ªï bi·∫øn tr√™n Tiki. ")
        discount_story.add_run("M·ªôt c√¢u h·ªèi nghi√™n c·ª©u: Li·ªáu gi·∫£m gi√° c√≥ th·ª±c s·ª± ·∫£nh h∆∞·ªüng ƒë·∫øn doanh s·ªë kh√¥ng? ")
        discount_story.add_run("D·ªØ li·ªáu c√≥ th·ªÉ cung c·∫•p c√¢u tr·∫£ l·ªùi:")
        
        for run in discount_story.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
        
        # So s√°nh s·∫£n ph·∫©m c√≥ v√† kh√¥ng c√≥ discount
        no_discount = next((r for r in stats["discount_impact"] if "Kh√¥ng gi·∫£m gi√°" in r["discount_range"]), None)
        with_discount = next((r for r in stats["discount_impact"] if "Kh√¥ng gi·∫£m gi√°" not in r["discount_range"]), None)
        
        if no_discount and with_discount:
            comparison_story = doc.add_paragraph()
            no_discount_sales = no_discount.get("avg_sales") or 0
            with_discount_sales = with_discount.get("avg_sales") or 0
            
            if with_discount_sales > no_discount_sales:
                diff = ((with_discount_sales - no_discount_sales) / no_discount_sales) * 100 if no_discount_sales > 0 else 0
                comparison_story.add_run("D·ªØ li·ªáu cho th·∫•y s·∫£n ph·∫©m c√≥ gi·∫£m gi√° th∆∞·ªùng b√°n ƒë∆∞·ª£c nhi·ªÅu h∆°n. ")
                comparison_story.add_run("ƒêi·ªÅu n√†y ch·ª©ng minh r·∫±ng khuy·∫øn m√£i l√† m·ªôt c√¥ng c·ª• marketing hi·ªáu qu·∫£ ƒë·ªÉ thu h√∫t ng∆∞·ªùi mua v√† tƒÉng doanh s·ªë.")
            else:
                comparison_story.add_run("Th√∫ v·ªã l√†, m·ªôt s·ªë s·∫£n ph·∫©m kh√¥ng gi·∫£m gi√° v·∫´n b√°n r·∫•t ch·∫°y. ")
                comparison_story.add_run("ƒêi·ªÅu n√†y c√≥ th·ªÉ do ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m t·ªët, th∆∞∆°ng hi·ªáu m·∫°nh, ho·∫∑c ƒë√°p ·ª©ng ƒë√∫ng nhu c·∫ßu c·ªßa ng∆∞·ªùi mua.")
            
            for run in comparison_story.runs:
                set_vietnamese_font(run)
                run.font.size = Pt(12)
        
        doc.add_paragraph()  # Spacing
    
    # 8. K·∫øt lu·∫≠n
    doc.add_heading("8. K·∫øt Lu·∫≠n: Nh·ªØng C√¢u Chuy·ªán ƒê√£ K·ªÉ", 1)
    
    # T·ªïng h·ª£p c√¢u chuy·ªán
    conclusion = doc.add_paragraph()
    conclusion.add_run("Qua qu√° tr√¨nh ph√¢n t√≠ch d·ªØ li·ªáu, ƒë√£ kh√°m ph√° ƒë∆∞·ª£c nhi·ªÅu insights th√∫ v·ªã v·ªÅ th·ªã tr∆∞·ªùng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ Vi·ªát Nam. ")
    conclusion.add_run(f"V·ªõi ")
    conclusion.add_run(f"{overview['total_products']:,}").bold = True
    conclusion.add_run(" s·∫£n ph·∫©m t·ª´ ")
    conclusion.add_run(f"{overview['total_categories']:,}").bold = True
    conclusion.add_run(" danh m·ª•c, dataset n√†y ph·∫£n √°nh m·ªôt th·ªã tr∆∞·ªùng s√¥i ƒë·ªông, ƒëa d·∫°ng v√† ƒë·∫ßy ti·ªÅm nƒÉng.")
    
    for run in conclusion.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # Nh·ªØng ph√°t hi·ªán ch√≠nh
    doc.add_heading("Nh·ªØng Ph√°t Hi·ªán Ch√≠nh", 2)
    learnings_intro = doc.add_paragraph()
    learnings_intro.add_run("T·ª´ ph√¢n t√≠ch d·ªØ li·ªáu, c√≥ th·ªÉ r√∫t ra nh·ªØng ph√°t hi·ªán sau:")
    
    for run in learnings_intro.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    # T√≠nh to√°n learnings t·ª´ d·ªØ li·ªáu
    learnings = []
    
    if prod_stats.get("distinct_brands"):
        learnings.append(f"Th·ªã tr∆∞·ªùng c√≥ {prod_stats['distinct_brands']:,} th∆∞∆°ng hi·ªáu kh√°c nhau, cho th·∫•y s·ª± ƒëa d·∫°ng v√† c·∫°nh tranh tr√™n th·ªã tr∆∞·ªùng.")
    
    if prod_stats.get("discounted_products") and overview.get("total_products"):
        discount_ratio = (prod_stats["discounted_products"] / overview["total_products"]) * 100
        learnings.append(f"Khuy·∫øn m√£i l√† m·ªôt chi·∫øn l∆∞·ª£c ph·ªï bi·∫øn - c√≥ {discount_ratio:.1f}% s·∫£n ph·∫©m ƒëang gi·∫£m gi√°.")
    
    if prod_stats.get("avg_rating"):
        learnings.append(f"Ng∆∞·ªùi ti√™u d√πng kh√° h√†i l√≤ng v·ªõi s·∫£n ph·∫©m tr√™n th·ªã tr∆∞·ªùng, v·ªõi ƒëi·ªÉm ƒë√°nh gi√° trung b√¨nh {safe_format(prod_stats.get('avg_rating'), '.2f')}/5.0.")
    
    if stats.get("price_sales_relationship"):
        max_sales_range = max(stats["price_sales_relationship"], key=lambda x: x.get("avg_sales", 0) or 0)
        if max_sales_range.get("price_range"):
            learnings.append(f"C√≥ m·ªôt 'v√πng gi√° v√†ng' - kho·∫£ng gi√° '{max_sales_range['price_range']}' n∆°i s·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t.")
    
    if cat_stats.get("distinct_levels"):
        learnings.append(f"C·∫•u tr√∫c danh m·ª•c ƒë∆∞·ª£c t·ªï ch·ª©c r·∫•t ch·∫∑t ch·∫Ω v·ªõi {cat_stats['distinct_levels']} c·∫•p ƒë·ªô, gi√∫p ng∆∞·ªùi mua d·ªÖ d√†ng t√¨m ki·∫øm.")
    
    for learning in learnings:
        p = doc.add_paragraph(learning, style="List Bullet")
        for run in p.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
    
    doc.add_paragraph()  # Spacing
    
    # ·ª®ng d·ª•ng
    doc.add_heading("·ª®ng D·ª•ng C·ªßa Dataset", 2)
    application = doc.add_paragraph()
    application.add_run("Dataset n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho nhi·ªÅu m·ª•c ƒë√≠ch nghi√™n c·ª©u v√† ph√¢n t√≠ch:")
    
    for run in application.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(12)
    
    applications = [
        "Nghi√™n c·ª©u v·ªÅ h√†nh vi mua s·∫Øm c·ªßa ng∆∞·ªùi Vi·ªát Nam",
        "Ph√¢n t√≠ch xu h∆∞·ªõng th·ªã tr∆∞·ªùng v√† d·ª± ƒëo√°n t∆∞∆°ng lai",
        "So s√°nh c√°c th∆∞∆°ng hi·ªáu v√† s·∫£n ph·∫©m",
        "H·ªçc t·∫≠p v·ªÅ Data Engineering v√† Data Analytics v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø",
        "Ph√°t tri·ªÉn c√°c d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu kh√°c"
    ]
    
    for app in applications:
        p = doc.add_paragraph(app, style="List Bullet")
        for run in p.runs:
            set_vietnamese_font(run)
            run.font.size = Pt(12)
    
    # Footer
    doc.add_paragraph()
    footer = doc.add_paragraph("---")
    footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
    footer_text = doc.add_paragraph("Tiki Data Pipeline - Data Story Document")
    footer_text.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in footer_text.runs:
        set_vietnamese_font(run)
        run.font.size = Pt(10)
        run.font.color.rgb = RGBColor(128, 128, 128)
    
    # L∆∞u file (x√≥a file c≈© n·∫øu t·ªìn t·∫°i v√† ƒëang b·ªã lock)
    try:
        if output_path.exists():
            try:
                output_path.unlink()
            except PermissionError:
                print(f"‚ö†Ô∏è  File ƒëang ƒë∆∞·ª£c m·ªü, vui l√≤ng ƒë√≥ng file {output_path} v√† ch·∫°y l·∫°i script")
                raise
        doc.save(str(output_path))
        print(f"‚úÖ ƒê√£ t·∫°o file docx: {output_path}")
    except PermissionError as e:
        print(f"‚ùå Kh√¥ng th·ªÉ ghi file: {e}")
        print(f"üí° Vui l√≤ng ƒë√≥ng file {output_path} n·∫øu ƒëang m·ªü v√† ch·∫°y l·∫°i script")
        raise


def main():
    """H√†m ch√≠nh"""
    # Set UTF-8 encoding for Windows
    if sys.platform == "win32":
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")
    
    print("=" * 70)
    print("üìñ X√ÇY D·ª∞NG C√ÇU CHUY·ªÜN D·ªÆ LI·ªÜU - TIKI DATA PIPELINE")
    print("=" * 70)
    
    # Load config
    config = load_env_config()
    print(f"\nüìã Th√¥ng tin k·∫øt n·ªëi:")
    print(f"   Host: {config['host']}")
    print(f"   Port: {config['port']}")
    print(f"   Database: {config['database']}")
    print(f"   User: {config['user']}")
    
    # K·∫øt n·ªëi database
    conn = connect_database(config)
    
    try:
        # Ph√¢n t√≠ch d·ªØ li·ªáu
        print("\nüîç B·∫Øt ƒë·∫ßu ph√¢n t√≠ch d·ªØ li·ªáu...")
        stats = analyze_database(conn)
        
        # T·∫°o file docx (lu√¥n ghi ƒë√® v√†o c√πng m·ªôt file)
        output_dir = PROJECT_ROOT / "docs"
        output_dir.mkdir(exist_ok=True)
        output_path = output_dir / "data_story.docx"
        
        print("\nüìù ƒêang t·∫°o file docx...")
        create_document(stats, output_path)
        
        print("\n" + "=" * 70)
        print("‚úÖ HO√ÄN T·∫§T!")
        print("=" * 70)
        print(f"\nüìÑ File ƒë√£ ƒë∆∞·ª£c t·∫°o t·∫°i: {output_path}")
        if output_path.exists():
            print(f"   K√≠ch th∆∞·ªõc: {output_path.stat().st_size / 1024:.2f} KB")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        conn.close()
        print("\nüîå ƒê√£ ƒë√≥ng k·∫øt n·ªëi database")


if __name__ == "__main__":
    main()

