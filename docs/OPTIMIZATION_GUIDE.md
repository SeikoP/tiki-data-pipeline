# H∆∞·ªõng D·∫´n T·ªëi ∆Øu Crawl 11k S·∫£n Ph·∫©m

## üìä Ph√¢n T√≠ch Hi·ªán Tr·∫°ng

V·ªõi **11,000 s·∫£n ph·∫©m** v√† c·∫•u h√¨nh hi·ªán t·∫°i:
- **Rate limit**: 2 gi√¢y/product
- **Th·ªùi gian crawl tu·∫ßn t·ª±**: 11,000 √ó 2s = **22,000 gi√¢y = 6.1 gi·ªù**
- **Dynamic Task Mapping**: T·∫°o 11k tasks song song (c√≥ th·ªÉ qu√° t·∫£i)

## üóìÔ∏è Multi-Day Crawling (Khuy·∫øn Ngh·ªã)

**Crawl trong nhi·ªÅu ng√†y** l√† c√°ch t·ªëi ∆∞u nh·∫•t cho 11k s·∫£n ph·∫©m:

### ∆Øu ƒëi·ªÉm:
- ‚úÖ Tr√°nh qu√° t·∫£i server v√† b·ªã block IP
- ‚úÖ Ph√¢n t√°n t·∫£i ƒë·ªÅu trong nhi·ªÅu ng√†y
- ‚úÖ C√≥ th·ªÉ resume n·∫øu l·ªói
- ‚úÖ T·ª± ƒë·ªông track progress
- ‚úÖ Kh√¥ng c·∫ßn ch·∫°y li√™n t·ª•c 6+ gi·ªù

### C·∫•u h√¨nh:
```python
# Airflow Variables
TIKI_PRODUCTS_PER_DAY = 1000  # Crawl 1000 products m·ªói ng√†y
TIKI_DETAIL_RATE_LIMIT_DELAY = 1.0  # 1 gi√¢y delay
```

### Th·ªùi gian:
- **11,000 products √∑ 1,000 products/ng√†y = 11 ng√†y**
- **M·ªói ng√†y**: 1,000 products √ó 1s = 1,000s = **16.7 ph√∫t** (v·ªõi 4 parallel batches)
- **T·ªïng th·ªùi gian**: 11 ng√†y √ó 16.7 ph√∫t = **~3 gi·ªù th·ª±c t·∫ø** (ph√¢n t√°n trong 11 ng√†y)

## üöÄ Gi·∫£i Ph√°p T·ªëi ∆Øu

### 1. **Multi-Day Crawling v·ªõi Progress Tracking** ‚≠ê (Khuy·∫øn ngh·ªã nh·∫•t)

Crawl trong nhi·ªÅu ng√†y v·ªõi tracking progress t·ª± ƒë·ªông:

**C·∫•u h√¨nh:**
```python
# Airflow Variables
TIKI_PRODUCTS_PER_DAY = 1000  # Crawl 1000 products m·ªói ng√†y
TIKI_DETAIL_RATE_LIMIT_DELAY = 1.0  # 1 gi√¢y delay
```

**T√≠nh nƒÉng:**
- ‚úÖ T·ª± ƒë·ªông track progress v√†o `crawl_progress.json`
- ‚úÖ Ch·ªâ crawl products ch∆∞a crawl
- ‚úÖ Resume t·ª´ ƒëi·ªÉm d·ª´ng n·∫øu l·ªói
- ‚úÖ DAG ch·∫°y h√†ng ng√†y, t·ª± ƒë·ªông crawl batch ti·∫øp theo
- ‚úÖ Kh√¥ng c·∫ßn can thi·ªáp th·ªß c√¥ng

**V√≠ d·ª• v·ªõi 11k products:**
- Ng√†y 1: Crawl products 0-999 (1000 products)
- Ng√†y 2: Crawl products 1000-1999 (1000 products)
- ...
- Ng√†y 11: Crawl products 10000-10999 (1000 products)

### 2. **Batch Processing v·ªõi Chunking**

Chia 11k s·∫£n ph·∫©m th√†nh batches nh·ªè, x·ª≠ l√Ω t·ª´ng batch:

**∆Øu ƒëi·ªÉm:**
- Tr√°nh qu√° t·∫£i Airflow v·ªõi 11k tasks
- D·ªÖ qu·∫£n l√Ω v√† monitor
- C√≥ th·ªÉ resume n·∫øu l·ªói
- T·ªëi ∆∞u memory v√† CPU

**C·∫•u h√¨nh:**
```python
# Airflow Variables
TIKI_DETAIL_BATCH_SIZE = 500  # M·ªói batch 500 products
TIKI_DETAIL_MAX_PARALLEL_BATCHES = 4  # 4 batches song song
TIKI_DETAIL_RATE_LIMIT_DELAY = 1.0  # Gi·∫£m xu·ªëng 1s (n·∫øu server cho ph√©p)
```

**Th·ªùi gian ∆∞·ªõc t√≠nh:**
- M·ªói batch: 500 products √ó 1s = 500s = 8.3 ph√∫t
- 4 batches song song: 8.3 ph√∫t
- T·ªïng batches: 11,000 / 500 = 22 batches
- Th·ªùi gian t·ªïng: 22 / 4 √ó 8.3 = **45.6 ph√∫t** (thay v√¨ 6.1 gi·ªù)

### 2. **TƒÉng Parallelism**

**C·∫•u h√¨nh Airflow:**
```yaml
# docker-compose.yaml
AIRFLOW__CELERY__WORKER_CONCURRENCY: 16  # M·ªói worker x·ª≠ l√Ω 16 tasks
AIRFLOW__CORE__PARALLELISM: 32  # T·ªïng s·ªë tasks song song
AIRFLOW__CELERY__WORKER_PREFETCH_MULTIPLIER: 4
```

**Scale workers:**
```yaml
# Th√™m nhi·ªÅu workers
airflow-worker-2:
  <<: *airflow-common
  command: celery worker
  # ...
```

### 3. **Smart Caching**

Ch·ªâ crawl products ch∆∞a c√≥ cache:
- Ki·ªÉm tra cache tr∆∞·ªõc khi crawl
- Skip products ƒë√£ c√≥ detail ƒë·∫ßy ƒë·ªß
- Gi·∫£m th·ªùi gian crawl ƒë√°ng k·ªÉ

**∆Ø·ªõc t√≠nh:**
- N·∫øu 50% ƒë√£ c√≥ cache: ch·ªâ crawl 5,500 products
- Th·ªùi gian: 5,500 √ó 1s / 4 batches = **22.9 ph√∫t**

### 4. **Gi·∫£m Rate Limit Delay**

**Ph√¢n t√≠ch:**
- Delay 2s/product: qu√° th·∫≠n tr·ªçng
- Delay 1s/product: h·ª£p l√Ω cho h·∫ßu h·∫øt server
- Delay 0.5s/product: n·∫øu server cho ph√©p

**Test v√† ƒëi·ªÅu ch·ªânh:**
```python
# B·∫Øt ƒë·∫ßu v·ªõi 1s, gi·∫£m d·∫ßn n·∫øu kh√¥ng b·ªã block
TIKI_DETAIL_RATE_LIMIT_DELAY = 1.0  # ‚Üí 0.8 ‚Üí 0.5
```

### 5. **Priority Queue**

∆Øu ti√™n crawl products quan tr·ªçng tr∆∞·ªõc:
- Products c√≥ sales_count cao
- Products m·ªõi
- Products ch∆∞a c√≥ detail

### 6. **Retry Mechanism**

T·ª± ƒë·ªông retry failed products:
```python
# Airflow task config
retries=2
retry_delay=timedelta(minutes=5)
```

### 7. **Progress Tracking**

L∆∞u progress v√†o database/file ƒë·ªÉ resume:
- Track products ƒë√£ crawl
- Resume t·ª´ ƒëi·ªÉm d·ª´ng
- Tr√°nh crawl l·∫°i products ƒë√£ xong

## üìù C·∫•u H√¨nh Khuy·∫øn Ngh·ªã

### Airflow Variables

```python
# Multi-day crawling (Khuy·∫øn ngh·ªã)
TIKI_PRODUCTS_PER_DAY = 1000  # S·ªë products crawl m·ªói ng√†y
TIKI_DETAIL_RATE_LIMIT_DELAY = 1.0  # 1 gi√¢y delay gi·ªØa c√°c requests

# Batch processing (n·∫øu kh√¥ng d√πng multi-day)
TIKI_DETAIL_BATCH_SIZE = 500
TIKI_DETAIL_MAX_PARALLEL_BATCHES = 4

# Timeout
TIKI_DETAIL_CRAWL_TIMEOUT = 60  # 1 ph√∫t/product

# Gi·ªõi h·∫°n (0 = kh√¥ng gi·ªõi h·∫°n, ch·ªâ d√πng khi test)
TIKI_MAX_PRODUCTS_FOR_DETAIL = 0
```

### Docker Compose

```yaml
environment:
  AIRFLOW__CELERY__WORKER_CONCURRENCY: 16
  AIRFLOW__CORE__PARALLELISM: 32
  AIRFLOW__CELERY__WORKER_PREFETCH_MULTIPLIER: 4
```

## üéØ K·∫ø Ho·∫°ch Th·ª±c Hi·ªán

### B∆∞·ªõc 1: C·∫•u h√¨nh Multi-Day Crawling (Khuy·∫øn ngh·ªã)
- Set `TIKI_PRODUCTS_PER_DAY = 1000` trong Airflow Variables
- DAG s·∫Ω t·ª± ƒë·ªông ch·∫°y h√†ng ng√†y v√† crawl batch ti·∫øp theo
- Progress ƒë∆∞·ª£c l∆∞u t·ª± ƒë·ªông v√†o `data/raw/products/crawl_progress.json`

### B∆∞·ªõc 2: Monitor Progress
- Ki·ªÉm tra file `crawl_progress.json` ƒë·ªÉ xem ti·∫øn ƒë·ªô
- Xem logs c·ªßa DAG ƒë·ªÉ bi·∫øt s·ªë products ƒë√£ crawl
- ƒêi·ªÅu ch·ªânh `TIKI_PRODUCTS_PER_DAY` n·∫øu c·∫ßn

### B∆∞·ªõc 3: T·ªëi ∆∞u Rate Limit
- B·∫Øt ƒë·∫ßu v·ªõi delay 1s
- Gi·∫£m d·∫ßn n·∫øu kh√¥ng b·ªã block (0.8s ‚Üí 0.5s)

### B∆∞·ªõc 4: Scale n·∫øu c·∫ßn
- N·∫øu mu·ªën crawl nhanh h∆°n: tƒÉng `TIKI_PRODUCTS_PER_DAY`
- N·∫øu b·ªã block: gi·∫£m `TIKI_PRODUCTS_PER_DAY` ho·∫∑c tƒÉng `TIKI_DETAIL_RATE_LIMIT_DELAY`

## ‚è±Ô∏è Th·ªùi Gian ∆Ø·ªõc T√≠nh

| C·∫•u h√¨nh | Th·ªùi gian | Ghi ch√∫ |
|----------|-----------|---------|
| Tu·∫ßn t·ª± (2s delay) | 6.1 gi·ªù | Kh√¥ng t·ªëi ∆∞u |
| **Multi-day: 1000/ng√†y, 1s delay** | **11 ng√†y** | **‚≠ê Khuy·∫øn ngh·ªã nh·∫•t** |
| Multi-day: 2000/ng√†y, 1s delay | 6 ng√†y | Nhanh h∆°n nh∆∞ng r·ªßi ro h∆°n |
| Batch 500, 4 parallel, 1s delay | 45 ph√∫t | M·ªôt l·∫ßn, c·∫ßn ch·∫°y li√™n t·ª•c |
| Batch 500, 8 parallel, 1s delay | 23 ph√∫t | C·∫ßn nhi·ªÅu resources |

## ‚ö†Ô∏è L∆∞u √ù

1. **Rate Limiting**: Kh√¥ng gi·∫£m delay qu√° th·∫•p ‚Üí c√≥ th·ªÉ b·ªã block IP
2. **Memory**: M·ªói Selenium instance t·ªën ~200-500MB RAM
3. **CPU**: C·∫ßn ƒë·ªß CPU cho parallel tasks
4. **Network**: ƒê·∫£m b·∫£o bandwidth ƒë·ªß cho nhi·ªÅu requests
5. **Database**: Airflow metadata DB c·∫ßn ƒë·ªß capacity

## üîß Troubleshooting

### L·ªói: Out of Memory
- Gi·∫£m `WORKER_CONCURRENCY`
- Gi·∫£m batch size
- TƒÉng memory cho workers

### L·ªói: Too many tasks
- Gi·∫£m parallelism
- TƒÉng batch size
- D√πng batch processing thay v√¨ Dynamic Task Mapping tr·ª±c ti·∫øp

### L·ªói: Rate limit/Blocked
- TƒÉng `RATE_LIMIT_DELAY`
- Gi·∫£m s·ªë parallel batches
- D√πng proxy rotation (n·∫øu c√≥)

